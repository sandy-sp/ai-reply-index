{
  "prompt": "**AI-Powered Resilience: Combating Sophisticated, Coordinated, and Adversarial\nMulti-Modal Disinformation Campaigns**\n\n  * **Focus Area:** AI Ethics, Misinformation/Disinformation, AI Security, Media Forensics\n  * **Prompt Details:** \"Conduct an in-depth research investigation into the development of a resilient, multi-layered, AI-driven defense framework against sophisticated, coordinated, and adversarially evolving multi-modal disinformation campaigns (involving text, images, audio, video, and deepfakes). This research should explore: \n    * **Early Detection of Coordinated Inauthentic Behavior:** AI techniques for identifying patterns of coordinated activity across multiple platforms and media types that indicate an orchestrated disinformation campaign, even before specific pieces of false content gain significant traction.\n    * **Robust Multi-Modal Content Authenticity Verification:** Advancing AI-powered forensic tools for detecting subtle manipulations in various media formats, including methods resilient to common adversarial attacks (e.g., GAN-generated content specifically designed to fool detectors).\n    * **Attribution and Source Tracing of Disinformation:** Research into AI methodologies that can assist in tracing disinformation back to its origins or primary disseminators, considering both technical artifacts and behavioral patterns.\n    * **Understanding and Predicting Disinformation Impact:** AI models to predict the potential reach, impact, and psychological effect of specific disinformation narratives on different populations, and to identify communities most vulnerable to such campaigns.\n    * **AI-Augmented Counter-Messaging and Inoculation Strategies:** Exploring the ethical development and application of AI to help generate and disseminate effective, fact-based counter-narratives, or to design \"inoculation\" strategies that can build cognitive resilience against common disinformation techniques.\n    * **The Human-AI Partnership in Combating Disinformation:** How can AI tools best augment the capabilities of human fact-checkers, journalists, educators, and policymakers in the fight against disinformation, ensuring human oversight and ethical application?\"\n  * **Keywords for further research:** AI disinformation detection, multi-modal deepfake analysis, coordinated inauthentic behavior AI, AI media forensics, adversarial attacks on AI detectors, AI counter-disinformation.",
  "model": "ChatGPT",
  "response": "**\n\n# AI-Powered Resilience: Combating Sophisticated, Coordinated, and Adversarial\nMulti-Modal Disinformation Campaigns\n\nExecutive Summary\n\nThe digital age has witnessed a significant surge in the prevalence and\nsophistication of disinformation campaigns. These campaigns, often\ncharacterized by their coordinated nature, adversarial intent, and use of\nmultiple media formats, pose a growing threat to individuals, organizations,\nand democratic processes. Simultaneously, Artificial Intelligence (AI) has\nemerged as a powerful force, playing a dual role as both an enabler of these\nsophisticated disinformation tactics and a critical tool in their detection\nand mitigation. This report delves into the intricate landscape of AI-powered\ndisinformation, examining its characteristics, the ways in which AI\nfacilitates its creation and spread, and the burgeoning field of AI-driven\nresilience aimed at countering these threats. The analysis encompasses the\ntechnical methodologies employed in AI-based detection, the inherent\nchallenges and limitations of these approaches, the crucial ethical\nconsiderations that must guide their development and deployment, and the\nfuture trends shaping the battle against disinformation. Ultimately, the\nreport underscores the necessity of a multi-faceted strategy that integrates\ntechnological innovation with robust policy frameworks, comprehensive\neducational initiatives, and the indispensable expertise of human analysts to\nfoster a more resilient and trustworthy information ecosystem.\n\nDefining the Modern Disinformation Threat:\n\nDisinformation campaigns represent a significant cybersecurity challenge in\nthe contemporary digital environment. These campaigns are defined as\ndeliberate efforts to disseminate false or misleading information with the\nintention to deceive or manipulate target audiences for various objectives,\nincluding political or financial gain.1 While the fundamental concept of\nspreading false information is not new, the scale and sophistication of modern\ncampaigns have been amplified by technological advancements.\n\nSophisticated disinformation campaigns often employ a range of intricate\ntechniques. These include the creation of false narratives, where stories are\ncrafted and propagated that are grossly distorted or entirely fabricated.\nEmotional manipulation is another common tactic, leveraging content that\ntriggers strong emotions such as fear or anger to increase user engagement and\nbroader dissemination of the false information. Furthermore, these campaigns\nfrequently exploit existing societal or political divisions, aiming to sow\ndiscord and confusion by intensifying these fractures.1 The intentional and\ncalculated nature of these strategies distinguishes sophisticated\ndisinformation from mere misinformation, which is the unintentional sharing of\ninaccurate information.2\n\nThe element of coordination is crucial in amplifying the reach and impact of\ndisinformation. Coordinated campaigns involve organized groups or networks of\nactors working in concert to spread specific messages and mislead target\naudiences. These operations often rely on a mix of authentic and inauthentic\nsocial media accounts, including bots and fake personas, to create a deceptive\nimpression of widespread support or opposition to a particular narrative.4 The\ngoal of such coordination is to manipulate public debate for strategic\npurposes, whether financial or political.8\n\nAdding another layer of complexity, many disinformation campaigns are\nadversarial in nature. Adversarial campaigns are strategic deception efforts\norchestrated to confuse, paralyze, and polarize an audience. These campaigns\noften involve state or non-state actors with malicious intent, seeking to\nundermine trust in institutions, damage reputations, or incite social unrest.1\nThe tactics employed can range from circulating incorrect information to\ncreating uncertainty and undermining the legitimacy of official information\nsources.9\n\nContemporary disinformation campaigns are increasingly characterized by their\nmulti-modal nature. This involves the strategic use of a combination of\ndifferent media formats, including text, images, audio, and video, to enhance\nthe believability and overall engagement of the false information.3 This\nmulti-modal content often includes manipulated media such as deepfakes, which\nutilize AI algorithms to generate highly realistic but ultimately false images\nand videos.15 The integration of various modalities can significantly increase\nthe persuasiveness of disinformation and make it considerably more challenging\nto debunk.19\n\nThe role of AI in the evolution of disinformation tactics is pivotal. AI\ntechnologies, particularly Natural Language Processing (NLP) and generative AI\nmodels, are now being leveraged to create and disseminate falsehoods with\nremarkable speed and at a massive scale.14 AI's capabilities extend to\ngenerating highly convincing fake content, encompassing everything from\nsophisticated deepfakes that can realistically depict individuals saying or\ndoing things they never did, to AI-generated articles that are virtually\nindistinguishable from content produced by credible news organizations.1\nFurthermore, AI plays a significant role in facilitating coordinated\ninauthentic behavior through the automated creation and management of fake\nonline personas, the deployment of bots to amplify false narratives, and the\noverall automation of content dissemination across various digital platforms.1\nThe confluence of these factors has significantly lowered the barrier to entry\nfor creating and spreading sophisticated disinformation, enabling a wider\nrange of actors, including non-state entities, to launch impactful campaigns.\n\nAI as an Enabler of Disinformation:\n\nArtificial Intelligence has become a potent tool in the hands of those seeking\nto create and disseminate disinformation. Its capabilities in content\ngeneration, facilitating coordination, and enhancing personalization have\nsignificantly amplified the reach and impact of these malicious campaigns.\n\nAI, particularly through Large Language Models (LLMs), has revolutionized the\ncreation of text-based disinformation. These models can generate fluent and\nseemingly accurate text, making it considerably easier to produce believable\nfake news articles, social media posts, and other forms of written content\ndesigned to deceive.14 The ability of AI to mimic human writing styles and\neven adapt its tone to suit different audiences makes it a powerful tool for\ncrafting persuasive falsehoods.\n\nThe landscape of image-based disinformation has also been transformed by\ngenerative AI tools such as Generative Adversarial Networks (GANs) and\ndiffusion models. These technologies can produce highly realistic fake images\nthat are often indistinguishable from authentic photographs, even to the\ntrained eye.1 Projects like ThisPersonDoesNotExist.com, which utilizes GANs to\ncreate realistic but entirely synthetic faces, have demonstrated the potential\nfor AI to generate seemingly credible visual content for disinformation\ncampaigns.17\n\nIn the realm of audio, AI-powered voice cloning technologies have emerged as a\nsignificant enabler of disinformation. These technologies can create realistic\naudio deepfakes, allowing malicious actors to impersonate individuals and\nspread false statements attributed to them.29 The ability to convincingly\nreplicate a person's voice opens up new avenues for scams, hoaxes, and\npolitical manipulation. The creation of fake audio messages from public\nfigures, as seen in examples targeting elections, underscores the potential\nfor this technology to mislead and influence public opinion.31\n\nFurthermore, advancements in AI have extended to video generation, with tools\nlike OpenAI's Sora demonstrating the capability to create highly detailed and\nrealistic fake videos from simple text prompts.27 This capability represents a\nsignificant leap in the sophistication of AI-generated disinformation, as\nrealistic fake video footage can be exceptionally persuasive and difficult to\ndebunk. The increasing sophistication and accessibility of these AI-powered\ncontent generation tools across text, image, audio, and video formats are\ncollectively amplifying the potential scale and impact of disinformation\ncampaigns, making it easier for malicious actors to create and disseminate\ncompelling falsehoods across the digital landscape.\n\nAI also plays a crucial role in facilitating Coordinated Inauthentic Behavior\n(CIB). AI-powered bots can rapidly spread disinformation across various online\nplatforms, operating simultaneously and creating a deceptive illusion of\nwidespread consensus around a particular narrative.1 These bots can be\nprogrammed to engage with content, like and share posts, and even participate\nin online discussions, making it appear as though there is genuine grassroots\nsupport for a particular viewpoint. Moreover, AI can be employed to generate\nextensive networks of fake personas and websites, further enhancing the\nbelievability of disinformation messages.11 These fake online identities can\nbe used to amplify narratives, lend credibility to false claims, and create\necho chambers that reinforce disinformation. Additionally, AI-driven social\nbots are becoming increasingly adept at mimicking human behavior online,\nmaking them more challenging to identify as part of coordinated inauthentic\nactivity.25 By learning from vast datasets of human interactions, these bots\ncan generate more natural-sounding text, engage in more realistic\nconversations, and exhibit patterns of behavior that are less easily\ndistinguishable from those of genuine users. This automation and scaling of\nCIB through AI enable malicious actors to create the false impression that\ntheir narratives have broad support and legitimacy, while simultaneously\nmaking it more difficult to trace the true origins of these campaigns.\n\nBeyond content generation and coordination, AI significantly enhances the\nscale and personalization of disinformation campaigns. AI algorithms possess\nthe capability to analyze vast quantities of user data harvested from social\nmedia platforms, search engines, and other online sources. This data analysis\nallows malicious actors to precisely target specific individuals or\ndemographic groups with disinformation messages that are tailored to their\nunique biases, vulnerabilities, and interests.1 Furthermore, AI-powered micro-\ntargeting and geofencing techniques can be employed to deliver disinformation\nto highly specific audiences based on their online behavior, geographic\nlocation, and even their social connections.1 By understanding the\npsychological profiles and online habits of their targets, disinformation\ncampaigns can craft messages that are more likely to resonate and be accepted\nas true. AI can also personalize the content of disinformation itself,\nadapting the language, tone, and even the specific claims made to align with\nthe individual's pre-existing beliefs and values.23 This level of\npersonalization significantly increases the persuasiveness of disinformation\nand the likelihood that individuals will engage with it, believe it, and share\nit further within their networks. The ability of AI to scale and personalize\ndisinformation in this manner poses a profound threat to public opinion, trust\nin institutions, and the integrity of democratic processes, as individuals are\nincreasingly exposed to highly targeted and seemingly credible falsehoods.\n\nAI-Driven Resilience: Detection and Countermeasures:\n\nIn response to the growing threat of AI-powered disinformation, the field of\nAI itself is being leveraged to develop sophisticated detection and\ncountermeasures. Various AI methodologies are proving effective in identifying\ndifferent forms of disinformation, ranging from text and images to audio and\ncoordinated inauthentic behavior.\n\nFor text-based disinformation, Natural Language Processing (NLP) techniques\noffer powerful analytical capabilities. NLP can analyze the linguistic\ncharacteristics of text, including its language, sentiment, and overall\nstructure, to identify patterns that are indicative of disinformation.14 These\npatterns can include the use of emotionally charged language, grammatical\ninconsistencies, or the presence of claims that contradict established facts.\nFurthermore, machine learning algorithms, encompassing supervised learning,\ndeep learning, and advanced transformer models like BERT, are being trained to\nclassify news articles and social media posts as either genuine or fake based\non these linguistic features and comparisons with verified information.39\nExplainable AI (XAI) methods are also contributing to this effort by helping\nto identify the specific linguistic features that influence a model's\nprediction, thereby improving the transparency and trustworthiness of these\ndetection systems and aiding in the identification and mitigation of potential\nbiases.42\n\nAI is also playing a crucial role in the detection of image and video\ndisinformation, particularly deepfakes. AI models can be trained to identify\nsubtle inconsistencies in facial features, unnatural vocal patterns, and other\nvisual or auditory artifacts that are often present in manipulated media.18\nFrequency domain analysis techniques can be employed to detect unique\n\"fingerprints\" left by AI image generation processes, providing a valuable\nmethod for distinguishing between real and synthetic images.43 Convolutional\nNeural Networks (CNNs) have demonstrated the ability to learn the granular\ncharacteristics of AI-generated videos, enabling them to effectively identify\nsynthetic video content.32 Additionally, AI-powered tools can analyze the\nmetadata associated with images and videos and even embed digital watermarks\nas a means of verifying their authenticity and detecting subsequent\nmanipulations.18\n\nThe detection of audio deepfakes and manipulated audio media is another area\nwhere AI is proving invaluable. AI-powered voice analysis techniques can\nidentify anomalies in speech patterns, such as unnatural pauses or changes in\nintonation, that may indicate artificial generation.44 Acoustic analysis,\ncombined with machine learning algorithms, can recognize patterns and\ninconsistencies in audio that are characteristic of synthetic speech.29\nSpecialized tools, such as Pindrop\u24c7 Pulse, utilize sophisticated AI algorithms\nto analyze audio segments for synthetic elements with a high degree of\naccuracy.44 These AI models are often trained on extensive datasets of both\nreal and AI-generated speech to enhance their ability to differentiate between\nthe two.\n\nAI is also being effectively used to analyze Coordinated Inauthentic Behavior\n(CIB). Machine learning models can examine the network connections and online\nbehavior of social media accounts to identify clusters of accounts exhibiting\nunnatural interaction patterns, which are often indicative of CIB.25 Graph-\nbased anomaly detection and time-series analysis are specific AI techniques\nthat can reveal coordinated activity typical of bot-driven disinformation\ncampaigns.25 Furthermore, multi-modal data fusion, which involves combining\nand analyzing text, image, and behavioral data associated with accounts, can\nsignificantly enhance the accuracy of CIB detection.25 AI can also identify\npatterns in how content is shared across networks, such as instances of co-\nretweeting or the sharing of identical URLs by multiple accounts in a short\nperiod, which can be strong indicators of coordinated activity.46\n\nThe proactive identification of disinformation campaigns is another crucial\narea where AI is being applied. AI can power early warning systems that\ncontinuously monitor online platforms for emerging malicious trends, sudden\nspikes in specific narratives, and other indicators that may signal the\nbeginning of a coordinated disinformation effort.23 Predictive models, driven\nby AI algorithms, can analyze the patterns of information spread and identify\ncontent that has the potential to become highly viral, allowing for early\nintervention by fact-checkers and platform administrators.38 Additionally, AI-\npowered systems can track the evolution of disinformation narratives over time\nand identify connections between seemingly disparate pieces of false\ninformation, providing a more holistic understanding of ongoing campaigns.48\n\nAutomated fact-checking and verification platforms represent a significant\napplication of AI in combating disinformation. AI-powered tools can\nautomatically extract factual claims from large volumes of text, compare these\nclaims against existing databases of verified information and reliable\nsources, and provide a determination of their accuracy.49 Platforms like\nClaimBuster and Full Fact utilize AI algorithms to identify claims that are\nlikely to be false or misleading and flag them for further review or automatic\ndebunking.51 AI can also assist human fact-checkers by identifying and\nclustering similar claims, as well as by providing relevant contextual\ninformation, thereby increasing the efficiency and scalability of the fact-\nchecking process.49\n\nFinally, AI is being explored for its potential in generating counter-\nnarratives to combat the spread of harmful disinformation. AI can be used to\ncreate non-aggressive, fact-based responses to hate speech and misinformation,\nproviding alternative perspectives and accurate information.14 Large Language\nModels (LLMs) can be leveraged to generate persuasive counter-arguments that\nare contextually relevant and incorporate background knowledge from diverse\nsources.55 AI-powered chatbots can also be deployed to engage with individuals\nwho have been exposed to conspiracy theories or other forms of disinformation,\nproviding accurate information and attempting to debunk false claims.36 This\ncapability to generate and disseminate counter-narratives at scale offers a\npromising avenue for mitigating the impact of disinformation campaigns.\n\nChallenges and Limitations in AI-Powered Disinformation Defense:\n\nDespite the significant potential of AI in combating disinformation, there are\nnumerous challenges and limitations that must be addressed to ensure its\neffectiveness and responsible use.\n\nOne of the primary challenges is the constantly evolving sophistication of\ndisinformation tactics. Those who create and spread disinformation are\ncontinuously adapting their techniques to evade detection by AI systems.36\nThis includes the increasing use of multi-modal formats, which combine text,\nimages, audio, and video in novel ways to enhance believability, making\ndetection more difficult for existing AI tools that may be primarily trained\non single modalities.14 Furthermore, sophisticated campaigns often employ\nsubtle manipulation techniques and nuanced language that AI models, which\ntypically rely on pattern recognition, struggle to interpret accurately.38\nThis ongoing arms race between those who create disinformation and those who\nseek to detect it necessitates continuous advancements in AI detection\ncapabilities to keep pace with these evolving tactics.\n\nAlgorithmic bias and fairness concerns represent another significant\nlimitation in AI-powered disinformation defense. AI models are trained on vast\ndatasets, and if these datasets contain societal biases, the models can\ninadvertently perpetuate and even amplify these biases in their detection of\ndisinformation.60 This can lead to content moderation algorithms\ndisproportionately flagging content from marginalized communities as\ndisinformation or hate speech, while potentially overlooking similar content\nfrom more privileged groups.36 Ensuring fairness and inclusivity in AI-powered\ndisinformation detection is therefore not only an ethical imperative but also\na significant technical challenge that requires careful attention to data\ncuration, model design, and ongoing monitoring.\n\nA critical vulnerability of AI models used for disinformation detection is\ntheir susceptibility to adversarial attacks. These attacks involve subtle\nmanipulations of the input data, often imperceptible to humans, that are\nspecifically designed to mislead the AI model into making incorrect\nclassifications.69 Deepfake detectors and broader disinformation detection\nsystems are both vulnerable to these types of attacks, which can effectively\ninhibit their performance and allow malicious actors to evade detection and\ncontinue spreading false information.76 The potential for even slight\nalterations to content to completely fool an AI detection system highlights\nthe need for more robust and resilient models.\n\nThe accuracy and reliability of AI-powered disinformation detection in real-\nworld scenarios can also be problematic. Current deepfake detection\ntechnologies, while promising, may have limited effectiveness when applied to\ndiverse real-world data that differs from the controlled conditions under\nwhich they were trained.18 Similarly, AI-powered fact-checking tools may\nstruggle to accurately discern between truly reliable and less trustworthy\nsources of information, potentially leading to inaccuracies in their\nassessments.81 Factors such as variations in lighting, facial expressions,\nvideo and audio quality, and the specific methods used to create the deepfake\ncan all impact the accuracy of AI detection models.18\n\nFinally, detecting nuanced and contextual disinformation presents a\nsignificant hurdle for AI. AI tools often struggle with understanding the\nsubtleties of human language, including sarcasm, irony, and cultural\nreferences, which can lead to both false positives (incorrectly flagging\nlegitimate content) and false negatives (missing actual disinformation).14\nDisinformation that relies on manipulating the context of information or\nstrategically omitting essential details is also particularly challenging for\nAI to identify.82 Furthermore, AI's limitations in comprehending intent can\nmake it difficult to distinguish between satire, which may intentionally\npresent false information for humorous or critical purposes, and deliberate\ndeception aimed at causing harm.44 These challenges underscore the need for\ncontinued research and development of AI models that possess a deeper\nunderstanding of human communication and the complexities of context.\n\nThe Human-AI Partnership and Ethical Considerations:\n\nWhile AI offers significant capabilities in combating disinformation, human\nexpertise remains indispensable for effective and ethical defense. A\ncollaborative partnership between AI technologies and human analysts is\ncrucial for navigating the complexities of this evolving threat.\n\nHuman fact-checkers and domain experts play a vital role in verifying complex\nclaims, providing nuanced judgments, and understanding the broader context of\ndisinformation campaigns in ways that AI alone cannot replicate.38 Human\noversight is also essential for identifying and mitigating biases that may be\npresent in AI algorithms, ensuring that detection systems are fair and do not\ndisproportionately impact certain communities or viewpoints.61 Hybrid systems\nthat effectively combine the scalability and efficiency of AI with the\ncritical thinking and contextual awareness of human experts have often\ndemonstrated superior performance in detecting and countering disinformation\ncompared to either approach in isolation.44\n\nThe development and deployment of AI countermeasures against disinformation\nmust be guided by strong ethical frameworks. Key principles within these\nframeworks include transparency, accountability, and respect for privacy.36\nTransparency is crucial for ensuring that the public understands how AI\ndetection models work and for building trust in their outcomes.14\nAccountability mechanisms are necessary to establish clear lines of\nresponsibility for the decisions and actions taken by AI-powered systems in\nidentifying and addressing disinformation.36 Furthermore, privacy\nconsiderations must be carefully addressed in the collection, storage, and use\nof data for training and deploying AI detection systems to ensure that\nindividuals' rights are protected.36\n\nA particularly complex ethical challenge lies in balancing the fundamental\nright to freedom of expression with the pressing need to combat harmful\ndisinformation.2 Overly aggressive content moderation by AI systems, while\nintended to curb the spread of falsehoods, can inadvertently lead to\ncensorship and the suppression of legitimate speech, particularly if the AI\nmodels are not sufficiently nuanced in their understanding of context and\nintent.36 Therefore, it is essential to establish clear guidelines for content\nmoderation and to implement transparent appeals processes that allow users to\nchallenge decisions made by AI systems, ensuring accountability and\nmaintaining user trust.85 Striking the appropriate balance requires ongoing\ndialogue and careful consideration of the potential impacts of both\ndisinformation and the measures taken to counter it on democratic values and\nindividual rights.\n\nBuilding a Resilient Information Ecosystem:\n\nCombating the multifaceted threat of AI-powered disinformation requires a\ncomprehensive approach that extends beyond technological solutions to\nencompass educational initiatives, policy frameworks, and collaborative\nefforts aimed at building a more resilient information ecosystem.\n\nMedia and digital literacy education play a foundational role in equipping\nindividuals with the critical thinking skills necessary to evaluate the\ncredibility of online information and identify various forms of\ndisinformation.1 These educational programs teach individuals how to navigate\nthe digital landscape safely and responsibly, including recognizing the red\nflags that often accompany misinformation and understanding the tactics used\nin disinformation campaigns.36 Furthermore, educating the public about the\ncapabilities and limitations of AI can foster a healthy sense of skepticism\ntowards online content, encouraging individuals to question the information\nthey encounter rather than accepting it at face value.96 By empowering\ncitizens with these skills, societies can build greater resilience against the\nmanipulative effects of disinformation.\n\nThe policy and regulatory landscape surrounding AI and disinformation is also\nevolving rapidly as governments and regulatory bodies increasingly recognize\nthe need to address these challenges.3 The European Union's Digital Services\nAct, for example, includes specific measures aimed at tackling disinformation\nonline, placing obligations on large online platforms to assess and mitigate\nthe risks their services pose to society, including the spread of false\ninformation.26 Policymakers are also actively considering regulations related\nto the labeling of AI-generated content, which would provide users with\ngreater transparency about the origin of the media they consume, as well as\nmeasures to increase the overall transparency of AI algorithms used in content\nmoderation and information dissemination.23 These policy and regulatory\nefforts are essential for establishing accountability, setting standards for\nthe responsible development and deployment of AI technologies, and creating a\nmore secure information environment.\n\nEffective countermeasures against AI-powered disinformation also require\nfostering strong collaboration between a diverse range of stakeholders. This\nincludes technology platforms, which play a critical role in the dissemination\nof information; governments, which are responsible for setting policy and\nregulatory frameworks; academic and research institutions, which contribute to\nthe development of detection tools and the understanding of disinformation\ndynamics; and civil society organizations, which advocate for media literacy\nand information integrity.14 The sharing of information, threat intelligence,\nand best practices among these stakeholders is crucial for developing a\ncomprehensive understanding of the evolving disinformation landscape and for\nenabling coordinated responses to campaigns.23 Public-private partnerships can\nalso play a vital role in facilitating the development and deployment of\neffective countermeasures against increasingly sophisticated synthetic\ndisinformation.95 This collaborative, multi-stakeholder approach is essential\nfor addressing the complex and rapidly changing challenges posed by AI-powered\ndisinformation and for building a more resilient and trustworthy information\necosystem for all.\n\nFuture Trends and the Path Forward:\n\nThe field of AI-powered disinformation and the corresponding resilience\nmechanisms are both rapidly evolving, with several key trends shaping the\nfuture landscape.\n\nNext-generation AI models are anticipated to incorporate increasingly advanced\ntechniques for analyzing and understanding the intricate relationships between\ndifferent modalities of information, including text, images, audio, and\nvideo.114 Advancements in multimodal learning will enable AI systems to\nprocess and integrate diverse data types more effectively, leading to more\naccurate and nuanced detection of disinformation that strategically combines\nvarious media formats.114 Furthermore, future AI models may leverage\nsophisticated knowledge graphs and enhanced reasoning capabilities to better\nunderstand the context and assess the veracity of multi-modal content, moving\nbeyond surface-level pattern recognition to deeper semantic analysis.108\n\nEmerging technologies and ongoing research efforts are also poised to\nsignificantly advance the field of AI-driven disinformation detection. There\nis a strong focus on developing more robust and deployable AI detectors that\ncan maintain high levels of accuracy and reliability when applied to real-\nworld scenarios, which often present more variability and complexity than\ncontrolled research environments.120 Explainable AI (XAI) is expected to play\nan increasingly crucial role in making AI detection systems more transparent\nin their decision-making processes, thereby fostering greater trust among\nusers and stakeholders.14 The integration of uncertainty quantification (UQ)\ninto AI detection systems will provide valuable insights into the confidence\nlevels associated with predictions, further enhancing the reliability and\ninterpretability of these tools.14 The field of AI-driven media forensics will\nalso continue to advance, offering increasingly sophisticated techniques for\nanalyzing and authenticating digital content across various media types, which\nwill be critical in identifying manipulated media used in disinformation\ncampaigns.121\n\nThe future of maintaining information integrity in the face of increasingly\nsophisticated AI-powered disinformation will likely be characterized by a\ngreater emphasis on synergistic partnerships between AI tools and human\nexpertise.14 It is anticipated that AI will increasingly handle the initial\nscreening and analysis of the vast volumes of online data, flagging\npotentially problematic content for further review by human experts. This\ndivision of labor will allow human analysts to focus their expertise on more\ncomplex and nuanced cases that require critical thinking, contextual\nunderstanding, and subject-matter knowledge that AI may still lack.36\nFurthermore, there is a trend towards the development of more user-friendly AI\ntools that can be readily adopted by individuals to assess the credibility of\nthe information they encounter online, empowering them to become more\ndiscerning consumers of digital content.27 This synergistic partnership\nbetween increasingly sophisticated AI tools and the critical thinking\nabilities of both experts and informed citizens represents the most promising\npath forward in the ongoing effort to maintain information integrity in an\nincreasingly complex digital world.\n\nConclusion\n\nThe analysis presented in this report underscores the intricate and evolving\nrelationship between Artificial Intelligence and the challenge of\ndisinformation. AI serves as a double-edged sword, both empowering malicious\nactors to create and disseminate sophisticated, coordinated, and adversarial\nmulti-modal disinformation campaigns, and providing the tools necessary to\ndetect and counter these threats. The increasing sophistication of AI-\ngenerated content across text, image, audio, and video formats, coupled with\nits ability to facilitate coordinated inauthentic behavior and personalized\ntargeting, presents a significant and growing challenge to information\nintegrity.\n\nHowever, the advancements in AI also offer a powerful arsenal of methodologies\nand tools for building resilience against disinformation. From NLP and machine\nlearning for text analysis to advanced techniques for detecting manipulated\nmedia and analyzing coordinated behavior, AI is proving to be an indispensable\nasset in the fight for truth in the digital age. Nevertheless, the limitations\nof AI in understanding nuanced language, its vulnerability to adversarial\nattacks, and the ever-present risk of algorithmic bias necessitate a cautious\nand ethical approach.\n\nThe future of combating disinformation lies in a holistic and adaptive\nstrategy that recognizes the crucial role of the human element. A synergistic\npartnership between increasingly sophisticated AI technologies and the\ncritical thinking, contextual understanding, and ethical judgment of human\nexperts and an informed public is essential. Furthermore, ongoing research and\ndevelopment in AI-driven detection methods, coupled with effective policy\nframeworks, comprehensive media and digital literacy education, and robust\ncollaboration among technology platforms, governments, and research\ninstitutions, will be critical in building a more resilient and trustworthy\ninformation ecosystem for the future. The path forward requires a continued\ncommitment to innovation, ethical responsibility, and a shared understanding\nof the complex interplay between technology and society in the ongoing battle\nagainst disinformation.\n\n#### Works cited\n\n  1. What Is a Disinformation Campaign? | CrowdStrike, accessed May 17, 2025, [https://www.crowdstrike.com/en-us/cybersecurity-101/social-engineering/disinformation-campaign/](https://www.crowdstrike.com/en-us/cybersecurity-101/social-engineering/disinformation-campaign/)\n\n  2. Navigating the Landscape of Misinformation and Disinformation: Background - New America, accessed May 17, 2025, [https://www.newamerica.org/future-security/reports/navigating-the-landscape-of-misinformation-and-disinformation/background/](https://www.newamerica.org/future-security/reports/navigating-the-landscape-of-misinformation-and-disinformation/background/)\n\n  3. Disinformation Meaning & Definition - Zevo Health, accessed May 17, 2025, [https://www.zevohealth.com/glossary/disinformation/](https://www.zevohealth.com/glossary/disinformation/)\n\n  4. pmc.ncbi.nlm.nih.gov, accessed May 17, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC10060790/#:~:text=Coordinated%20inauthentic%20behavior%20(CIB)%20is,across%20multiple%20social%20media%20platforms.](https://pmc.ncbi.nlm.nih.gov/articles/PMC10060790/#:~:text=Coordinated%20inauthentic%20behavior%20\\(CIB\\)%20is,across%20multiple%20social%20media%20platforms.)\n\n  5. Inauthentic Behavior | Transparency Center, accessed May 17, 2025, [https://transparency.meta.com/policies/community-standards/inauthentic-behavior/](https://transparency.meta.com/policies/community-standards/inauthentic-behavior/)\n\n  6. Coordinated Influence Operations\u2014 Fear, Uncertainty and Doubt | Bipartisan Policy Center, accessed May 17, 2025, [https://bipartisanpolicy.org/blog/coordinated-influence-operations/](https://bipartisanpolicy.org/blog/coordinated-influence-operations/)\n\n  7. Coordinated inauthentic behavior - Semantic interoperability for platform governance, accessed May 17, 2025, [https://platformglossary.info/coordinated-inauthentic-behavior/](https://platformglossary.info/coordinated-inauthentic-behavior/)\n\n  8. Understanding Coordinated Inauthentic Behavior (CIB): What it is and How it Impacts the General Public - Vicarius, accessed May 17, 2025, [https://www.vicarius.io/vsociety/posts/understanding-coordinated-inauthentic-behavior-cib-what-it-is-and-how-it-impacts-the-general-public](https://www.vicarius.io/vsociety/posts/understanding-coordinated-inauthentic-behavior-cib-what-it-is-and-how-it-impacts-the-general-public)\n\n  9. Disinformation attack - Wikipedia, accessed May 17, 2025, [https://en.wikipedia.org/wiki/Disinformation_attack](https://en.wikipedia.org/wiki/Disinformation_attack)\n\n  10. Winning in the Information Environment: Recent Successes in Combating Adversary Disinformation and Recommendations for the Future - Air University, accessed May 17, 2025, [https://www.airuniversity.af.edu/Wild-Blue-Yonder/Articles/Article-Display/Article/3630158/winning-in-the-information-environment-recent-successes-in-combating-adversary/](https://www.airuniversity.af.edu/Wild-Blue-Yonder/Articles/Article-Display/Article/3630158/winning-in-the-information-environment-recent-successes-in-combating-adversary/)\n\n  11. Don't be a target: How to identify adversarial propaganda > U.S. ..., accessed May 17, 2025, [https://www.cybercom.mil/Media/News/Article/3551070/dont-be-a-target-how-to-identify-adversarial-propaganda/](https://www.cybercom.mil/Media/News/Article/3551070/dont-be-a-target-how-to-identify-adversarial-propaganda/)\n\n  12. GAO-24-107600, FOREIGN DISINFORMATION: Defining and Detecting Threats, accessed May 17, 2025, [https://www.gao.gov/assets/gao-24-107600.pdf](https://www.gao.gov/assets/gao-24-107600.pdf)\n\n  13. FMNV: A Dataset of Media-Published News Videos for Fake News Detection - arXiv, accessed May 17, 2025, [https://arxiv.org/html/2504.07687v3](https://arxiv.org/html/2504.07687v3)\n\n  14. AI in Disinformation Detection - Applied Cybersecurity & Internet Governance, accessed May 17, 2025, [https://www.acigjournal.com/AI-in-Disinformation-Detection,200200,0,2.html](https://www.acigjournal.com/AI-in-Disinformation-Detection,200200,0,2.html)\n\n  15. Fighting fake news with multimodal AI - Almawave, accessed May 17, 2025, [https://www.almawave.com/en-fake-news/](https://www.almawave.com/en-fake-news/)\n\n  16. Factsheet 4: Types of Misinformation and Disinformation - UNHCR, accessed May 17, 2025, [https://www.unhcr.org/innovation/wp-content/uploads/2022/02/Factsheet-4.pdf](https://www.unhcr.org/innovation/wp-content/uploads/2022/02/Factsheet-4.pdf)\n\n  17. The evolving role of AI-generated media in shaping disinformation campaigns - DFRLab, accessed May 17, 2025, [https://dfrlab.org/2025/05/01/the-evolving-role-of-ai-generated-media-in-shaping-disinformation-campaigns/](https://dfrlab.org/2025/05/01/the-evolving-role-of-ai-generated-media-in-shaping-disinformation-campaigns/)\n\n  18. Science & Tech Spotlight: Combating Deepfakes | U.S. GAO, accessed May 17, 2025, [https://www.gao.gov/products/gao-24-107292](https://www.gao.gov/products/gao-24-107292)\n\n  19. Full article: A Picture Paints a Thousand Lies? The Effects and Mechanisms of Multimodal Disinformation and Rebuttals Disseminated via Social Media - Taylor & Francis Online, accessed May 17, 2025, [https://www.tandfonline.com/doi/full/10.1080/10584609.2019.1674979](https://www.tandfonline.com/doi/full/10.1080/10584609.2019.1674979)\n\n  20. Multi-modal Misinformation Detection: Approaches, Challenges and Opportunities - arXiv, accessed May 17, 2025, [https://arxiv.org/pdf/2203.13883](https://arxiv.org/pdf/2203.13883)\n\n  21. The Russian Disinformation Threat: Active Campaigns in 2024 - Kettering Foundation, accessed May 17, 2025, [https://kettering.org/the-russian-disinformation-threat-active-campaigns-in-2024/](https://kettering.org/the-russian-disinformation-threat-active-campaigns-in-2024/)\n\n  22. AI in disinformation detection - Applied Cybersecurity & Internet Governance, accessed May 17, 2025, [https://www.acigjournal.com/pdf-200200-124467?filename=AI%20in%20Disinformation.pdf](https://www.acigjournal.com/pdf-200200-124467?filename=AI+in+Disinformation.pdf)\n\n  23. AI and the Future of Disinformation Campaigns | Center for Security and Emerging Technology, accessed May 17, 2025, [https://cset.georgetown.edu/publication/ai-and-the-future-of-disinformation-campaigns-2/](https://cset.georgetown.edu/publication/ai-and-the-future-of-disinformation-campaigns-2/)\n\n  24. Don't be a target: How to identify adversarial propaganda - Air Force Reserve Command, accessed May 17, 2025, [https://www.afrc.af.mil/News/Article/3550266/dont-be-a-target-how-to-identify-adversarial-propaganda/](https://www.afrc.af.mil/News/Article/3550266/dont-be-a-target-how-to-identify-adversarial-propaganda/)\n\n  25. Adversarial Machine Learning in Detecting Inauthentic Behavior on Social Platforms, accessed May 17, 2025, [https://aithority.com/machine-learning/adversarial-machine-learning-in-detecting-inauthentic-behavior-on-social-platforms/](https://aithority.com/machine-learning/adversarial-machine-learning-in-detecting-inauthentic-behavior-on-social-platforms/)\n\n  26. 20240805-CIB-detection-tree.pdf - EU DisinfoLab, accessed May 17, 2025, [https://www.disinfo.eu/wp-content/uploads/2024/08/20240805-CIB-detection-tree.pdf](https://www.disinfo.eu/wp-content/uploads/2024/08/20240805-CIB-detection-tree.pdf)\n\n  27. AI and the spread of fake news sites: Experts explain how to counteract them, accessed May 17, 2025, [https://news.vt.edu/articles/2024/02/AI-generated-fake-news-experts.html](https://news.vt.edu/articles/2024/02/AI-generated-fake-news-experts.html)\n\n  28. The role of artificial intelligence in disinformation | Data & Policy | Cambridge Core, accessed May 17, 2025, [https://www.cambridge.org/core/journals/data-and-policy/article/role-of-artificial-intelligence-in-disinformation/7C4BF6CA35184F149143DE968FC4C3B6](https://www.cambridge.org/core/journals/data-and-policy/article/role-of-artificial-intelligence-in-disinformation/7C4BF6CA35184F149143DE968FC4C3B6)\n\n  29. Audio Deepfake Detection: What Has Been Achieved and What Lies Ahead - MDPI, accessed May 17, 2025, [https://www.mdpi.com/1424-8220/25/7/1989](https://www.mdpi.com/1424-8220/25/7/1989)\n\n  30. How a Spanish media group created an AI tool to detect audio deepfakes to help journalists in a big election year | Reuters Institute for the Study of Journalism, accessed May 17, 2025, [https://reutersinstitute.politics.ox.ac.uk/news/how-spanish-media-group-created-ai-tool-detect-audio-deepfakes-help-journalists-big-election](https://reutersinstitute.politics.ox.ac.uk/news/how-spanish-media-group-created-ai-tool-detect-audio-deepfakes-help-journalists-big-election)\n\n  31. How AI-generated disinformation might impact this year's elections and how journalists should report on it | Reuters Institute for the Study of Journalism, accessed May 17, 2025, [https://reutersinstitute.politics.ox.ac.uk/news/how-ai-generated-disinformation-might-impact-years-elections-and-how-journalists-should-report](https://reutersinstitute.politics.ox.ac.uk/news/how-ai-generated-disinformation-might-impact-years-elections-and-how-journalists-should-report)\n\n  32. On the Trail of Deepfakes, Drexel Researchers Identify 'Fingerprints' of AI-Generated Video, accessed May 17, 2025, [https://drexel.edu/news/archive/2024/April/machine-learning-generative-ai-video-detection](https://drexel.edu/news/archive/2024/April/machine-learning-generative-ai-video-detection)\n\n  33. Decoding Disinformation: Automating the Detection of Coordinated, accessed May 17, 2025, [https://jerrygaolondon.substack.com/p/decoding-disinformation-automating](https://jerrygaolondon.substack.com/p/decoding-disinformation-automating)\n\n  34. www.cisa.gov, accessed May 17, 2025, [https://www.cisa.gov/sites/default/files/publications/tactics-of-disinformation_508.pdf](https://www.cisa.gov/sites/default/files/publications/tactics-of-disinformation_508.pdf)\n\n  35. Countering AI-powered disinformation through national regulation: learning from the case of Ukraine - Frontiers, accessed May 17, 2025, [https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1474034/full](https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1474034/full)\n\n  36. Using Responsible AI to combat misinformation - Trilateral Research, accessed May 17, 2025, [https://trilateralresearch.com/responsible-ai/using-responsible-ai-to-combat-misinformation](https://trilateralresearch.com/responsible-ai/using-responsible-ai-to-combat-misinformation)\n\n  37. GenAI and the battle against misinformation - Duke Corporate Education, accessed May 17, 2025, [https://www.dukece.com/insights/genai_and_the_battle_against_misinformation/](https://www.dukece.com/insights/genai_and_the_battle_against_misinformation/)\n\n  38. The use of artificial intelligence in counter-disinformation: a world wide (web) mapping, accessed May 17, 2025, [https://www.frontiersin.org/journals/political-science/articles/10.3389/fpos.2025.1517726/full](https://www.frontiersin.org/journals/political-science/articles/10.3389/fpos.2025.1517726/full)\n\n  39. Application of Artificial Intelligence Techniques to Detect Fake News: A Review - MDPI, accessed May 17, 2025, [https://www.mdpi.com/2079-9292/12/24/5041](https://www.mdpi.com/2079-9292/12/24/5041)\n\n  40. A comparison of artificial intelligence models used for fake news detection - The Distant Reader, accessed May 17, 2025, [https://distantreader.org/stacks/journals/bulletin/bulletin-1680.pdf](https://distantreader.org/stacks/journals/bulletin/bulletin-1680.pdf)\n\n  41. How to Fight AI-Generated Fake News \u2014 With AI | Built In, accessed May 17, 2025, [https://builtin.com/artificial-intelligence/fight-ai-generated-fake-news](https://builtin.com/artificial-intelligence/fight-ai-generated-fake-news)\n\n  42. Enhancing Disinformation Detection with Explainable AI and Named Entity Replacement, accessed May 17, 2025, [https://arxiv.org/html/2502.04863v1](https://arxiv.org/html/2502.04863v1)\n\n  43. New tools use AI 'fingerprints' to detect altered photos, videos - Binghamton News, accessed May 17, 2025, [https://www.binghamton.edu/news/story/5109/new-tools-use-ai-fingerprints-to-detect-altered-photos-videos](https://www.binghamton.edu/news/story/5109/new-tools-use-ai-fingerprints-to-detect-altered-photos-videos)\n\n  44. AI in the Role of Combating Misinformation | Pindrop, accessed May 17, 2025, [https://www.pindrop.com/article/ai-in-the-role-of-combating-misinformation/](https://www.pindrop.com/article/ai-in-the-role-of-combating-misinformation/)\n\n  45. Deepfake Detection Technology - Pindrop, accessed May 17, 2025, [https://www.pindrop.com/solution/deepfake-detection/](https://www.pindrop.com/solution/deepfake-detection/)\n\n  46. Detecting Influence Campaigns on X with AI and Network Science - USC Viterbi, accessed May 17, 2025, [https://viterbischool.usc.edu/news/2024/05/detecting-influence-campaigns-on-x-with-ai-and-network-science/](https://viterbischool.usc.edu/news/2024/05/detecting-influence-campaigns-on-x-with-ai-and-network-science/)\n\n  47. A new AI early warning system to combat disinformation and prevent violence previewed in the Bulletin of Atomic Scientists - Kroc Institute for International Peace Studies, accessed May 17, 2025, [https://kroc.nd.edu/news-events/news/a-new-ai-early-warning-system-to-combat-disinformation-and-prevent-violence-previewed-in-the-bulletin-of-atomic-scientists/](https://kroc.nd.edu/news-events/news/a-new-ai-early-warning-system-to-combat-disinformation-and-prevent-violence-previewed-in-the-bulletin-of-atomic-scientists/)\n\n  48. Detection of fake news campaigns using graph convolutional networks | palowise.ai, accessed May 17, 2025, [https://www.palowise.ai/blog/palowise-papers/detection-of-fake-news-campaigns-using-graph-convolutional-networks/](https://www.palowise.ai/blog/palowise-papers/detection-of-fake-news-campaigns-using-graph-convolutional-networks/)\n\n  49. How AI-Powered Fact-Checking Can Help Combat Misinformation | Ivy Exec, accessed May 17, 2025, [https://ivyexec.com/career-advice/2025/how-ai-powered-fact-checking-can-help-combat-misinformation](https://ivyexec.com/career-advice/2025/how-ai-powered-fact-checking-can-help-combat-misinformation)\n\n  50. Norwegian start-up Factiverse to revolutionize fact-checking with AI - Hello Future, accessed May 17, 2025, [https://hellofuture.orange.com/en/factiverse-reliable-ai-fact-checking-in-more-than-100-languages/](https://hellofuture.orange.com/en/factiverse-reliable-ai-fact-checking-in-more-than-100-languages/)\n\n  51. Full Fact AI, accessed May 17, 2025, [https://fullfact.org/ai/](https://fullfact.org/ai/)\n\n  52. Fact-checking AI with Lateral Reading - Using AI tools in Research - Research Guides at Texas A&M University-Corpus Christi, accessed May 17, 2025, [https://guides.library.tamucc.edu/AI/lateralreadingAI](https://guides.library.tamucc.edu/AI/lateralreadingAI)\n\n  53. ClaimBuster: Automated Live Fact-Checking - IDIR Lab, accessed May 17, 2025, [https://idir.uta.edu/claimbuster/](https://idir.uta.edu/claimbuster/)\n\n  54. 13 AI-Powered Tools for Fighting Fake News - The Trusted Web, accessed May 17, 2025, [https://thetrustedweb.org/ai-powered-tools-for-fighting-fake-news/](https://thetrustedweb.org/ai-powered-tools-for-fighting-fake-news/)\n\n  55. Fact-based Counter Narrative Generation to Combat Hate Speech | OpenReview, accessed May 17, 2025, [https://openreview.net/forum?id=GrvxqI3XL4&referrer=%5Bthe%20profile%20of%20Suman%20Kalyan%20Maity%5D(%2Fprofile%3Fid%3D~Suman_Kalyan_Maity2)](https://openreview.net/forum?id=GrvxqI3XL4&referrer=%5Bthe+profile+of+Suman+Kalyan+Maity%5D\\(/profile?id%3D~Suman_Kalyan_Maity2\\))\n\n  56. Counter-narratives: paradigm shift in the fight against hate and fake-news - FBK Magazine, accessed May 17, 2025, [https://magazine.fbk.eu/en/news/counter-narratives-paradigm-shift-in-the-fight-against-hate-and-fake-news/](https://magazine.fbk.eu/en/news/counter-narratives-paradigm-shift-in-the-fight-against-hate-and-fake-news/)\n\n  57. MIT study: An AI chatbot can reduce belief in conspiracy theories, accessed May 17, 2025, [https://mitsloan.mit.edu/ideas-made-to-matter/mit-study-ai-chatbot-can-reduce-belief-conspiracy-theories](https://mitsloan.mit.edu/ideas-made-to-matter/mit-study-ai-chatbot-can-reduce-belief-conspiracy-theories)\n\n  58. CISOs Urged to Prepare for Evolving Disinformation Tactics - Nexus Connect, accessed May 17, 2025, [https://nexusconnect.io/articles/cisos-urged-to-prepare-for-evolving-disinformation-tactics](https://nexusconnect.io/articles/cisos-urged-to-prepare-for-evolving-disinformation-tactics)\n\n  59. Artificial Intelligence and Disinformation in - Brill, accessed May 17, 2025, [https://brill.com/view/journals/shrs/29/1-4/article-p55_55.xml](https://brill.com/view/journals/shrs/29/1-4/article-p55_55.xml)\n\n  60. How to detect Fake News with AI | Founderz, accessed May 17, 2025, [https://founderz.com/blog/detecting-fake-news-with-ai/](https://founderz.com/blog/detecting-fake-news-with-ai/)\n\n  61. The Benefits and Risks of AI in Content Moderation | Datafloq, accessed May 17, 2025, [https://datafloq.com/read/benefits-risks-ai-content-moderation/](https://datafloq.com/read/benefits-risks-ai-content-moderation/)\n\n  62. Content Moderation - Mozilla Foundation, accessed May 17, 2025, [https://foundation.mozilla.org/en/campaigns/trained-for-deception-how-artificial-intelligence-fuels-online-disinformation/content-moderation/](https://foundation.mozilla.org/en/campaigns/trained-for-deception-how-artificial-intelligence-fuels-online-disinformation/content-moderation/)\n\n  63. Biases in Artificial Intelligence: How to Detect and Reduce Bias in AI Models - Onix-Systems, accessed May 17, 2025, [https://onix-systems.com/blog/ai-bias-detection-and-mitigation](https://onix-systems.com/blog/ai-bias-detection-and-mitigation)\n\n  64. FYS 101: Algorithmic Bias and Misinformation - Research Guides - Syracuse University, accessed May 17, 2025, [https://researchguides.library.syr.edu/c.php?g=1092612&p=9865553](https://researchguides.library.syr.edu/c.php?g=1092612&p=9865553)\n\n  65. What Is AI Bias? | IBM, accessed May 17, 2025, [https://www.ibm.com/think/topics/ai-bias](https://www.ibm.com/think/topics/ai-bias)\n\n  66. The Intersection of AI, Fake News, and Racial Bias - Business Wire, accessed May 17, 2025, [https://www.businesswire.com/blog/ai-fake-news-racial-bias](https://www.businesswire.com/blog/ai-fake-news-racial-bias)\n\n  67. When AI Gets It Wrong: Addressing AI Hallucinations and Bias, accessed May 17, 2025, [https://mitsloanedtech.mit.edu/ai/basics/addressing-ai-hallucinations-and-bias/](https://mitsloanedtech.mit.edu/ai/basics/addressing-ai-hallucinations-and-bias/)\n\n  68. The Limitations of Automated Tools in Content Moderation - New America, accessed May 17, 2025, [https://www.newamerica.org/oti/reports/everything-moderation-analysis-how-internet-platforms-are-using-artificial-intelligence-moderate-user-generated-content/the-limitations-of-automated-tools-in-content-moderation/](https://www.newamerica.org/oti/reports/everything-moderation-analysis-how-internet-platforms-are-using-artificial-intelligence-moderate-user-generated-content/the-limitations-of-automated-tools-in-content-moderation/)\n\n  69. Adversarial Attacks: The Hidden Risk in AI Security, accessed May 17, 2025, [https://securing.ai/ai-security/adversarial-attacks-ai/](https://securing.ai/ai-security/adversarial-attacks-ai/)\n\n  70. 6 Key Adversarial Attacks and Their Consequences - Mindgard AI, accessed May 17, 2025, [https://mindgard.ai/blog/ai-under-attack-six-key-adversarial-attacks-and-their-consequences](https://mindgard.ai/blog/ai-under-attack-six-key-adversarial-attacks-and-their-consequences)\n\n  71. The Threat of Adversarial AI - Wiz, accessed May 17, 2025, [https://www.wiz.io/academy/adversarial-ai-machine-learning](https://www.wiz.io/academy/adversarial-ai-machine-learning)\n\n  72. How do AI attacks impact people, organizations, and society? - AIShield, accessed May 17, 2025, [https://boschaishield.com/resources/blog/how-do-ai-attacks-impact-people-organizations-and-society/](https://boschaishield.com/resources/blog/how-do-ai-attacks-impact-people-organizations-and-society/)\n\n  73. What Is Adversarial AI in Machine Learning? - Palo Alto Networks, accessed May 17, 2025, [https://www.paloaltonetworks.com/cyberpedia/what-are-adversarial-attacks-on-AI-Machine-Learning](https://www.paloaltonetworks.com/cyberpedia/what-are-adversarial-attacks-on-AI-Machine-Learning)\n\n  74. What is Adversarial AI? Uncovering the Risks and Strategies to Mitigate | FPT Software, accessed May 17, 2025, [https://fptsoftware.com/resource-center/blogs/what-is-adversarial-ai-uncovering-the-risks-and-strategies-to-mitigate](https://fptsoftware.com/resource-center/blogs/what-is-adversarial-ai-uncovering-the-risks-and-strategies-to-mitigate)\n\n  75. Adversarial Attacks on AI-Generated Text Detection Models: A Token Probability-Based Approach Using Embeddings - arXiv, accessed May 17, 2025, [https://arxiv.org/html/2501.18998v2](https://arxiv.org/html/2501.18998v2)\n\n  76. XAI-Based Detection of Adversarial Attacks on Deepfake Detectors - OpenReview, accessed May 17, 2025, [https://openreview.net/forum?id=7pBKrcn199](https://openreview.net/forum?id=7pBKrcn199)\n\n  77. Fake It Until You Break It: On the Adversarial Robustness of AI-generated Image Detectors - arXiv, accessed May 17, 2025, [https://arxiv.org/html/2410.01574v2](https://arxiv.org/html/2410.01574v2)\n\n  78. XAI-Based Detection of Adversarial Attacks on Deepfake Detectors - arXiv, accessed May 17, 2025, [https://arxiv.org/html/2403.02955v2](https://arxiv.org/html/2403.02955v2)\n\n  79. Deepfake detectors don't work in the real world - Information Age | ACS, accessed May 17, 2025, [https://ia.acs.org.au/article/2025/deepfake-detectors-don-t-work-in-the-real-world.html](https://ia.acs.org.au/article/2025/deepfake-detectors-don-t-work-in-the-real-world.html)\n\n  80. [2502.10920] Do Deepfake Detectors Work in Reality? - arXiv, accessed May 17, 2025, [https://arxiv.org/abs/2502.10920](https://arxiv.org/abs/2502.10920)\n\n  81. 'Garbage in, garbage out': AI fails to debunk disinformation, study finds - VOA, accessed May 17, 2025, [https://www.voanews.com/a/garbage-in-garbage-out-ai-fails-to-debunk-disinformation-study-finds/7830414.html](https://www.voanews.com/a/garbage-in-garbage-out-ai-fails-to-debunk-disinformation-study-finds/7830414.html)\n\n  82. What is disinformation? - Bundesregierung, accessed May 17, 2025, [https://www.bundesregierung.de/breg-de/service/datenschutzhinweis/disinformation-definition-1911048](https://www.bundesregierung.de/breg-de/service/datenschutzhinweis/disinformation-definition-1911048)\n\n  83. AI and Content Moderation - Chase India, accessed May 17, 2025, [https://www.chase-india.com/media/faengjxy/ai-and-content-moderation.pdf](https://www.chase-india.com/media/faengjxy/ai-and-content-moderation.pdf)\n\n  84. The Role Of Humans And AI In Social Media's Battle Against Misinformation - Forbes, accessed May 17, 2025, [https://www.forbes.com/councils/forbestechcouncil/2024/02/12/the-role-of-humans-and-ai-in-social-medias-battle-against-misinformation/](https://www.forbes.com/councils/forbestechcouncil/2024/02/12/the-role-of-humans-and-ai-in-social-medias-battle-against-misinformation/)\n\n  85. AI in content moderation : all you need to know - iPleaders, accessed May 17, 2025, [https://blog.ipleaders.in/ai-in-content-moderation-all-you-need-to-know/](https://blog.ipleaders.in/ai-in-content-moderation-all-you-need-to-know/)\n\n  86. The Role of Explainability in Collaborative Human-AI Disinformation Detection - ACM FAccT, accessed May 17, 2025, [https://facctconference.org/static/papers24/facct24-146.pdf](https://facctconference.org/static/papers24/facct24-146.pdf)\n\n  87. The Dual Nature of AI in Information Dissemination: Ethical Considerations - PMC - PubMed Central, accessed May 17, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC11522648/](https://pmc.ncbi.nlm.nih.gov/articles/PMC11522648/)\n\n  88. Policy Brief - Ensuring Ethical AI Practices to counter Disinformation - Media Futures, accessed May 17, 2025, [https://mediafutures.eu/wp-content/uploads/2023/09/MediaFutures_Policy-Briefs_Ensuring-Ethical-AI-Practices-to-counter-Disinformation.pdf](https://mediafutures.eu/wp-content/uploads/2023/09/MediaFutures_Policy-Briefs_Ensuring-Ethical-AI-Practices-to-counter-Disinformation.pdf)\n\n  89. AI Misinformation: Concerns and Prevention Methods - GlobalSign, accessed May 17, 2025, [https://www.globalsign.com/en/blog/ai-misinformation-concerns-and-prevention](https://www.globalsign.com/en/blog/ai-misinformation-concerns-and-prevention)\n\n  90. Regulating disinformation with artificial intelligence - European Parliament, accessed May 17, 2025, [https://www.europarl.europa.eu/RegData/etudes/STUD/2019/624279/EPRS_STU(2019)624279_EN.pdf](https://www.europarl.europa.eu/RegData/etudes/STUD/2019/624279/EPRS_STU\\(2019\\)624279_EN.pdf)\n\n  91. Countering AI-powered disinformation through national regulation: learning from the case of Ukraine - PMC - PubMed Central, accessed May 17, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC11747593/](https://pmc.ncbi.nlm.nih.gov/articles/PMC11747593/)\n\n  92. Content Moderation Challenges : Fusion CX Services, accessed May 17, 2025, [https://www.fusioncx.com/blog/content-moderation/content-moderation-challenges/](https://www.fusioncx.com/blog/content-moderation/content-moderation-challenges/)\n\n  93. Content Moderation in a New Era for AI and Automation | Oversight Board, accessed May 17, 2025, [https://www.oversightboard.com/news/content-moderation-in-a-new-era-for-ai-and-automation/](https://www.oversightboard.com/news/content-moderation-in-a-new-era-for-ai-and-automation/)\n\n  94. AI and Misinformation - 2024 Dean's Report, accessed May 17, 2025, [https://2024.jou.ufl.edu/page/ai-and-misinformation](https://2024.jou.ufl.edu/page/ai-and-misinformation)\n\n  95. Disinformation Countermeasures and Artificial Intelligence - Frontiers, accessed May 17, 2025, [https://www.frontiersin.org/research-topics/58930/disinformation-countermeasures-and-artificial-intelligence](https://www.frontiersin.org/research-topics/58930/disinformation-countermeasures-and-artificial-intelligence)\n\n  96. Exploring How to Build Community-Level Resilience Against Disinformation - PEN America, accessed May 17, 2025, [https://pen.org/report/how-to-build-community-level-resilience-against-disinformation/](https://pen.org/report/how-to-build-community-level-resilience-against-disinformation/)\n\n  97. The Science of Disinformation: Cognitive Vulnerabilities and Digital Manipulation, accessed May 17, 2025, [https://moderndiplomacy.eu/2025/02/09/the-science-of-disinformation-cognitive-vulnerabilities-and-digital-manipulation/](https://moderndiplomacy.eu/2025/02/09/the-science-of-disinformation-cognitive-vulnerabilities-and-digital-manipulation/)\n\n  98. Building Resilience to Misinformation: An Instructional Toolkit: Glossary - Research Guides, accessed May 17, 2025, [https://libguides.ucalgary.ca/c.php?g=731350&p=5264938](https://libguides.ucalgary.ca/c.php?g=731350&p=5264938)\n\n  99. How AI can also be used to combat online disinformation - The World Economic Forum, accessed May 17, 2025, [https://www.weforum.org/stories/2024/06/ai-combat-online-misinformation-disinformation/](https://www.weforum.org/stories/2024/06/ai-combat-online-misinformation-disinformation/)\n\n  100. The Case for News Literacy Skills in an AI World | AASA, accessed May 17, 2025, [https://www.aasa.org/resources/resource/the-case-for-news-literacy-skills-in-an-ai-world](https://www.aasa.org/resources/resource/the-case-for-news-literacy-skills-in-an-ai-world)\n\n  101. Helping Students Spot Misinformation Online | NEA - National Education Association, accessed May 17, 2025, [https://www.nea.org/nea-today/all-news-articles/helping-students-spot-misinformation-online](https://www.nea.org/nea-today/all-news-articles/helping-students-spot-misinformation-online)\n\n  102. Enhancing media literacy skills in the age of AI - eSchool News, accessed May 17, 2025, [https://www.eschoolnews.com/innovative-teaching/2024/11/08/enhancing-media-literacy-skills-in-the-age-of-ai/](https://www.eschoolnews.com/innovative-teaching/2024/11/08/enhancing-media-literacy-skills-in-the-age-of-ai/)\n\n  103. Media Literacy Education and AI | Harvard Graduate School of Education, accessed May 17, 2025, [https://www.gse.harvard.edu/ideas/education-now/24/04/media-literacy-education-and-ai](https://www.gse.harvard.edu/ideas/education-now/24/04/media-literacy-education-and-ai)\n\n  104. Tackling disinformation and promoting digital literacy - European Union - Learning Corner, accessed May 17, 2025, [https://learning-corner.learning.europa.eu/learning-materials/tackling-disinformation-and-promoting-digital-literacy_en](https://learning-corner.learning.europa.eu/learning-materials/tackling-disinformation-and-promoting-digital-literacy_en)\n\n  105. How to teach students critical thinking skills to combat misinformation online, accessed May 17, 2025, [https://www.apa.org/monitor/2024/09/media-literacy-misinformation](https://www.apa.org/monitor/2024/09/media-literacy-misinformation)\n\n  106. The Importance of Media Literacy In Countering Disinformation - EDMO, accessed May 17, 2025, [https://edmo.eu/areas-of-activities/media-literacy/the-importance-of-media-literacy-in-countering-disinformation/](https://edmo.eu/areas-of-activities/media-literacy/the-importance-of-media-literacy-in-countering-disinformation/)\n\n  107. CounterCloud - AI powered disinformation experiment - Futurist.com, accessed May 17, 2025, [https://futurist.com/2023/10/29/countercloud-ai-powered-disinformation-experiment/](https://futurist.com/2023/10/29/countercloud-ai-powered-disinformation-experiment/)\n\n  108. Design of AI Applications to Counter Disinformation - UMass Boston, accessed May 17, 2025, [https://www.umb.edu/news/recent-news/design-ai-applications-counter-disinformation/](https://www.umb.edu/news/recent-news/design-ai-applications-counter-disinformation/)\n\n  109. How to spot AI fake news \u2013 and what policymakers can do to help | USC Price, accessed May 17, 2025, [https://priceschool.usc.edu/news/ai-election-disinformation-biden-california-europe/](https://priceschool.usc.edu/news/ai-election-disinformation-biden-california-europe/)\n\n  110. Regulating AI Deepfakes and Synthetic Media in the Political Arena, accessed May 17, 2025, [https://www.brennancenter.org/our-work/research-reports/regulating-ai-deepfakes-and-synthetic-media-political-arena](https://www.brennancenter.org/our-work/research-reports/regulating-ai-deepfakes-and-synthetic-media-political-arena)\n\n  111. Countering Disinformation Effectively: An Evidence-Based Policy Guide, accessed May 17, 2025, [https://carnegieendowment.org/research/2024/01/countering-disinformation-effectively-an-evidence-based-policy-guide](https://carnegieendowment.org/research/2024/01/countering-disinformation-effectively-an-evidence-based-policy-guide)\n\n  112. Challenging misinformation in the age of AI: Building a collaborative future, accessed May 17, 2025, [https://allianceforscience.org/blog/2025/03/challenging-misinformation-in-the-age-of-ai-building-a-collaborative-future/](https://allianceforscience.org/blog/2025/03/challenging-misinformation-in-the-age-of-ai-building-a-collaborative-future/)\n\n  113. AI Startups and the Fight Against Mis/Disinformation Online: An Update, accessed May 17, 2025, [https://www.gmfus.org/news/ai-startups-and-fight-against-misdisinformation-online-update](https://www.gmfus.org/news/ai-startups-and-fight-against-misdisinformation-online-update)\n\n  114. 5 AI Trends Shaping the Future of Public Sector in 2025 | Google Cloud Blog, accessed May 17, 2025, [https://cloud.google.com/blog/topics/public-sector/5-ai-trends-shaping-the-future-of-the-public-sector-in-2025](https://cloud.google.com/blog/topics/public-sector/5-ai-trends-shaping-the-future-of-the-public-sector-in-2025)\n\n  115. LLM-Enhanced multimodal detection of fake news | PLOS One, accessed May 17, 2025, [https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0312240](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0312240)\n\n  116. Multimodal Learning In AI: Introduction, Current Trends, and Future - Scribble Data, accessed May 17, 2025, [https://www.scribbledata.io/blog/multimodal-learning-in-ai-introduction-current-trends-and-future/](https://www.scribbledata.io/blog/multimodal-learning-in-ai-introduction-current-trends-and-future/)\n\n  117. Reinforced Adaptive Knowledge Learning for Multimodal Fake News Detection, accessed May 17, 2025, [https://ojs.aaai.org/index.php/AAAI/article/view/29618/31048](https://ojs.aaai.org/index.php/AAAI/article/view/29618/31048)\n\n  118. AnyGPT: The Next Generation of Multimodal Large-Scale Language Models Integrating Image, Speech, and Text | AI-SCHOLAR, accessed May 17, 2025, [https://ai-scholar.tech/en/articles/large-language-models/anygpt](https://ai-scholar.tech/en/articles/large-language-models/anygpt)\n\n  119. Multimodal AI: Everything You Need to Know - DataStax, accessed May 17, 2025, [https://www.datastax.com/guides/multimodal-ai](https://www.datastax.com/guides/multimodal-ai)\n\n  120. Challenges and Safeguards against AI-Generated Disinformation - Hoover Institution, accessed May 17, 2025, [https://www.hoover.org/challenges-and-safeguards-against-ai-generated-disinformation](https://www.hoover.org/challenges-and-safeguards-against-ai-generated-disinformation)\n\n  121. Revolutionizing Investigations: The Impact of AI in Digital Forensics, accessed May 17, 2025, [https://www.cyberdefensemagazine.com/revolutionizing-investigations-the-impact-of-ai-in-digital-forensics/](https://www.cyberdefensemagazine.com/revolutionizing-investigations-the-impact-of-ai-in-digital-forensics/)\n\n  122. Keeping Pace with Rapid Advances in Generative Artificial Intelligence - UL Research Institutes, accessed May 17, 2025, [https://ul.org/news/keeping-pace-with-rapid-advances-in-generative-artificial-intelligence/](https://ul.org/news/keeping-pace-with-rapid-advances-in-generative-artificial-intelligence/)\n\n  123. Call for Papers: Special Issue on Unveiling Truth: Exploring the Frontier of AI and ML in Multimedia Forensics, accessed May 17, 2025, [https://www.computer.org/digital-library/magazines/mu/cfp-unveiling-frontier-ai-mm-forensics](https://www.computer.org/digital-library/magazines/mu/cfp-unveiling-frontier-ai-mm-forensics)\n\n  124. MediFor: Media Forensics - DARPA, accessed May 17, 2025, [https://www.darpa.mil/research/programs/media-forensics](https://www.darpa.mil/research/programs/media-forensics)\n\n  125. About The National Center for Media Forensics - College of Arts & Media - CU Denver, accessed May 17, 2025, [https://artsandmedia.ucdenver.edu/cam-areas-of-study/national-center-for-media-forensics/about-the-national-center-for-media-forensics](https://artsandmedia.ucdenver.edu/cam-areas-of-study/national-center-for-media-forensics/about-the-national-center-for-media-forensics)\n\n  126. Media Forensics Hub - Clemson University, accessed May 17, 2025, [https://www.clemson.edu/centers-institutes/watt/hub/](https://www.clemson.edu/centers-institutes/watt/hub/)\n\n  127. How AI Quakes the Digital Forensics Landscape \u2013 Cyber - University of Hawaii-West Oahu, accessed May 17, 2025, [https://westoahu.hawaii.edu/cyber/forensics-weekly-executive-summmaries/how-ai-quakes-the-digital-forensics-landscape/](https://westoahu.hawaii.edu/cyber/forensics-weekly-executive-summmaries/how-ai-quakes-the-digital-forensics-landscape/)\n\n  128. Artificial Intelligence in Social Media Forensics: A Comprehensive Survey and Analysis, accessed May 17, 2025, [https://www.mdpi.com/2079-9292/13/9/1671](https://www.mdpi.com/2079-9292/13/9/1671)\n\n  129. (PDF) Artificial Intelligence in Social Media Forensics: A Comprehensive Survey and Analysis - ResearchGate, accessed May 17, 2025, [https://www.researchgate.net/publication/380147461_Artificial_Intelligence_in_Social_Media_Forensics_A_Comprehensive_Survey_and_Analysis](https://www.researchgate.net/publication/380147461_Artificial_Intelligence_in_Social_Media_Forensics_A_Comprehensive_Survey_and_Analysis)\n\n  130. Digital Forensics: The Good, the Bad, and the AI-Generated - ACEDS, accessed May 17, 2025, [https://aceds.org/digital-forensics-the-good-the-bad-and-the-ai-generated-aceds-blog/](https://aceds.org/digital-forensics-the-good-the-bad-and-the-ai-generated-aceds-blog/)\n\n  131. Key Trends in Digital Forensics for 2025: Technological Innovation and Core Challenges, accessed May 17, 2025, [https://www.salvationdata.com/knowledge/key-trends-in-digital-forensics-for-2025/](https://www.salvationdata.com/knowledge/key-trends-in-digital-forensics-for-2025/)\n\n  132. CEO Lee Reiber: The Digital Forensics Landscape in 2025 - What Lies Ahead?, accessed May 17, 2025, [https://www.oxygenforensics.com/en/resources/digital-forensics-trends-2025/](https://www.oxygenforensics.com/en/resources/digital-forensics-trends-2025/)\n\n  133. Future Trends in AI and Digital Forensics - ResearchGate, accessed May 17, 2025, [https://www.researchgate.net/publication/387692303_Future_Trends_in_AI_and_Digital_Forensics](https://www.researchgate.net/publication/387692303_Future_Trends_in_AI_and_Digital_Forensics)\n\n  134. Enhancing, not replacing, human expertise with AI - Magnet Forensics, accessed May 17, 2025, [https://www.magnetforensics.com/blog/enhancing-not-replacing-human-expertise-with-ai-in-digital-forensics/](https://www.magnetforensics.com/blog/enhancing-not-replacing-human-expertise-with-ai-in-digital-forensics/)\n\n  135. Digital Forensics Trends for 2025 - Exterro, accessed May 17, 2025, [https://www.exterro.com/resources/white-papers/digital-forensics-trends-for-2025](https://www.exterro.com/resources/white-papers/digital-forensics-trends-for-2025)\n\n  136. Future Trends in AI and Digital Forensics - IGI Global, accessed May 17, 2025, [https://www.igi-global.com/chapter/future-trends-in-ai-and-digital-forensics/367321](https://www.igi-global.com/chapter/future-trends-in-ai-and-digital-forensics/367321)\n\n  137. AI-Driven Digital Forensics: Market Trends, Technologies, and Competition - KBV Research, accessed May 17, 2025, [https://www.kbvresearch.com/blog/ai-driven-digital-forensics/](https://www.kbvresearch.com/blog/ai-driven-digital-forensics/)\n\n  138. The Future Of Digital Forensics: Trends And Technologies - Brandefense, accessed May 17, 2025, [https://brandefense.io/blog/drps/the-future-of-digital-forensics-trends-and-technologies/](https://brandefense.io/blog/drps/the-future-of-digital-forensics-trends-and-technologies/)\n\n  139. Human-AI Cooperation to Tackle Misinformation and Polarization, accessed May 17, 2025, [https://cacm.acm.org/research/human-ai-cooperation-to-tackle-misinformation-and-polarization/](https://cacm.acm.org/research/human-ai-cooperation-to-tackle-misinformation-and-polarization/)\n\n  140. Exploring Multidimensional Checkworthiness: Designing AI-assisted Claim Prioritization for Human Fact-checkers - arXiv, accessed May 17, 2025, [https://arxiv.org/html/2412.08185v2](https://arxiv.org/html/2412.08185v2)\n\n  141. EMERGING TECHNOLOGIES AND AUTOMATED FACT-CHECKING: TOOLS, TECHNIQUES AND ALGORITHMS - Edam, accessed May 17, 2025, [https://edam.org.tr/Uploads/Yukleme_Resim/pdf-28-08-2023-23-40-14.pdf](https://edam.org.tr/Uploads/Yukleme_Resim/pdf-28-08-2023-23-40-14.pdf)\n\n  142. How Generative AI Is Helping Fact-Checkers Flag Election Disinformation, But Is Less Useful in the Global South, accessed May 17, 2025, [https://gijn.org/stories/how-generative-ai-helps-fact-checkers/](https://gijn.org/stories/how-generative-ai-helps-fact-checkers/)\n\n  143. \"Fact-checking\" fact checkers: A data-driven approach | HKS Misinformation Review, accessed May 17, 2025, [https://misinforeview.hks.harvard.edu/article/fact-checking-fact-checkers-a-data-driven-approach/](https://misinforeview.hks.harvard.edu/article/fact-checking-fact-checkers-a-data-driven-approach/)\n\n  144. Due Diligence: Disinformation, AI and the Charitable Landscape in 2025 | NPTrust, accessed May 17, 2025, [https://www.nptrust.org/philanthropic-resources/philanthropist/due-diligence-disinformation-ai-and-the-charitable-landscape-in-2025/](https://www.nptrust.org/philanthropic-resources/philanthropist/due-diligence-disinformation-ai-and-the-charitable-landscape-in-2025/)\n\n  145. (PDF) Artificial intelligence in the battle against disinformation and misinformation: a systematic review of challenges and approaches - ResearchGate, accessed May 17, 2025, [https://www.researchgate.net/publication/388421309_Artificial_intelligence_in_the_battle_against_disinformation_and_misinformation_a_systematic_review_of_challenges_and_approaches](https://www.researchgate.net/publication/388421309_Artificial_intelligence_in_the_battle_against_disinformation_and_misinformation_a_systematic_review_of_challenges_and_approaches)\n\n  146. Putting AI to work in the fight against disinformation | EBU Technology & Innovation, accessed May 17, 2025, [https://tech.ebu.ch/news/2023/12/putting-ai-to-work-in-the-fight-against-disinformation](https://tech.ebu.ch/news/2023/12/putting-ai-to-work-in-the-fight-against-disinformation)\n\n  147. Human-AI Collaboration Investigating Social Media Disinformation, accessed May 17, 2025, [https://cyberinitiative.org/research/funded-projects/2021-curbing-disinformation/ai-investigating-social-media-disinformation.html](https://cyberinitiative.org/research/funded-projects/2021-curbing-disinformation/ai-investigating-social-media-disinformation.html)\n\n  148. AI and the Future of Disinformation Campaigns | Center for Security and Emerging Technology, accessed May 17, 2025, [https://cset.georgetown.edu/publication/ai-and-the-future-of-disinformation-campaigns/](https://cset.georgetown.edu/publication/ai-and-the-future-of-disinformation-campaigns/)\n\n  149. MiRAGeNews: Multimodal Realistic AI-Generated News Detection - arXiv, accessed May 17, 2025, [https://arxiv.org/html/2410.09045](https://arxiv.org/html/2410.09045)\n\n  150. Multimodal Misinformation Detection by Learning from Synthetic Data with Multimodal LLMs - arXiv, accessed May 17, 2025, [https://arxiv.org/html/2409.19656v1](https://arxiv.org/html/2409.19656v1)\n\n**",
  "tags": [
    "DeepResearch"
  ],
  "date": "2025-05-17"
}