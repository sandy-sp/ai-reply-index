{
  "prompt": "The Future of Decentralized and Federated AI: Scalability, Privacy, and\nCollaborative Intelligence| AI Architectures, Privacy-Preserving AI,\nCollaborative AI| \"Perform an in-depth research exploration into the future\ntrajectory of decentralized AI, federated learning, and swarm intelligence,\nfocusing on their combined potential to create highly scalable, privacy-\npreserving, and collaboratively intelligent systems. The research should\naddress:  \nAdvanced Federated Learning Techniques: Investigate novel algorithms and\narchitectures for federated learning that go beyond current methods,\naddressing challenges like statistical heterogeneity, communication\nbottlenecks, security vulnerabilities (e.g., model poisoning, inference\nattacks), and incentive mechanisms for data/compute contribution.  \nDecentralized AI Infrastructure: Explore the viability of blockchain,\ndistributed ledger technologies, and peer-to-peer networking as foundational\ninfrastructure for truly decentralized AI model training, inference, and\ngovernance.  \nPrivacy-Enhancing Technologies (PETs) in Federated Systems: Analyze the\nintegration and effectiveness of advanced PETs (e.g., homomorphic encryption,\nsecure multi-party computation, differential privacy, zero-knowledge proofs)\nin the context of large-scale federated and decentralized AI.  \nEmergent Intelligence in Swarm Systems: Research how principles from swarm\nrobotics and collective intelligence in nature can be translated into AI\nsystems where multiple, potentially heterogeneous, AI agents collaborate on\ncomplex tasks without centralized control, leading to emergent problem-solving\ncapabilities.  \nReal-world Applications and Use Cases: Identify and analyze promising real-\nworld applications for these combined technologies, such as decentralized\nhealthcare networks, collaborative drug discovery, distributed sensor networks\nfor environmental monitoring, or community-owned AI models.  \nChallenges and Ethical Considerations: Discuss the unique challenges (e.g.,\nauditability, accountability in decentralized systems, energy consumption) and\nethical dilemmas posed by widespread adoption of these AI paradigms.\"|\nFederated learning advancements, decentralized AI, swarm intelligence AI,\nprivacy-enhancing AI, collaborative AI, blockchain AI, secure multi-party\ncomputation AI.  \n---|---|---|---",
  "model": "ChatGPT",
  "response": "**\n\n# The Future of Decentralized and Federated AI: Scalability, Privacy, and\nCollaborative Intelligence\n\nIntroduction: The Decentralized and Federated AI Landscape: Defining Key\nConcepts and Motivations.\n\nDecentralized Artificial Intelligence (AI) and Federated AI represent evolving\nparadigms in the field of machine learning, driven by the limitations of\ntraditional centralized AI models.1 Decentralized AI fundamentally shifts AI\nprocessing and data storage from a central authority to a distributed network\nof devices or nodes.3 This distribution aims to enhance data privacy,\nsecurity, and user control by keeping data closer to its source and reducing\nthe risks associated with centralized data repositories.1 Federated AI, on the\nother hand, is a specific decentralized machine learning approach that enables\nmultiple parties to collaboratively train a shared model without exchanging\ntheir private data.6 In federated learning, a central server typically\norchestrates the training process, but the raw data remains localized on\nindividual devices or within organizational silos.8\n\nThe necessity for these decentralized and federated approaches stems from\nseveral critical factors inherent in the current technological landscape.\nTraditional centralized AI models often require vast datasets to achieve high\nperformance, leading to the consolidation of data in the hands of a few large\norganizations.10 This centralization raises significant concerns regarding\ndata privacy, algorithmic surveillance, and vulnerabilities to data breaches.5\nMoreover, the increasing volume and distribution of data generated by the\nproliferation of edge computing devices and the Internet of Things (IoT) make\ncentralized architectures increasingly inefficient due to bandwidth\nlimitations and latency issues.1 The sheer volume of data produced at the edge\noften cannot be practically or efficiently transferred and processed in a\ncentral location.1\n\nFurthermore, a growing global awareness of data privacy has led to stringent\nregulations like GDPR and HIPAA, mandating privacy-preserving solutions for\nhandling sensitive information.14 Federated and decentralized AI offer\npromising avenues to address these regulatory requirements by enabling the\nutilization of distributed data without direct access or the need for data\ncentralization.6 Beyond privacy and scalability, these paradigms also unlock\nthe potential for collaborative intelligence, allowing diverse entities to\ncontribute to the development and improvement of AI models, accelerating\ninnovation, and fostering solutions to complex problems that might be\nintractable for a single organization.16 The tension between the need for\nlarge datasets to train powerful AI models and the increasing emphasis on data\nprivacy is a fundamental driving force behind the advancement of federated and\ndecentralized AI.6\n\nScalability in Decentralized and Federated AI:\n\nScalability is a paramount concern in the development and deployment of AI\nsystems, especially as applications become more complex and data volumes\ncontinue to grow exponentially. Decentralized and federated AI offer unique\napproaches and face specific challenges in achieving scalability for large-\nscale applications.\n\nAdvancements in Federated Learning for Large-Scale Applications.\n\nFederated Learning (FL) has emerged as a viable framework for training machine\nlearning models on an unprecedented scale, involving millions of devices\nacross diverse learning domains.8 This capability has been practically\ndemonstrated by industry giants such as Google, Apple, and Meta, where FL\npowers features in widely used products while ensuring user data remains on\ntheir devices.8 The scalability of FL allows for collaborative training\nwithout the need to centralize vast amounts of data, addressing privacy\nconcerns and enabling the development of more robust and generalizable\nmodels.6\n\nHowever, the increasing complexity of AI models, particularly large multi-\nmodal models, and the evolving landscape where training, inference, and\npersonalization are becoming intertwined, present significant challenges to\ntraditional FL frameworks.21 To address the demands of large-scale\ndeployments, researchers have explored hierarchical FL architectures. These\nsystems introduce intermediary aggregation layers between the central server\nand the edge devices, efficiently managing the communication and workload\ndistribution across a massive number of clients.22 This hierarchical structure\nenables the implementation and scaling of advanced FL algorithms, optimizing\nresource utilization and reducing the communication burden on the central\nserver.22 The practical success of FL in real-world applications underscores\nits potential as a scalable solution for distributed learning on vast\ndecentralized datasets.8\n\nScalability Challenges and Solutions in Decentralized AI Systems.\n\nDecentralized AI systems, while offering benefits in terms of privacy and\nrobustness, face their own set of scalability challenges, particularly when\ndealing with large-scale applications requiring high throughput.10 To handle\nthe demand for processing millions of transactions or data points per second,\na multi-layered approach is often necessary.10 This can involve combining\nlayer-two scaling solutions, which enhance transaction speed and reduce fees,\nwith modular blockchain architectures like Celestia and Cosmos, designed for\nbuilding scalable and interoperable decentralized applications.10 Furthermore,\nallowing off-chain AI processing, where computations are performed outside the\nmain blockchain, with on-chain validation using technologies like Zero-\nKnowledge proofs (ZKPs) can provide a pathway to scaling AI tasks without\noverwhelming the decentralized network.10 Decentralized networks such as\nRender and Akash offer platforms where distributed computing resources can be\nleveraged to provide the necessary processing power for AI tasks, contributing\nto the scalability of decentralized AI applications.10 Overcoming the inherent\nlimitations of decentralized systems to meet the computational demands of\nlarge-scale AI remains an active area of research and development.\n\nThe Role of Efficient Aggregation Techniques.\n\nIn Federated Learning, the aggregation of local models trained on diverse\nclient data is a crucial step that significantly impacts the performance and\nefficiency of the global model, especially in large-scale settings with\nheterogeneous data.6 While Federated Averaging (FedAvg) serves as a\nfoundational algorithm, its limitations in handling data heterogeneity have\nspurred the development of more advanced aggregation techniques.6 FedProx, for\ninstance, introduces a proximal term to the local objective function,\nencouraging consistency among locally updated models and improving convergence\nin heterogeneous networks.6 Adaptive optimization algorithms like FedAdam\nadjust learning rates based on the gradients, potentially leading to faster\nconvergence.32 FedNova addresses statistical heterogeneity by normalizing\nlocal updates during aggregation, balancing contributions from clients with\nvarying computational capabilities.33 For scenarios with periodic client\nparticipation, Amplified SCAFFOLD utilizes amplified updates and long-range\ncontrol variates to achieve linear speedup and resilience to data\nheterogeneity.7 In personalized federated learning, layer-wise aggregation\nstrategies like pFedLA and KAPC allow for different aggregation weights across\ndifferent layers of the neural network, catering to individual client data\ncharacteristics.6 Furthermore, the concept of differentiated aggregation\ninvolves aggregating different parts of the model at varying frequencies to\nenhance communication efficiency without compromising model accuracy.25 These\ndiverse and evolving aggregation techniques play a vital role in making\nfederated learning a scalable and effective approach for training models on\nlarge, distributed datasets with varying characteristics.6\n\nTable 1: Comparison of Federated Learning Aggregation Techniques\n\n  \n\nAlgorithm Name| Key Feature| Addressed Challenge| Relevant Snippet IDs  \n---|---|---|---  \nFedAvg| Weighted averaging of model parameters| Communication efficiency| 6  \nFedProx| Proximal regularization term| Data heterogeneity, Convergence| 6  \nFedAdam| Adaptive learning rates| Convergence speed| 32  \nFedNova| Normalization of local updates| Statistical heterogeneity,\nVariability| 33  \nAmplified SCAFFOLD| Amplified updates, Long-range control variates| Data\nheterogeneity, Communication efficiency, Periodic participation| 7  \npFedLA/KAPC| Layer-wise aggregation weights| Personalized learning, Data\nheterogeneity| 6  \nFedALS| Differentiated aggregation frequencies| Communication efficiency| 25  \n  \nPrivacy Preservation in Decentralized and Federated AI:\n\nEnsuring the privacy of sensitive data is a fundamental requirement for the\nwidespread adoption of decentralized and federated AI. Various techniques have\nbeen developed to address this critical aspect, ranging from secure\naggregation protocols to advanced cryptographic methods.\n\nState-of-the-Art Secure Aggregation Techniques in Federated Learning.\n\nSecure aggregation (SecAgg) is a cornerstone of privacy preservation in\nfederated learning, designed to allow a central server to obtain an aggregated\nmodel update from multiple clients without gaining access to the individual\nupdates themselves.40 This protection is crucial as individual updates can\ninadvertently reveal sensitive information about the training data.42 Several\ncryptographic techniques underpin secure aggregation, including secret\nsharing, where each client's update is split into multiple shares and\ndistributed among other participants, and homomorphic encryption, which\nenables the server to perform mathematical operations on encrypted data\nwithout decryption.43 These methods ensure that the server only learns the\nfinal aggregated result, preserving the confidentiality of individual\ncontributions.43 Advancements in secure aggregation protocols include\nLightSecAgg, which offers efficient handling of user dropouts, a common\nchallenge in federated environments, and ClusterGuard, a clustered aggregation\nscheme that enhances security and robustness against poisoning attacks.44\nVerifiable packed Shamir secret sharing provides another efficient approach\nfor secure and verifiable aggregation, reducing communication overhead while\nmaintaining privacy guarantees.40 These state-of-the-art secure aggregation\ntechniques are vital for building practical and privacy-respecting federated\nlearning systems.40\n\nHomomorphic Encryption and Other Privacy-Enhancing Technologies.\n\nHomomorphic Encryption (HE) stands out as a powerful Privacy-Enhancing\nTechnology (PET) that allows computations to be performed directly on\nencrypted data, ensuring that sensitive information remains protected\nthroughout the learning process.47 While HE offers strong privacy guarantees,\nits implementation in federated learning often faces challenges related to\nsignificant computational and communication overhead, particularly for large-\nscale models.47 Researchers have explored techniques to mitigate these\noverheads, such as selective parameter encryption, where only sensitive\nparameters are encrypted, significantly reducing the computational burden and\ncommunication costs.48 Beyond HE, other PETs play a crucial role in enhancing\nprivacy in decentralized and federated AI. Differential privacy (DP) adds\ncalibrated noise to the model updates or the final aggregated model, providing\na quantifiable privacy guarantee by limiting the information that can be\ninferred about individual data points [20,\n\n#### Works cited\n\n  1. Will 'Decentralized AI' make AI more transparent? - SCB 10X, accessed May 10, 2025, [https://www.scb10x.com/en/blog/will-decentralized-ai-make-ai-more-transparent](https://www.scb10x.com/en/blog/will-decentralized-ai-make-ai-more-transparent)\n\n  2. Challenges and Opportunities of Decentralized AI - Comidor, accessed May 10, 2025, [https://www.comidor.com/blog/artificial-intelligence/decentralized-ai/](https://www.comidor.com/blog/artificial-intelligence/decentralized-ai/)\n\n  3. Decentralized AI 101: Everything You Need to Know - Coinspeaker, accessed May 10, 2025, [https://www.coinspeaker.com/guides/decentralized-ai-101-everything-you-need-to-know/](https://www.coinspeaker.com/guides/decentralized-ai-101-everything-you-need-to-know/)\n\n  4. What is Decentralized AI? - Understanding the Future of Artificial Intelligence - SwarmZero, accessed May 10, 2025, [https://swarmzero.ai/blog/what-is-decentralized-ai](https://swarmzero.ai/blog/what-is-decentralized-ai)\n\n  5. Decentralized AI: Exploring the Revolutionary Technology in 2025 - Interexy, accessed May 10, 2025, [https://interexy.com/decentralized-ai-exploring-the-potential-of-the-revolutionary-technology/](https://interexy.com/decentralized-ai-exploring-the-potential-of-the-revolutionary-technology/)\n\n  6. A Survey of Recent Advances for Tackling Data Heterogeneity in ..., accessed May 10, 2025, [https://www.preprints.org/manuscript/202502.1159/v1](https://www.preprints.org/manuscript/202502.1159/v1)\n\n  7. NeurIPS Poster Federated Learning under Periodic Client ..., accessed May 10, 2025, [https://neurips.cc/virtual/2024/poster/94818](https://neurips.cc/virtual/2024/poster/94818)\n\n  8. arxiv.org, accessed May 10, 2025, [https://arxiv.org/pdf/2410.08892](https://arxiv.org/pdf/2410.08892)\n\n  9. A comprehensive experimental comparison between federated and centralized learning - Oxford Academic, accessed May 10, 2025, [https://academic.oup.com/database/article/doi/10.1093/database/baaf016/8090114](https://academic.oup.com/database/article/doi/10.1093/database/baaf016/8090114)\n\n  10. How Will Decentralized AI Affect Big Tech? | Built In, accessed May 10, 2025, [https://builtin.com/articles/decentralized-ai-big-tech](https://builtin.com/articles/decentralized-ai-big-tech)\n\n  11. A Perspective on Decentralizing AI - nanda.mit.edu, accessed May 10, 2025, [https://nanda.media.mit.edu/decentralized_AI_perspective.pdf](https://nanda.media.mit.edu/decentralized_AI_perspective.pdf)\n\n  12. Federated Learning: Risks and Challenges - Edge AI and Vision Alliance, accessed May 10, 2025, [https://www.edge-ai-vision.com/2025/01/federated-learning-risks-and-challenges/](https://www.edge-ai-vision.com/2025/01/federated-learning-risks-and-challenges/)\n\n  13. Top 5 AI Adoption Challenges for 2025: Overcoming Barriers to ..., accessed May 10, 2025, [https://convergetp.com/2025/03/25/top-5-ai-adoption-challenges-for-2025-overcoming-barriers-to-success/](https://convergetp.com/2025/03/25/top-5-ai-adoption-challenges-for-2025-overcoming-barriers-to-success/)\n\n  14. Federated Learning: Recent Advances and New Challenges - NeurIPS 2025, accessed May 10, 2025, [https://neurips.cc/virtual/2022/workshop/50002](https://neurips.cc/virtual/2022/workshop/50002)\n\n  15. A systematic survey on the application of federated learning in mental state detection and human activity recognition - Frontiers, accessed May 10, 2025, [https://www.frontiersin.org/journals/digital-health/articles/10.3389/fdgth.2024.1495999/full](https://www.frontiersin.org/journals/digital-health/articles/10.3389/fdgth.2024.1495999/full)\n\n  16. AI could supercharge human collective intelligence in everything from disaster relief to medical research - News & Events | Trinity College Dublin, accessed May 10, 2025, [https://www.tcd.ie/news_events/articles/2025/ai-could-supercharge-human-collective-intelligence-in-everything-from-disaster-relief-to-medical-research/](https://www.tcd.ie/news_events/articles/2025/ai-could-supercharge-human-collective-intelligence-in-everything-from-disaster-relief-to-medical-research/)\n\n  17. AI Trend Seminar 2025: Navigating the era of collective intelligence - AI Sweden, accessed May 10, 2025, [https://www.ai.se/en/news/ai-trend-seminar-2025-navigating-era-collective-intelligence](https://www.ai.se/en/news/ai-trend-seminar-2025-navigating-era-collective-intelligence)\n\n  18. Harnessing the power of collective intelligence with AI | Digital Leaders, accessed May 10, 2025, [https://digileaders.com/harnessing-the-power-of-collective-intelligence-with-ai/](https://digileaders.com/harnessing-the-power-of-collective-intelligence-with-ai/)\n\n  19. Advancing Drug Discovery Through Federated Learning, accessed May 10, 2025, [https://www.lhasalimited.org/blog/federated-learning-drug-discovery/](https://www.lhasalimited.org/blog/federated-learning-drug-discovery/)\n\n  20. arXiv:2410.08892v2 [cs.LG] 3 Mar 2025, accessed May 10, 2025, [https://arxiv.org/pdf/2410.08892?](https://arxiv.org/pdf/2410.08892)\n\n  21. Federated Learning in Practice: Reflections and Projections - arXiv, accessed May 10, 2025, [https://arxiv.org/html/2410.08892](https://arxiv.org/html/2410.08892)\n\n  22. Effortless Federated Learning on Mobile with NVIDIA FLARE and ..., accessed May 10, 2025, [https://developer.nvidia.com/blog/effortless-federated-learning-on-mobile-with-nvidia-flare-and-meta-executorch/](https://developer.nvidia.com/blog/effortless-federated-learning-on-mobile-with-nvidia-flare-and-meta-executorch/)\n\n  23. Advances in Federated Learning: Applications and Challenges in ..., accessed May 10, 2025, [https://www.mdpi.com/2073-431X/14/4/124](https://www.mdpi.com/2073-431X/14/4/124)\n\n  24. What algorithms are commonly used in federated learning? - Milvus Blog, accessed May 10, 2025, [https://blog.milvus.io/ai-quick-reference/what-algorithms-are-commonly-used-in-federated-learning](https://blog.milvus.io/ai-quick-reference/what-algorithms-are-commonly-used-in-federated-learning)\n\n  25. Communication Efficient Federated Representation Learning ..., accessed May 10, 2025, [https://openreview.net/forum?id=vstaHBy5N4](https://openreview.net/forum?id=vstaHBy5N4)\n\n  26. Federated Learning in Large Scale Networks: Exploring Hierarchical Federated Learning - DiVA portal, accessed May 10, 2025, [http://www.diva-portal.org/smash/get/diva2:1543886/FULLTEXT01.pdf](http://www.diva-portal.org/smash/get/diva2:1543886/FULLTEXT01.pdf)\n\n  27. ICML Communication Efficient Federated Learning with ... - ICML 2025, accessed May 10, 2025, [https://icml.cc/virtual/2024/37160](https://icml.cc/virtual/2024/37160)\n\n  28. The Effect of Personalization in FedProx: A Fine-grained Analysis on ..., accessed May 10, 2025, [https://openreview.net/forum?id=aQSbfKYXvo](https://openreview.net/forum?id=aQSbfKYXvo)\n\n  29. On Convergence of FedProx: Local Dissimilarity Invariant Bounds, Non-smoothness and Beyond, accessed May 10, 2025, [https://proceedings.neurips.cc/paper_files/paper/2022/file/45ecdd6cf1f507d378a3442ed89e580b-Paper-Conference.pdf](https://proceedings.neurips.cc/paper_files/paper/2022/file/45ecdd6cf1f507d378a3442ed89e580b-Paper-Conference.pdf)\n\n  30. FedProx: FedSplit Algorithm based Federated Learning for Statistical and System Heterogeneity in Medical Data Communication, accessed May 10, 2025, [https://jisis.org/wp-content/uploads/2024/09/2024.I3.021.pdf](https://jisis.org/wp-content/uploads/2024/09/2024.I3.021.pdf)\n\n  31. FedUB: Federated Learning Algorithm Based on Update Bias - MDPI, accessed May 10, 2025, [https://www.mdpi.com/2227-7390/12/10/1601](https://www.mdpi.com/2227-7390/12/10/1601)\n\n  32. geehokim/FedACG: (CVPR 2024) Communication-Efficient Federated Learning with Accelerated Client Gradient - GitHub, accessed May 10, 2025, [https://github.com/geehokim/FedACG](https://github.com/geehokim/FedACG)\n\n  33. [2411.06352] Client Contribution Normalization for Enhanced Federated Learning - arXiv, accessed May 10, 2025, [https://arxiv.org/abs/2411.06352](https://arxiv.org/abs/2411.06352)\n\n  34. neurips2021workshopfl.github.io, accessed May 10, 2025, [https://neurips2021workshopfl.github.io/NFFL-2021/papers/2021/Oh2021.pdf](https://neurips2021workshopfl.github.io/NFFL-2021/papers/2021/Oh2021.pdf)\n\n  35. Federated Learning under Periodic Client Participation and Heterogeneous Data: A New Communication-Efficient Algorithm and Analysis - NIPS papers, accessed May 10, 2025, [https://proceedings.neurips.cc/paper_files/paper/2024/file/0f98645119923217a245735c2c4d23f4-Paper-Conference.pdf](https://proceedings.neurips.cc/paper_files/paper/2024/file/0f98645119923217a245735c2c4d23f4-Paper-Conference.pdf)\n\n  36. arxiv.org, accessed May 10, 2025, [https://arxiv.org/pdf/2410.23131?](https://arxiv.org/pdf/2410.23131)\n\n  37. Federated Learning under Periodic Client Participation and Heterogeneous Data: A New Communication-Efficient Algorithm and Analysis | OpenReview, accessed May 10, 2025, [https://openreview.net/forum?id=WftaVkL6G2&referrer=%5Bthe%20profile%20of%20Mingrui%20Liu%5D(%2Fprofile%3Fid%3D~Mingrui_Liu2)](https://openreview.net/forum?id=WftaVkL6G2&referrer=%5Bthe+profile+of+Mingrui+Liu%5D\\(/profile?id%3D~Mingrui_Liu2\\))\n\n  38. Personalized Federated Learning with Local Attention | Request PDF, accessed May 10, 2025, [https://www.researchgate.net/publication/369792098_Personalized_Federated_Learning_with_Local_Attention](https://www.researchgate.net/publication/369792098_Personalized_Federated_Learning_with_Local_Attention)\n\n  39. Knowledge-Aware Parameter Coaching for Personalized Federated Learning - AAAI Publications, accessed May 10, 2025, [https://ojs.aaai.org/index.php/AAAI/article/view/29651/31107](https://ojs.aaai.org/index.php/AAAI/article/view/29651/31107)\n\n  40. proceedings.neurips.cc, accessed May 10, 2025, [https://proceedings.neurips.cc/paper_files/paper/2024/file/bcbdc25dc4f0be5ae8ac07232df6e33a-Paper-Conference.pdf](https://proceedings.neurips.cc/paper_files/paper/2024/file/bcbdc25dc4f0be5ae8ac07232df6e33a-Paper-Conference.pdf)\n\n  41. RFLPA: A Robust Federated Learning Framework against Poisoning Attacks with Secure Aggregation, accessed May 10, 2025, [https://proceedings.neurips.cc/paper_files/paper/2024/hash/bcbdc25dc4f0be5ae8ac07232df6e33a-Abstract-Conference.html](https://proceedings.neurips.cc/paper_files/paper/2024/hash/bcbdc25dc4f0be5ae8ac07232df6e33a-Abstract-Conference.html)\n\n  42. Dual Defense: Enhancing Privacy and Mitigating Poisoning Attacks ..., accessed May 10, 2025, [https://openreview.net/forum?id=EVw8Jh5Et9&referrer=%5Bthe%20profile%20of%20Jianxin%20Li%5D(%2Fprofile%3Fid%3D~Jianxin_Li3)](https://openreview.net/forum?id=EVw8Jh5Et9&referrer=%5Bthe+profile+of+Jianxin+Li%5D\\(/profile?id%3D~Jianxin_Li3\\))\n\n  43. Group verifiable secure aggregate federated learning based on secret sharing - PMC, accessed May 10, 2025, [https://pmc.ncbi.nlm.nih.gov/articles/PMC11926380/](https://pmc.ncbi.nlm.nih.gov/articles/PMC11926380/)\n\n  44. LightSecAgg: a Lightweight and Versatile Design for Secure ..., accessed May 10, 2025, [https://proceedings.mlsys.org/paper_files/paper/2022/hash/6c44dc73014d66ba49b28d483a8f8b0d-Abstract.html](https://proceedings.mlsys.org/paper_files/paper/2022/hash/6c44dc73014d66ba49b28d483a8f8b0d-Abstract.html)\n\n  45. Rethinking Secure Aggregation in FL! - Salman Avestimehr, accessed May 10, 2025, [https://www.avestimehr.com/news-spotlight/ranking-secure-aggregation-fl](https://www.avestimehr.com/news-spotlight/ranking-secure-aggregation-fl)\n\n  46. eprint.iacr.org, accessed May 10, 2025, [https://eprint.iacr.org/2024/2082.pdf](https://eprint.iacr.org/2024/2082.pdf)\n\n  47. Homomorphic Encryption in Federated Learning - Leo Celis Blog, accessed May 10, 2025, [https://blog.leocelis.com/2024/07/17/homomorphic-encryption-in-federated-learning/](https://blog.leocelis.com/2024/07/17/homomorphic-encryption-in-federated-learning/)\n\n  48. FedML-HE: An Efficient Homomorphic-Encryption-Based Privacy ..., accessed May 10, 2025, [https://openreview.net/forum?id=PuYD0fh5aq](https://openreview.net/forum?id=PuYD0fh5aq)\n\n  49. Improving Efficiency in Federated Learning with Optimized Homomorphic Encryption - arXiv, accessed May 10, 2025, [https://arxiv.org/html/2504.03002v1](https://arxiv.org/html/2504.03002v1)\n\n  50. Homomorphic Encryption Integrated With Federated Learning - Protiviti, accessed May 10, 2025, [https://www.protiviti.com/sites/default/files/2025-03/protiviti_white-paper_homomorphic_encryption.pdf](https://www.protiviti.com/sites/default/files/2025-03/protiviti_white-paper_homomorphic_encryption.pdf)\n\n  51. FedNIC: enhancing privacy-preserving federated learning via homomorphic encryption offload on SmartNIC - Frontiers, accessed May 10, 2025, [https://www.frontiersin.org/journals/computer-science/articles/10.3389/fcomp.2024.1465352/full](https://www.frontiersin.org/journals/computer-science/articles/10.3389/fcomp.2024.1465352/full)\n\n  52. Federated Learning with Homomorphic Encryption | NVIDIA Technical Blog, accessed May 10, 2025, [https://developer.nvidia.com/blog/federated-learning-with-homomorphic-encryption/](https://developer.nvidia.com/blog/federated-learning-with-homomorphic-encryption/)\n\n  53. Communication Efficient Differentially Private Federated Learning Using Second Order Information, accessed May 10, 2025, [https://petsymposium.org/popets/2025/popets-2025-0032.pdf](https://petsymposium.org/popets/2025/popets-2025-0032.pdf)\n\n  54. NeurIPS Poster Dynamic Personalized Federated Learning with Adaptive Differential Privacy, accessed May 10, 2025, [https://neurips.cc/virtual/2023/poster/71639](https://neurips.cc/virtual/2023/poster/71639)\n\n  55. Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey - MDPI, accessed May 10, 2025, [https://www.mdpi.com/2079-9292/12/12/2703](https://www.mdpi.com/2079-9292/12/12/2703)\n\n  56. Will Synthetic Data Finally Solve the Data Access Problem? Workshop summary - OpenReview, accessed May 10, 2025, [https://openreview.net/pdf?id=0nw5rjqxw2](https://openreview.net/pdf?id=0nw5rjqxw2)\n\n  57. Virginia Smith - Carnegie Mellon University, accessed May 10, 2025, [http://www.cs.cmu.edu/~smithv/](http://www.cs.cmu.edu/~smithv/)\n\n  58. Secure and Flexible Privacy-Preserving Federated Learning Based on Multi-Key Fully Homomorphic Encryption - MDPI, accessed May 10, 2025, [https://www.mdpi.com/2079-9292/13/22/4478](https://www.mdpi.com/2079-9292/13/22/4478)\n\n  59. MASKCRYPT: Federated Learning with Selective Homomorphic Encryption - University of Toronto, accessed May 10, 2025, [https://iqua.ece.toronto.edu/papers/chenghao-tdsc24.pdf](https://iqua.ece.toronto.edu/papers/chenghao-tdsc24.pdf)\n\n  60. Privacy-Preserving Analytical Pipelines Using Differential Privacy and Secure Multi-Party Computation in Federated Cloud Frameworks - Scholar9, accessed May 10, 2025, [https://scholar9.com/publication/f9ca6ae6fb1f1a42668cd8b0fa340383.pdf](https://scholar9.com/publication/f9ca6ae6fb1f1a42668cd8b0fa340383.pdf)\n\n  61. SMPAI: Secure Multi-Party Computation for Federated Learning - J.P. Morgan, accessed May 10, 2025, [https://www.jpmorgan.com/content/dam/jpm/cib/complex/content/technology/ai-research-publications/pdf-9.pdf](https://www.jpmorgan.com/content/dam/jpm/cib/complex/content/technology/ai-research-publications/pdf-9.pdf)\n\n  62. Belt and Braces: When Federated Learning Meets Differential Privacy, accessed May 10, 2025, [https://cacm.acm.org/research/belt-and-braces-when-federated-learning-meets-differential-privacy/](https://cacm.acm.org/research/belt-and-braces-when-federated-learning-meets-differential-privacy/)\n\n  63. Communication-Efficient Decentralized Multi-agent Machine Learning Method | AIM - AUTM, accessed May 10, 2025, [https://aim.autm.net/public/project/77587/](https://aim.autm.net/public/project/77587/)\n\n**",
  "tags": [],
  "date": "2025-05-23"
}