# Response from Gemini

# \*\*The Future of Decentralized and Federated AI: Scalability, Privacy, and

Collaborative Intelligence\*\*

Introduction: The Decentralized and Federated AI Landscape: Defining Key
Concepts and Motivations.

Decentralized Artificial Intelligence (AI) and Federated AI represent evolving
paradigms in the field of machine learning, driven by the limitations of
traditional centralized AI models.1 Decentralized AI fundamentally shifts AI
processing and data storage from a central authority to a distributed network
of devices or nodes.3 This distribution aims to enhance data privacy,
security, and user control by keeping data closer to its source and reducing
the risks associated with centralized data repositories.1 Federated AI, on the
other hand, is a specific decentralized machine learning approach that enables
multiple parties to collaboratively train a shared model without exchanging
their private data.6 In federated learning, a central server typically
orchestrates the training process, but the raw data remains localized on
individual devices or within organizational silos.8

The necessity for these decentralized and federated approaches stems from
several critical factors inherent in the current technological landscape.
Traditional centralized AI models often require vast datasets to achieve high
performance, leading to the consolidation of data in the hands of a few large
organizations.10 This centralization raises significant concerns regarding
data privacy, algorithmic surveillance, and vulnerabilities to data breaches.5
Moreover, the increasing volume and distribution of data generated by the
proliferation of edge computing devices and the Internet of Things (IoT) make
centralized architectures increasingly inefficient due to bandwidth
limitations and latency issues.1 The sheer volume of data produced at the edge
often cannot be practically or efficiently transferred and processed in a
central location.1

Furthermore, a growing global awareness of data privacy has led to stringent
regulations like GDPR and HIPAA, mandating privacy-preserving solutions for
handling sensitive information.14 Federated and decentralized AI offer
promising avenues to address these regulatory requirements by enabling the
utilization of distributed data without direct access or the need for data
centralization.6 Beyond privacy and scalability, these paradigms also unlock
the potential for collaborative intelligence, allowing diverse entities to
contribute to the development and improvement of AI models, accelerating
innovation, and fostering solutions to complex problems that might be
intractable for a single organization.16 The tension between the need for
large datasets to train powerful AI models and the increasing emphasis on data
privacy is a fundamental driving force behind the advancement of federated and
decentralized AI.6

Scalability in Decentralized and Federated AI:

Scalability is a paramount concern in the development and deployment of AI
systems, especially as applications become more complex and data volumes
continue to grow exponentially. Decentralized and federated AI offer unique
approaches and face specific challenges in achieving scalability for large-
scale applications.

Advancements in Federated Learning for Large-Scale Applications.

Federated Learning (FL) has emerged as a viable framework for training machine
learning models on an unprecedented scale, involving millions of devices
across diverse learning domains.8 This capability has been practically
demonstrated by industry giants such as Google, Apple, and Meta, where FL
powers features in widely used products while ensuring user data remains on
their devices.8 The scalability of FL allows for collaborative training
without the need to centralize vast amounts of data, addressing privacy
concerns and enabling the development of more robust and generalizable
models.6

However, the increasing complexity of AI models, particularly large multi-
modal models, and the evolving landscape where training, inference, and
personalization are becoming intertwined, present significant challenges to
traditional FL frameworks.21 To address the demands of large-scale
deployments, researchers have explored hierarchical FL architectures. These
systems introduce intermediary aggregation layers between the central server
and the edge devices, efficiently managing the communication and workload
distribution across a massive number of clients.22 This hierarchical structure
enables the implementation and scaling of advanced FL algorithms, optimizing
resource utilization and reducing the communication burden on the central
server.22 The practical success of FL in real-world applications underscores
its potential as a scalable solution for distributed learning on vast
decentralized datasets.8

Scalability Challenges and Solutions in Decentralized AI Systems.

Decentralized AI systems, while offering benefits in terms of privacy and
robustness, face their own set of scalability challenges, particularly when
dealing with large-scale applications requiring high throughput.10 To handle
the demand for processing millions of transactions or data points per second,
a multi-layered approach is often necessary.10 This can involve combining
layer-two scaling solutions, which enhance transaction speed and reduce fees,
with modular blockchain architectures like Celestia and Cosmos, designed for
building scalable and interoperable decentralized applications.10 Furthermore,
allowing off-chain AI processing, where computations are performed outside the
main blockchain, with on-chain validation using technologies like Zero-
Knowledge proofs (ZKPs) can provide a pathway to scaling AI tasks without
overwhelming the decentralized network.10 Decentralized networks such as
Render and Akash offer platforms where distributed computing resources can be
leveraged to provide the necessary processing power for AI tasks, contributing
to the scalability of decentralized AI applications.10 Overcoming the inherent
limitations of decentralized systems to meet the computational demands of
large-scale AI remains an active area of research and development.

The Role of Efficient Aggregation Techniques.

In Federated Learning, the aggregation of local models trained on diverse
client data is a crucial step that significantly impacts the performance and
efficiency of the global model, especially in large-scale settings with
heterogeneous data.6 While Federated Averaging (FedAvg) serves as a
foundational algorithm, its limitations in handling data heterogeneity have
spurred the development of more advanced aggregation techniques.6 FedProx, for
instance, introduces a proximal term to the local objective function,
encouraging consistency among locally updated models and improving convergence
in heterogeneous networks.6 Adaptive optimization algorithms like FedAdam
adjust learning rates based on the gradients, potentially leading to faster
convergence.32 FedNova addresses statistical heterogeneity by normalizing
local updates during aggregation, balancing contributions from clients with
varying computational capabilities.33 For scenarios with periodic client
participation, Amplified SCAFFOLD utilizes amplified updates and long-range
control variates to achieve linear speedup and resilience to data
heterogeneity.7 In personalized federated learning, layer-wise aggregation
strategies like pFedLA and KAPC allow for different aggregation weights across
different layers of the neural network, catering to individual client data
characteristics.6 Furthermore, the concept of differentiated aggregation
involves aggregating different parts of the model at varying frequencies to
enhance communication efficiency without compromising model accuracy.25 These
diverse and evolving aggregation techniques play a vital role in making
federated learning a scalable and effective approach for training models on
large, distributed datasets with varying characteristics.6

**Table 1: Comparison of Federated Learning Aggregation Techniques**

**Algorithm Name** | **Key Feature** | **Addressed Challenge** | **Relevant Snippet IDs**\
---|---|---|---\
FedAvg | Weighted averaging of model parameters | Communication efficiency | 6\
FedProx | Proximal regularization term | Data heterogeneity, Convergence | 6\
FedAdam | Adaptive learning rates | Convergence speed | 32\
FedNova | Normalization of local updates | Statistical heterogeneity, Variability | 33\
Amplified SCAFFOLD | Amplified updates, Long-range control variates | Data heterogeneity, Communication efficiency, Periodic participation | 7\
pFedLA/KAPC | Layer-wise aggregation weights | Personalized learning, Data heterogeneity | 6\
FedALS | Differentiated aggregation frequencies | Communication efficiency | 25

Privacy Preservation in Decentralized and Federated AI:

Ensuring the privacy of sensitive data is a fundamental requirement for the
widespread adoption of decentralized and federated AI. Various techniques have
been developed to address this critical aspect, ranging from secure
aggregation protocols to advanced cryptographic methods.

State-of-the-Art Secure Aggregation Techniques in Federated Learning.

Secure aggregation (SecAgg) is a cornerstone of privacy preservation in
federated learning, designed to allow a central server to obtain an aggregated
model update from multiple clients without gaining access to the individual
updates themselves.40 This protection is crucial as individual updates can
inadvertently reveal sensitive information about the training data.42 Several
cryptographic techniques underpin secure aggregation, including secret
sharing, where each client's update is split into multiple shares and
distributed among other participants, and homomorphic encryption, which
enables the server to perform mathematical operations on encrypted data
without decryption.43 These methods ensure that the server only learns the
final aggregated result, preserving the confidentiality of individual
contributions.43 Advancements in secure aggregation protocols include
LightSecAgg, which offers efficient handling of user dropouts, a common
challenge in federated environments, and ClusterGuard, a clustered aggregation
scheme that enhances security and robustness against poisoning attacks.44
Verifiable packed Shamir secret sharing provides another efficient approach
for secure and verifiable aggregation, reducing communication overhead while
maintaining privacy guarantees.40 These state-of-the-art secure aggregation
techniques are vital for building practical and privacy-respecting federated
learning systems.40

Homomorphic Encryption and Other Privacy-Enhancing Technologies.

Homomorphic Encryption (HE) stands out as a powerful Privacy-Enhancing
Technology (PET) that allows computations to be performed directly on
encrypted data, ensuring that sensitive information remains protected
throughout the learning process.47 While HE offers strong privacy guarantees,
its implementation in federated learning often faces challenges related to
significant computational and communication overhead, particularly for large-
scale models.47 Researchers have explored techniques to mitigate these
overheads, such as selective parameter encryption, where only sensitive
parameters are encrypted, significantly reducing the computational burden and
communication costs.48 Beyond HE, other PETs play a crucial role in enhancing
privacy in decentralized and federated AI. Differential privacy (DP) adds
calibrated noise to the model updates or the final aggregated model, providing
a quantifiable privacy guarantee by limiting the information that can be
inferred about individual data points \[20,

#### Works cited

1. Will 'Decentralized AI' make AI more transparent? - SCB 10X, accessed May 10, 2025, [_https://www.scb10x.com/en/blog/will-decentralized-ai-make-ai-more-transparent_](https://www.scb10x.com/en/blog/will-decentralized-ai-make-ai-more-transparent)

1. Challenges and Opportunities of Decentralized AI - Comidor, accessed May 10, 2025, [_https://www.comidor.com/blog/artificial-intelligence/decentralized-ai/_](https://www.comidor.com/blog/artificial-intelligence/decentralized-ai/)

1. Decentralized AI 101: Everything You Need to Know - Coinspeaker, accessed May 10, 2025, [_https://www.coinspeaker.com/guides/decentralized-ai-101-everything-you-need-to-know/_](https://www.coinspeaker.com/guides/decentralized-ai-101-everything-you-need-to-know/)

1. What is Decentralized AI? - Understanding the Future of Artificial Intelligence - SwarmZero, accessed May 10, 2025, [_https://swarmzero.ai/blog/what-is-decentralized-ai_](https://swarmzero.ai/blog/what-is-decentralized-ai)

1. Decentralized AI: Exploring the Revolutionary Technology in 2025 - Interexy, accessed May 10, 2025, [_https://interexy.com/decentralized-ai-exploring-the-potential-of-the-revolutionary-technology/_](https://interexy.com/decentralized-ai-exploring-the-potential-of-the-revolutionary-technology/)

1. A Survey of Recent Advances for Tackling Data Heterogeneity in ..., accessed May 10, 2025, [_https://www.preprints.org/manuscript/202502.1159/v1_](https://www.preprints.org/manuscript/202502.1159/v1)

1. NeurIPS Poster Federated Learning under Periodic Client ..., accessed May 10, 2025, [_https://neurips.cc/virtual/2024/poster/94818_](https://neurips.cc/virtual/2024/poster/94818)

1. arxiv.org, accessed May 10, 2025, [_https://arxiv.org/pdf/2410.08892_](https://arxiv.org/pdf/2410.08892)

1. A comprehensive experimental comparison between federated and centralized learning - Oxford Academic, accessed May 10, 2025, [_https://academic.oup.com/database/article/doi/10.1093/database/baaf016/8090114_](https://academic.oup.com/database/article/doi/10.1093/database/baaf016/8090114)

1. How Will Decentralized AI Affect Big Tech? | Built In, accessed May 10, 2025, [_https://builtin.com/articles/decentralized-ai-big-tech_](https://builtin.com/articles/decentralized-ai-big-tech)

1. A Perspective on Decentralizing AI - nanda.mit.edu, accessed May 10, 2025, [_https://nanda.media.mit.edu/decentralized_AI_perspective.pdf_](https://nanda.media.mit.edu/decentralized_AI_perspective.pdf)

1. Federated Learning: Risks and Challenges - Edge AI and Vision Alliance, accessed May 10, 2025, [_https://www.edge-ai-vision.com/2025/01/federated-learning-risks-and-challenges/_](https://www.edge-ai-vision.com/2025/01/federated-learning-risks-and-challenges/)

1. Top 5 AI Adoption Challenges for 2025: Overcoming Barriers to ..., accessed May 10, 2025, [_https://convergetp.com/2025/03/25/top-5-ai-adoption-challenges-for-2025-overcoming-barriers-to-success/_](https://convergetp.com/2025/03/25/top-5-ai-adoption-challenges-for-2025-overcoming-barriers-to-success/)

1. Federated Learning: Recent Advances and New Challenges - NeurIPS 2025, accessed May 10, 2025, [_https://neurips.cc/virtual/2022/workshop/50002_](https://neurips.cc/virtual/2022/workshop/50002)

1. A systematic survey on the application of federated learning in mental state detection and human activity recognition - Frontiers, accessed May 10, 2025, [_https://www.frontiersin.org/journals/digital-health/articles/10.3389/fdgth.2024.1495999/full_](https://www.frontiersin.org/journals/digital-health/articles/10.3389/fdgth.2024.1495999/full)

1. AI could supercharge human collective intelligence in everything from disaster relief to medical research - News & Events | Trinity College Dublin, accessed May 10, 2025, [_https://www.tcd.ie/news_events/articles/2025/ai-could-supercharge-human-collective-intelligence-in-everything-from-disaster-relief-to-medical-research/_](https://www.tcd.ie/news_events/articles/2025/ai-could-supercharge-human-collective-intelligence-in-everything-from-disaster-relief-to-medical-research/)

1. AI Trend Seminar 2025: Navigating the era of collective intelligence - AI Sweden, accessed May 10, 2025, [_https://www.ai.se/en/news/ai-trend-seminar-2025-navigating-era-collective-intelligence_](https://www.ai.se/en/news/ai-trend-seminar-2025-navigating-era-collective-intelligence)

1. Harnessing the power of collective intelligence with AI | Digital Leaders, accessed May 10, 2025, [_https://digileaders.com/harnessing-the-power-of-collective-intelligence-with-ai/_](https://digileaders.com/harnessing-the-power-of-collective-intelligence-with-ai/)

1. Advancing Drug Discovery Through Federated Learning, accessed May 10, 2025, [_https://www.lhasalimited.org/blog/federated-learning-drug-discovery/_](https://www.lhasalimited.org/blog/federated-learning-drug-discovery/)

1. arXiv:2410.08892v2 [cs.LG] 3 Mar 2025, accessed May 10, 2025, [_https://arxiv.org/pdf/2410.08892?_](https://arxiv.org/pdf/2410.08892)

1. Federated Learning in Practice: Reflections and Projections - arXiv, accessed May 10, 2025, [_https://arxiv.org/html/2410.08892_](https://arxiv.org/html/2410.08892)

1. Effortless Federated Learning on Mobile with NVIDIA FLARE and ..., accessed May 10, 2025, [_https://developer.nvidia.com/blog/effortless-federated-learning-on-mobile-with-nvidia-flare-and-meta-executorch/_](https://developer.nvidia.com/blog/effortless-federated-learning-on-mobile-with-nvidia-flare-and-meta-executorch/)

1. Advances in Federated Learning: Applications and Challenges in ..., accessed May 10, 2025, [_https://www.mdpi.com/2073-431X/14/4/124_](https://www.mdpi.com/2073-431X/14/4/124)

1. What algorithms are commonly used in federated learning? - Milvus Blog, accessed May 10, 2025, [_https://blog.milvus.io/ai-quick-reference/what-algorithms-are-commonly-used-in-federated-learning_](https://blog.milvus.io/ai-quick-reference/what-algorithms-are-commonly-used-in-federated-learning)

1. Communication Efficient Federated Representation Learning ..., accessed May 10, 2025, [_https://openreview.net/forum?id=vstaHBy5N4_](https://openreview.net/forum?id=vstaHBy5N4)

1. Federated Learning in Large Scale Networks: Exploring Hierarchical Federated Learning - DiVA portal, accessed May 10, 2025, [_http://www.diva-portal.org/smash/get/diva2:1543886/FULLTEXT01.pdf_](http://www.diva-portal.org/smash/get/diva2:1543886/FULLTEXT01.pdf)

1. ICML Communication Efficient Federated Learning with ... - ICML 2025, accessed May 10, 2025, [_https://icml.cc/virtual/2024/37160_](https://icml.cc/virtual/2024/37160)

1. The Effect of Personalization in FedProx: A Fine-grained Analysis on ..., accessed May 10, 2025, [_https://openreview.net/forum?id=aQSbfKYXvo_](https://openreview.net/forum?id=aQSbfKYXvo)

1. On Convergence of FedProx: Local Dissimilarity Invariant Bounds, Non-smoothness and Beyond, accessed May 10, 2025, [_https://proceedings.neurips.cc/paper_files/paper/2022/file/45ecdd6cf1f507d378a3442ed89e580b-Paper-Conference.pdf_](https://proceedings.neurips.cc/paper_files/paper/2022/file/45ecdd6cf1f507d378a3442ed89e580b-Paper-Conference.pdf)

1. FedProx: FedSplit Algorithm based Federated Learning for Statistical and System Heterogeneity in Medical Data Communication, accessed May 10, 2025, [_https://jisis.org/wp-content/uploads/2024/09/2024.I3.021.pdf_](https://jisis.org/wp-content/uploads/2024/09/2024.I3.021.pdf)

1. FedUB: Federated Learning Algorithm Based on Update Bias - MDPI, accessed May 10, 2025, [_https://www.mdpi.com/2227-7390/12/10/1601_](https://www.mdpi.com/2227-7390/12/10/1601)

1. geehokim/FedACG: (CVPR 2024) Communication-Efficient Federated Learning with Accelerated Client Gradient - GitHub, accessed May 10, 2025, [_https://github.com/geehokim/FedACG_](https://github.com/geehokim/FedACG)

1. [2411.06352] Client Contribution Normalization for Enhanced Federated Learning - arXiv, accessed May 10, 2025, [_https://arxiv.org/abs/2411.06352_](https://arxiv.org/abs/2411.06352)

1. neurips2021workshopfl.github.io, accessed May 10, 2025, [_https://neurips2021workshopfl.github.io/NFFL-2021/papers/2021/Oh2021.pdf_](https://neurips2021workshopfl.github.io/NFFL-2021/papers/2021/Oh2021.pdf)

1. Federated Learning under Periodic Client Participation and Heterogeneous Data: A New Communication-Efficient Algorithm and Analysis - NIPS papers, accessed May 10, 2025, [_https://proceedings.neurips.cc/paper_files/paper/2024/file/0f98645119923217a245735c2c4d23f4-Paper-Conference.pdf_](https://proceedings.neurips.cc/paper_files/paper/2024/file/0f98645119923217a245735c2c4d23f4-Paper-Conference.pdf)

1. arxiv.org, accessed May 10, 2025, [_https://arxiv.org/pdf/2410.23131?_](https://arxiv.org/pdf/2410.23131)

1. Federated Learning under Periodic Client Participation and Heterogeneous Data: A New Communication-Efficient Algorithm and Analysis | OpenReview, accessed May 10, 2025, [_https://openreview.net/forum?id=WftaVkL6G2 &referrer=%5Bthe%20profile%20of%20Mingrui%20Liu%5D(%2Fprofile%3Fid%3D~Mingrui_Liu2)_](<https://openreview.net/forum?id=WftaVkL6G2&referrer=%5Bthe+profile+of+Mingrui+Liu%5D(/profile?id%3D~Mingrui_Liu2)>)

1. Personalized Federated Learning with Local Attention | Request PDF, accessed May 10, 2025, [_https://www.researchgate.net/publication/369792098_Personalized_Federated_Learning_with_Local_Attention_](https://www.researchgate.net/publication/369792098_Personalized_Federated_Learning_with_Local_Attention)

1. Knowledge-Aware Parameter Coaching for Personalized Federated Learning - AAAI Publications, accessed May 10, 2025, [_https://ojs.aaai.org/index.php/AAAI/article/view/29651/31107_](https://ojs.aaai.org/index.php/AAAI/article/view/29651/31107)

1. proceedings.neurips.cc, accessed May 10, 2025, [_https://proceedings.neurips.cc/paper_files/paper/2024/file/bcbdc25dc4f0be5ae8ac07232df6e33a-Paper-Conference.pdf_](https://proceedings.neurips.cc/paper_files/paper/2024/file/bcbdc25dc4f0be5ae8ac07232df6e33a-Paper-Conference.pdf)

1. RFLPA: A Robust Federated Learning Framework against Poisoning Attacks with Secure Aggregation, accessed May 10, 2025, [_https://proceedings.neurips.cc/paper_files/paper/2024/hash/bcbdc25dc4f0be5ae8ac07232df6e33a-Abstract-Conference.html_](https://proceedings.neurips.cc/paper_files/paper/2024/hash/bcbdc25dc4f0be5ae8ac07232df6e33a-Abstract-Conference.html)

1. Dual Defense: Enhancing Privacy and Mitigating Poisoning Attacks ..., accessed May 10, 2025, [_https://openreview.net/forum?id=EVw8Jh5Et9 &referrer=%5Bthe%20profile%20of%20Jianxin%20Li%5D(%2Fprofile%3Fid%3D~Jianxin_Li3)_](<https://openreview.net/forum?id=EVw8Jh5Et9&referrer=%5Bthe+profile+of+Jianxin+Li%5D(/profile?id%3D~Jianxin_Li3)>)

1. Group verifiable secure aggregate federated learning based on secret sharing - PMC, accessed May 10, 2025, [_https://pmc.ncbi.nlm.nih.gov/articles/PMC11926380/_](https://pmc.ncbi.nlm.nih.gov/articles/PMC11926380/)

1. LightSecAgg: a Lightweight and Versatile Design for Secure ..., accessed May 10, 2025, [_https://proceedings.mlsys.org/paper_files/paper/2022/hash/6c44dc73014d66ba49b28d483a8f8b0d-Abstract.html_](https://proceedings.mlsys.org/paper_files/paper/2022/hash/6c44dc73014d66ba49b28d483a8f8b0d-Abstract.html)

1. Rethinking Secure Aggregation in FL! - Salman Avestimehr, accessed May 10, 2025, [_https://www.avestimehr.com/news-spotlight/ranking-secure-aggregation-fl_](https://www.avestimehr.com/news-spotlight/ranking-secure-aggregation-fl)

1. eprint.iacr.org, accessed May 10, 2025, [_https://eprint.iacr.org/2024/2082.pdf_](https://eprint.iacr.org/2024/2082.pdf)

1. Homomorphic Encryption in Federated Learning - Leo Celis Blog, accessed May 10, 2025, [_https://blog.leocelis.com/2024/07/17/homomorphic-encryption-in-federated-learning/_](https://blog.leocelis.com/2024/07/17/homomorphic-encryption-in-federated-learning/)

1. FedML-HE: An Efficient Homomorphic-Encryption-Based Privacy ..., accessed May 10, 2025, [_https://openreview.net/forum?id=PuYD0fh5aq_](https://openreview.net/forum?id=PuYD0fh5aq)

1. Improving Efficiency in Federated Learning with Optimized Homomorphic Encryption - arXiv, accessed May 10, 2025, [_https://arxiv.org/html/2504.03002v1_](https://arxiv.org/html/2504.03002v1)

1. Homomorphic Encryption Integrated With Federated Learning - Protiviti, accessed May 10, 2025, [_https://www.protiviti.com/sites/default/files/2025-03/protiviti_white-paper_homomorphic_encryption.pdf_](https://www.protiviti.com/sites/default/files/2025-03/protiviti_white-paper_homomorphic_encryption.pdf)

1. FedNIC: enhancing privacy-preserving federated learning via homomorphic encryption offload on SmartNIC - Frontiers, accessed May 10, 2025, [_https://www.frontiersin.org/journals/computer-science/articles/10.3389/fcomp.2024.1465352/full_](https://www.frontiersin.org/journals/computer-science/articles/10.3389/fcomp.2024.1465352/full)

1. Federated Learning with Homomorphic Encryption | NVIDIA Technical Blog, accessed May 10, 2025, [_https://developer.nvidia.com/blog/federated-learning-with-homomorphic-encryption/_](https://developer.nvidia.com/blog/federated-learning-with-homomorphic-encryption/)

1. Communication Efficient Differentially Private Federated Learning Using Second Order Information, accessed May 10, 2025, [_https://petsymposium.org/popets/2025/popets-2025-0032.pdf_](https://petsymposium.org/popets/2025/popets-2025-0032.pdf)

1. NeurIPS Poster Dynamic Personalized Federated Learning with Adaptive Differential Privacy, accessed May 10, 2025, [_https://neurips.cc/virtual/2023/poster/71639_](https://neurips.cc/virtual/2023/poster/71639)

1. Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey - MDPI, accessed May 10, 2025, [_https://www.mdpi.com/2079-9292/12/12/2703_](https://www.mdpi.com/2079-9292/12/12/2703)

1. Will Synthetic Data Finally Solve the Data Access Problem? Workshop summary - OpenReview, accessed May 10, 2025, [_https://openreview.net/pdf?id=0nw5rjqxw2_](https://openreview.net/pdf?id=0nw5rjqxw2)

1. Virginia Smith - Carnegie Mellon University, accessed May 10, 2025, [_http://www.cs.cmu.edu/~smithv/_](http://www.cs.cmu.edu/~smithv/)

1. Secure and Flexible Privacy-Preserving Federated Learning Based on Multi-Key Fully Homomorphic Encryption - MDPI, accessed May 10, 2025, [_https://www.mdpi.com/2079-9292/13/22/4478_](https://www.mdpi.com/2079-9292/13/22/4478)

1. MASKCRYPT: Federated Learning with Selective Homomorphic Encryption - University of Toronto, accessed May 10, 2025, [_https://iqua.ece.toronto.edu/papers/chenghao-tdsc24.pdf_](https://iqua.ece.toronto.edu/papers/chenghao-tdsc24.pdf)

1. Privacy-Preserving Analytical Pipelines Using Differential Privacy and Secure Multi-Party Computation in Federated Cloud Frameworks - Scholar9, accessed May 10, 2025, [_https://scholar9.com/publication/f9ca6ae6fb1f1a42668cd8b0fa340383.pdf_](https://scholar9.com/publication/f9ca6ae6fb1f1a42668cd8b0fa340383.pdf)

1. SMPAI: Secure Multi-Party Computation for Federated Learning - J.P. Morgan, accessed May 10, 2025, [_https://www.jpmorgan.com/content/dam/jpm/cib/complex/content/technology/ai-research-publications/pdf-9.pdf_](https://www.jpmorgan.com/content/dam/jpm/cib/complex/content/technology/ai-research-publications/pdf-9.pdf)

1. Belt and Braces: When Federated Learning Meets Differential Privacy, accessed May 10, 2025, [_https://cacm.acm.org/research/belt-and-braces-when-federated-learning-meets-differential-privacy/_](https://cacm.acm.org/research/belt-and-braces-when-federated-learning-meets-differential-privacy/)

1. Communication-Efficient Decentralized Multi-agent Machine Learning Method | AIM - AUTM, accessed May 10, 2025, [_https://aim.autm.net/public/project/77587/_](https://aim.autm.net/public/project/77587/)
