# **A Detailed Study Plan for Learning Generative AI**

Generative Artificial Intelligence represents a significant frontier in the field of AI, focusing on the development of models capable of producing new data instances that exhibit characteristics similar to those found in the training data.1 Unlike discriminative AI, which is designed to categorize or distinguish between data points, Generative AI aims to understand and replicate the underlying data distribution, enabling the creation of novel content. The demand for professionals with expertise in this rapidly evolving area is substantial, driven by the potential of these models to revolutionize various aspects of technology and industry, including the advancement of self-driving vehicles and the sophistication of recommendation systems.3 The transformative power of Generative AI extends across numerous sectors, offering innovative solutions in medical diagnostics, where synthetic medical images can enhance the training of diagnostic tools 4, and in creative industries, where these models can generate original artwork, music, and textual content.2

The ability of Generative AI to move beyond mere analysis and into the realm of creation signifies a paradigm shift in how machines interact with and understand the world. Its capacity to generate personalized experiences, automate content creation, and foster innovation highlights its broad appeal, extending beyond traditional technical applications.9 Understanding the practical application of these models requires a distinction between training, the process by which models learn from data, and inference, the stage where the trained model is applied to new, unseen data to generate outputs.10 This study plan is designed to provide a structured pathway for individuals seeking to gain a comprehensive understanding of Generative AI, encompassing foundational knowledge and practical skills through the utilization of freely available, open-source resources.

## **Module 1: Foundational Concepts**

### **1.1 Introduction to Machine Learning**

Machine learning, at its core, involves programming computers to optimize their performance on a specific task by learning from example data or past experiences.11 This learning process entails adjusting the parameters of a model based on the patterns identified within the training data.11 The fundamental components of this process include data storage, which provides the means to store and retrieve the large datasets necessary for effective learning; abstraction, where knowledge is extracted from the stored data through the creation and refinement of models; generalization, which is the ability of a learned model to apply its knowledge to new, unseen data that is similar to the training data; and evaluation, which involves measuring the performance and utility of the learned knowledge and providing feedback to improve the overall learning process.11

Machine learning encompasses several distinct types, each suited to different problems and data characteristics. Supervised learning involves training models on labeled data, where the desired output is known for each input. Unsupervised learning, on the other hand, focuses on discovering hidden patterns and structures within unlabeled data. Reinforcement learning trains agents to make decisions by interacting with an environment and learning from the rewards or penalties received. Semi-supervised learning utilizes a combination of both labeled and unlabeled data to improve model performance, often leveraging the abundance of unlabeled data to enhance the learning from a smaller set of labeled examples.12 Generative models, which are the focus of this study plan, often fall under the category of unsupervised learning as they aim to learn the inherent distribution of the data without relying on explicit labels.1

For those embarking on this learning journey, several excellent open-source introductory machine learning courses are available:

* **Introduction to Machine Learning | MIT Open Learning Library** 14 (URL: 14): This course from MIT emphasizes the principles and algorithms of machine learning from a modeling and prediction perspective. It covers the formulation of learning problems, concepts of representation, overfitting, and generalization. The course includes exercises in supervised and reinforcement learning, with applications to images and temporal sequences. The format includes lectures, lecture notes, exercises, labs, and homework problems, requiring an estimated effort of 12 hours per week over 13 weeks.14  
* **Machine Learning | Duke University on Coursera** 16 (URL: 16): This intermediate-level course from Duke University explores the practical applications of machine learning across various industries, including medical diagnostics, image recognition, and text prediction. It requires approximately 25 hours to complete and covers Python prerequisites, PyTorch installation, coding environments, logistic regression, multi-layer perceptrons, convolutional neural networks, natural language processing, and reinforcement learning.16  
* **Machine Learning Crash Course | Google** 17 (URL: 17): Google's fast-paced, practical introduction to machine learning features animated videos, interactive visualizations, and hands-on practice exercises. The self-contained modules cover topics such as linear regression, logistic regression, classification, working with categorical data, datasets, generalization, overfitting, neural networks, large language models, real-world ML considerations, and ML fairness.17  
* **CS50's Introduction to Artificial Intelligence with Python | Harvard on edX** 3 (URL: 3): This intermediate-level course explores the concepts and algorithms at the foundation of modern artificial intelligence, including machine learning. It delves into ideas behind game-playing engines, handwriting recognition, and machine translation. Through hands-on projects using Python, students gain experience with graph search algorithms, classification, optimization, and reinforcement learning.3 The course is 7 weeks long and requires 10-30 hours of effort per week.  
* **Intro to Machine Learning | Kaggle Learn** 18 (URL: 18): This beginner-friendly course on Kaggle takes approximately 3 hours to complete and focuses on the core ideas of machine learning, guiding learners to build their first models. The lessons cover how models work, basic data exploration, building a first model, model validation, underfitting and overfitting, random forests, and an introduction to machine learning competitions.18

These resources offer a diverse range of entry points into the field of machine learning, catering to various learning preferences and time commitments.3 For a broader overview of machine learning topics, the lecture notes from Stanford's CS229 course could serve as a valuable reference throughout this study plan.19 The course covers a wide array of subjects, including supervised learning, unsupervised learning, learning theory, and reinforcement learning, providing a comprehensive foundation for further exploration into Generative AI.19

### **1.2 Deep Learning Fundamentals**

Deep learning, a subfield of machine learning, distinguishes itself by utilizing neural networks with multiple layers to extract complex features from large datasets.20 These deep neural networks have shown remarkable success in tasks such as image recognition, natural language processing, and speech processing.20 The fundamental components of these networks include neurons, which are the basic computational units inspired by biological neurons; layers, which organize neurons into input, hidden, and output structures; weights and biases, which are the learnable parameters of the network adjusted during training; activation functions, which introduce non-linearity allowing the network to model complex relationships; loss functions, which quantify the error between the network's predictions and the actual values; backpropagation, the algorithm used to update the network's weights based on the calculated error; and the learning rate, a hyperparameter that controls the size of the weight updates during training.20

To gain a solid understanding of these deep learning fundamentals, several open-source courses and tutorials are highly recommended:

* **Intro to Deep Learning | Kaggle Learn** 21 (URL: 21): This beginner-level course on Kaggle focuses on using TensorFlow and Keras to build and train neural networks for structured data. It covers essential topics such as single neurons, deep neural networks, stochastic gradient descent, overfitting and underfitting, dropout and batch normalization techniques, and applying deep learning to binary classification tasks.21 This course builds upon the foundational concepts taught in Kaggle's "Intro to Machine Learning".21  
* **Intro to Deep Learning with PyTorch | Udacity** 22 (URL: 22): Udacity's intermediate-level course provides a comprehensive introduction to deep learning using the PyTorch framework. It explores the basic concepts behind neural networks, how they are trained, and how to use PyTorch to build and train deep neural networks for applications in natural language processing and computer vision. The course covers convolutional neural networks, style transfer techniques, recurrent neural networks for sequential data, and sentiment prediction using RNNs.22  
* **Neural Networks and Deep Learning | Coursera by deeplearning.ai** 23 (URL: 23): Taught by Andrew Ng, this beginner-level course on Coursera provides a foundational understanding of neural networks and deep learning. It covers the architecture and basic operations of neural networks, including logistic regression as a simple neural network, shallow neural networks with one hidden layer, and deeper neural networks with multiple layers. Key concepts such as activation functions, gradient descent, and backpropagation are explained in detail.23 The course requires intermediate Python programming skills.23  
* **Introduction to Deep Learning (6.S191) | MIT OpenCourseWare** 24 (URL: 24): This introductory course from MIT explores deep learning methods with applications in computer vision, natural language processing, biology, and more. It aims to provide students with foundational knowledge of deep learning algorithms and practical experience in building neural networks using TensorFlow. The course assumes familiarity with calculus and linear algebra.24  
* **Introduction to Deep Learning (I2DL) | SLDS LMU** 25 (URL: 25): This open and free introductory course on deep learning from SLDS LMU offers a wide range of self-study materials, including lecture videos, PDF slides, cheatsheets, exercises with solutions, and Jupyter notebooks in both Python (using PyTorch) and R (using TensorFlow). The course covers the necessary background on traditional artificial neural networks, backpropagation, online learning, and regularization. It also delves into special methods used in deep learning, such as drop-out and rectified linear units, as well as more advanced topics like convolutional layers, recurrent neural networks, auto-encoders, and generative adversarial networks (GANs).25

These diverse resources provide multiple avenues for acquiring a strong foundation in deep learning, accommodating different learning styles and preferences for deep learning frameworks.21 Additionally, the Deep Learning Tutorial on GeeksforGeeks 20 (URL: 20) offers a comprehensive overview of both basic and advanced topics in deep learning, making it a valuable supplementary resource for reinforcing learned concepts and exploring further into areas relevant to Generative AI.

### **1.3 Mathematical Prerequisites for Generative AI**

A solid understanding of certain mathematical concepts is crucial for effectively learning and working with Generative AI. These include:

* **Linear Algebra:** This branch of mathematics deals with vectors, matrices, and linear transformations, which are fundamental to the operations within neural networks.24 Concepts such as matrix multiplication, vector spaces, dimensionality reduction techniques like Principal Component Analysis (PCA), and Singular Value Decomposition (SVD) are particularly important in understanding how data is represented and processed in Generative AI models.  
* **Calculus:** Calculus provides the tools necessary for understanding and implementing the optimization algorithms used to train neural networks.24 Key concepts include derivatives (which measure the rate of change), gradients (which indicate the direction of steepest ascent or descent), the chain rule (for differentiating composite functions), and various optimization techniques like gradient descent, which are essential for adjusting the parameters of Generative AI models during training.  
* **Probability and Statistics:** Generative models often have a strong probabilistic foundation, requiring a good understanding of probability distributions (such as Gaussian, Bernoulli, and Categorical distributions), joint and marginal probabilities, conditional probability, Bayes' rule (fundamental for Bayesian inference), and the concept of expectation.26 Statistical concepts like maximum likelihood estimation and Bayesian approaches are also important for understanding how these models learn the underlying data distributions.

Several open-source resources can aid in reviewing and mastering these mathematical prerequisites:

* **Online Resources:** Websites like CalculusMadeEasy.org, ProbabilityCourse.com, and the collection of resources at Math for ML 28 offer free access to learning materials covering these topics specifically for machine learning.  
* **Visual Learning:** The engaging videos by 3Blue1Brown on YouTube and the comprehensive lessons available on Khan Academy 28 provide excellent visual and intuitive explanations of mathematical concepts, making them more accessible.  
* **Linear Algebra in Machine Learning:** While not a standalone math course explicitly mentioned in the snippets, the machine learning courses from MIT (6.036 14 and 6.S191 24) assume a prerequisite knowledge of linear algebra and will likely cover relevant concepts as needed within the context of machine learning algorithms.  
* **Matrix Calculus for Deep Learning:** The paper "The Matrix Calculus You Need For Deep Learning" 29 (available as a free PDF) is a focused resource that specifically covers the matrix calculus required for understanding and working with deep learning models, including those used in Generative AI.

These resources, particularly the online platforms recommended by the machine learning community 28, offer flexible and accessible ways to build or refresh the necessary mathematical foundation for delving into the intricacies of Generative AI.24

**Table 1: Open-Source Introductory Machine Learning Courses**

| Course Name | Provider | URL | Key Topics | Estimated Effort | Duration |
| :---- | :---- | :---- | :---- | :---- | :---- |
| Introduction to Machine Learning | MIT Open Learning Library | (https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/about) | Modeling and prediction, supervised learning, reinforcement learning, images, temporal sequences | 12 hours/week | 13 weeks |
| Machine Learning | Duke University on Coursera | [https://www.coursera.org/learn/machine-learning-duke](https://www.coursera.org/learn/machine-learning-duke) | Practical applications across industries, Python prerequisites, PyTorch, logistic regression, neural networks, CNNs, NLP, reinforcement learning | \~25 hours | Self-paced |
| Machine Learning Crash Course | Google | [https://developers.google.com/machine-learning/crash-course](https://developers.google.com/machine-learning/crash-course) | Linear regression, logistic regression, classification, categorical data, datasets, generalization, overfitting, neural networks, large language models, real-world ML, fairness | Self-paced | Self-paced |
| CS50's Introduction to Artificial Intelligence with Python | Harvard on edX | [https://pll.harvard.edu/course/cs50s-introduction-artificial-intelligence-python](https://pll.harvard.edu/course/cs50s-introduction-artificial-intelligence-python) | AI principles, Python implementation, graph search, reinforcement learning, machine learning, designing intelligent systems | 10-30 hours/week | 7 weeks |
| Intro to Machine Learning | Kaggle Learn | [https://www.kaggle.com/learn/intro-to-machine-learning](https://www.kaggle.com/learn/intro-to-machine-learning) | How models work, data exploration, first model, model validation, underfitting/overfitting, random forests, competitions | \~3 hours | Self-paced |

**Table 2: Open-Source Introductory Deep Learning Courses and Tutorials**

| Resource Name | Provider/Platform | URL | Key Topics | Framework Focus | Estimated Effort/Duration |
| :---- | :---- | :---- | :---- | :---- | :---- |
| Intro to Deep Learning | Kaggle Learn | [https://www.kaggle.com/learn/intro-to-deep-learning](https://www.kaggle.com/learn/intro-to-deep-learning) | Single neuron, deep neural networks, stochastic gradient descent, overfitting/underfitting, dropout, batch normalization, binary classification | TensorFlow/Keras | \~4 hours |
| Intro to Deep Learning with PyTorch | Udacity | [https://www.udacity.com/course/deep-learning-pytorch--ud188](https://www.udacity.com/course/deep-learning-pytorch--ud188) | Basics of deep learning, neural network operations, PyTorch fundamentals, convolutional neural networks, style transfer, recurrent neural networks, sentiment prediction | PyTorch | \~17 hours |
| Neural Networks and Deep Learning | Coursera by deeplearning.ai | [https://www.coursera.org/learn/neural-networks-deep-learning](https://www.coursera.org/learn/neural-networks-deep-learning) | Basics of neural networks, logistic regression, shallow neural networks, deep L-layer neural networks, key concepts in deep learning | None | Self-paced |
| Introduction to Deep Learning (6.S191) | MIT OpenCourseWare | [https://ocw.mit.edu/courses/6-s191-introduction-to-deep-learning-january-iap-2020/](https://ocw.mit.edu/courses/6-s191-introduction-to-deep-learning-january-iap-2020/) | Foundational knowledge of deep learning algorithms, practical experience building neural networks, applications in computer vision, NLP, biology | TensorFlow | Varies |
| Introduction to Deep Learning (I2DL) | SLDS LMU | [https://slds-lmu.github.io/i2dl/](https://slds-lmu.github.io/i2dl/) | Traditional ANNs, backpropagation, online learning, regularization, CNNs, RNNs, auto-encoders, GANs, materials in Python (PyTorch) and R (TensorFlow) | PyTorch/TensorFlow | Self-paced |
| Deep Learning Tutorial | GeeksforGeeks | [https://www.geeksforgeeks.org/deep-learning-tutorial/](https://www.geeksforgeeks.org/deep-learning-tutorial/) | Basics and advanced topics, neural networks, CNNs, RNNs, generative models, deep reinforcement learning | TensorFlow/PyTorch | Self-paced |

## **Module 2: Variational Autoencoders (VAEs)**

### **2.1 Understanding the Theory and Mathematics of VAEs**

Variational Autoencoders (VAEs) stand as a significant class of generative models in the field of machine learning. These models are designed to learn the latent distribution of input data, enabling them to not only reconstruct the original data but also to generate new data points that share similar characteristics.30 At their core, VAEs consist of three main components: an encoder, which takes the input data and maps it into a lower-dimensional latent space; the latent space itself, which serves as a compressed representation of the essential features of the data; and a decoder, which takes a point from the latent space and attempts to reconstruct the original input or generate a new sample.30

A key distinction between VAEs and traditional autoencoders lies in the nature of the latent space. While traditional autoencoders learn a deterministic, fixed representation for each input, VAEs learn a probabilistic representation. This means that the encoder in a VAE maps an input to the parameters of a probability distribution (typically a Gaussian distribution) in the latent space, rather than to a single, fixed vector.30 This probabilistic approach allows VAEs to capture the uncertainty and variability inherent in the data. The latent variables within this space represent the underlying factors of variation in the dataset.33 The goal is to create a latent space that is not only compressed but also well-organized and continuous, facilitating meaningful interpolation and generation.33

The mathematical formulation of VAEs centers around maximizing the Evidence Lower Bound (ELBO). The ELBO is a proxy for the log-likelihood of the data, which is often intractable to compute directly. The ELBO comprises two key terms: the reconstruction loss, which measures how well the decoder can reconstruct the input from a sampled latent vector, and the KL divergence, which measures the difference between the learned latent distribution and a prior distribution (usually a standard normal distribution).32 The reconstruction loss encourages the model to retain the essential information from the input, while the KL divergence acts as a regularizer, ensuring that the latent space has good properties for generation, such as continuity and completeness.32 The ELBO can be mathematically expressed as: L(q)=Ez∼q(z∣x)​\[logp(x∣z)\]−KL(q(z∣x)∣∣p(z)).35

A crucial technique for training VAEs is the reparameterization trick. This trick addresses the issue that the sampling process from the latent distribution is non-deterministic, which would prevent the flow of gradients during backpropagation. The reparameterization trick allows us to express the sampling process as a deterministic function of the parameters of the latent distribution (mean and variance) and a random noise variable drawn from a fixed distribution (e.g., a standard normal distribution).31 For a Gaussian latent distribution, this is commonly represented as: z=μ+σ⋅ϵ, where ϵ∼N(0,I).31 This reformulation makes the sampling process differentiable, enabling the use of gradient-based optimization algorithms like backpropagation to train the VAE.31

For a deeper understanding of the theory behind VAEs, several resources are available. Carl Doersch's "Tutorial on Variational Autoencoders" 37 provides a comprehensive overview of the intuitions and mathematics. The seminal paper "An Introduction to Variational Autoencoders" by Kingma and Welling 38 offers a more formal treatment of the subject. Additionally, blog posts on websites like Jeremy Jordan's 35 and Jaan.io 39 provide accessible explanations of the core concepts and mathematical underpinnings of VAEs.

### **2.2 VAEs and Probabilistic Graphical Models**

Variational Autoencoders are not just deep learning architectures but are also deeply rooted in the framework of probabilistic graphical models.40 Probabilistic graphical models are statistical models that use graphs to represent the probabilistic relationships among a set of random variables. In the context of VAEs, the relationships between the observed data, the unobserved (latent) variables, and the parameters of the model can be visualized as a graph, illustrating how these components depend on each other.40

The encoder in a VAE plays the role of learning an approximate posterior distribution over the latent variables, conditioned on the observed input data.34 In Bayesian inference, the posterior distribution p(z∣x) represents our updated beliefs about the latent variables (z) after observing the data (x). However, this posterior is often computationally intractable, meaning it cannot be calculated directly. VAEs overcome this by using a neural network (the encoder) to learn a tractable approximation qϕ​(z∣x) to this true posterior.34

The structure of a VAE can be represented as a directed acyclic graph (DAG), a common way to depict probabilistic graphical models.40 In this graph, the latent variables (z) are typically considered the "parents" of the observed data (x), indicating that the data is generated from the latent representation. The encoder learns to infer the distribution over these latent variables given the observed data, while the decoder learns the conditional distribution of the data given the latent variables.40 Snippet 41 provides visual examples of these graphical models for both standard and conditional VAEs.

The task of finding this approximate posterior in VAEs is achieved through variational Bayesian methods.34 Variational inference is a technique used to approximate intractable integrals that arise in Bayesian inference. In VAEs, the goal is to find an approximate posterior distribution qϕ​(z∣x) that is "close" to the true posterior pθ​(z∣x). The "closeness" between these distributions is typically measured using the Kullback-Leibler (KL) divergence. By minimizing this divergence (or equivalently, maximizing the ELBO), VAEs can learn a meaningful and generative latent space for complex data.34

For further exploration of the connection between VAEs and probabilistic graphical models, the Wikipedia page on Variational Autoencoders 40 provides a good starting point. Additionally, lecture notes from courses such as those at CMU 42, Illinois 43, and Imperial College London 41 often delve into this theoretical relationship, providing a deeper understanding of the statistical foundations of VAEs.

### **2.3 Variational Inference in the Context of VAEs**

Variational inference is a cornerstone of Variational Autoencoders, serving as the primary method for approximating the often-intractable probability distributions that arise in Bayesian modeling.31 In the context of VAEs, the central challenge is to estimate the posterior distribution pθ​(z∣x), which represents the probability of the latent variables (z) given the observed data (x). This distribution is typically very complex and cannot be computed directly. Variational inference offers a solution by introducing a simpler, tractable distribution qϕ​(z∣x), parameterized by ϕ, which we aim to make as close as possible to the true posterior.31

VAEs employ an inference network, typically implemented as the encoder, to learn the parameters ϕ of this approximate posterior distribution over the latent variables given the input data.39 This inference network takes an input data point and outputs the parameters that define the approximate posterior distribution in the latent space (e.g., the mean and variance of a Gaussian distribution). A key aspect of VAEs is the use of amortized variational inference.34 Instead of learning a separate set of parameters for the variational distribution for each individual data point, the encoder learns a single set of parameters that are shared across all data samples. This allows the model to efficiently approximate the posterior for new, unseen data points with a single forward pass through the encoder, without requiring a separate optimization process for each new sample.34

The objective of variational inference in VAEs is to find the parameters ϕ that make the approximate posterior qϕ​(z∣x) as similar as possible to the true posterior pθ​(z∣x). This similarity is quantified by the Kullback-Leibler (KL) divergence. Minimizing the KL divergence between qϕ​(z∣x) and the prior distribution p(z) (which is often chosen to be a simple distribution like a standard normal) is equivalent to maximizing the Evidence Lower Bound (ELBO).33 Maximizing the ELBO encourages the encoder to learn a latent distribution that is both close to the prior and allows the decoder to accurately reconstruct the input data.33

For further understanding of variational inference in the context of VAEs, resources like the discussions on StackExchange 47 offer valuable insights. The blog post on Jaan.io 39 also provides a clear explanation of the probability model framework used in VAEs, which relies heavily on variational inference. For a more formal treatment, the section on "Variational Inference" in the "Auto-Encoding Variational Bayes" paper 45 provides a detailed mathematical explanation of the concepts.

### **2.4 Exploring Open-Source VAE Implementations (TensorFlow and PyTorch)**

For learners seeking to gain practical experience with Variational Autoencoders, numerous open-source implementations are available in popular deep learning frameworks like TensorFlow and PyTorch. These resources provide valuable opportunities to study, modify, and experiment with VAEs.

**TensorFlow:**

* The official TensorFlow website offers a tutorial on Conditional Variational Autoencoders (CVAE) 49 (URL: 49), which demonstrates how to train a VAE on the MNIST dataset. Another tutorial on the TensorFlow website covers basic autoencoders 50 (URL: 50), which can provide foundational understanding before diving into VAEs.  
* Kaggle notebooks, such as "Learn by Example: Variational Autoencoder" 51 (URL: 51), offer practical, hands-on implementations of VAEs using TensorFlow and Keras on the MNIST dataset.  
* LearnOpenCV provides a comprehensive tutorial on Variational Autoencoders in TensorFlow 52 (URL: 52), which covers training VAEs on both the Fashion MNIST dataset and a cartoon dataset, including visualization of the latent space.  
* The Paperspace blog features a tutorial on how to build a Variational Autoencoder in Keras 53 (URL: 53), focusing on the MNIST dataset and explaining the encoder, decoder, and training process.  
* GitHub hosts a variety of open-source TensorFlow implementations of VAEs, including repositories like "Tensorflow-VAE-" 54 (URL: 54), "VAE-Tensorflow" by ChengBinJin 55 (URL: 55) which implements VAEs for MNIST and the FreyFace dataset, "CVAE" by mingukkang 56 (URL: 56) for Conditional VAEs, "VAE-Tensorflow" by shaohua0116 57 (URL: 57), "variational-autoencoder" by conormdurkan 58 (URL: 58) focused on MNIST, and "vae" by ondrejbiza 59 (URL: 59). Additionally, "Variational-Graph-Auto-encoders-Tensorflow-2-Spektral-" by FilippoMB 60 (URL: 60) provides an implementation for graph data.

**PyTorch:**

* The official PyTorch tutorials 61 (URL: 61) include examples and concepts relevant to building VAEs.  
* Kaggle notebooks, such as "PyTorch Vanilla GAN" by rafat97 62 (URL: 62), while focused on GANs, may contain relevant code snippets or structures applicable to VAEs as well, as GANs and VAEs are both generative models.  
* Datacamp offers a step-by-step tutorial on implementing a VAE in PyTorch 44 (URL: 44) using the MNIST dataset, covering the encoder, decoder, loss function, and training loop.  
* PyImageSearch provides detailed tutorials on implementing VAEs with PyTorch, including "A Deep Dive into Variational Autoencoders with PyTorch" 63 (URL: 63) using the Fashion MNIST dataset, and "Generating Faces Using Variational Autoencoders with PyTorch" 64 (URL: 64) which utilizes the CelebA dataset.  
* GitHub hosts numerous PyTorch implementations of VAEs, such as "PyTorch-VAE" by AntixK 65 (URL: 65), which is a collection of various VAE models trained on the CelebA dataset, "Pytorch-VAE-tutorial" by Jackson-Kang 66 (URL: 66) with implementations of VAE and VQ-VAE, "VariationalAutoEncoder" by Robotmurlock 45 (URL: 45), "PyTorch-VAE" by ethanluoyc 68 (URL: 68), "s-vae-pytorch" by nicola-decao 69 (URL: 69) for hyperspherical VAEs, "Pytorch-VAE" by SashaMalysheva 70 (URL: 70) for Cifar10, "Variational-autoencoder" by bvezilic 71 (URL: 71), "ladder-vae-pytorch" by addtt 72 (URL: 72) for Ladder VAEs, "variational\_autoencoder\_pytorch" by geyang 73 (URL: 73), and "Variational-Autoencoder-PyTorch" by bhpfelix 74 (URL: 74) trained on CelebA, as well as "cVAE" by unnir 75 (URL: 75) for conditional VAEs.

The abundance of these open-source resources, with implementations on various datasets like MNIST, Fashion MNIST, and CelebA 44, highlights the active community and provides learners with a wide range of practical examples to study and build upon. The availability of implementations in both TensorFlow and PyTorch ensures that individuals can work with their preferred framework.44

**Table 3: Open-Source VAE Implementations**

| Framework | Repository/Tutorial Name | URL | Dataset Used (if specified) | Key Features/Notes |
| :---- | :---- | :---- | :---- | :---- |
| TensorFlow | CVAE Tutorial | [https://www.tensorflow.org/tutorials/generative/cvae](https://www.tensorflow.org/tutorials/generative/cvae) | MNIST | Demonstrates training a VAE |
| TensorFlow | Learn by Example: Variational Autoencoder | [https://www.kaggle.com/code/charel/learn-by-example-variational-autoencoder](https://www.kaggle.com/code/charel/learn-by-example-variational-autoencoder) | MNIST | Keras implementation |
| TensorFlow | VAE in TensorFlow | [https://learnopencv.com/variational-autoencoder-in-tensorflow/](https://learnopencv.com/variational-autoencoder-in-tensorflow/) | Fashion MNIST, Cartoon | Covers theory and implementation |
| TensorFlow | Build a VAE in Keras | [https://blog.paperspace.com/how-to-build-variational-autoencoder-keras/](https://blog.paperspace.com/how-to-build-variational-autoencoder-keras/) | MNIST | Keras implementation |
| TensorFlow | Tensorflow-VAE- | ([https://github.com/blackhat-coder/Tensorflow-VAE-](https://github.com/blackhat-coder/Tensorflow-VAE-)) | Unspecified | Experimental implementation |
| TensorFlow | VAE-Tensorflow | ([https://github.com/ChengBinJin/VAE-Tensorflow](https://github.com/ChengBinJin/VAE-Tensorflow)) | MNIST, FreyFace | Includes denoising |
| TensorFlow | CVAE | [https://github.com/mingukkang/CVAE](https://github.com/mingukkang/CVAE) | MNIST | Conditional VAE |
| TensorFlow | VAE-Tensorflow | ([https://github.com/shaohua0116/VAE-Tensorflow](https://github.com/shaohua0116/VAE-Tensorflow)) | Unspecified | For a deep learning course |
| TensorFlow | variational-autoencoder | [https://github.com/conormdurkan/variational-autoencoder](https://github.com/conormdurkan/variational-autoencoder) | MNIST | Well-documented |
| TensorFlow | vae | [https://github.com/ondrejbiza/vae](https://github.com/ondrejbiza/vae) | Unspecified | Includes VQ-VAE |
| TensorFlow | Variational-Graph-Auto-encoders-Tensorflow-2-Spektral- | ([https://github.com/FilippoMB/Variational-Graph-Auto-encoders-Tensorflow-2-Spektral-](https://github.com/FilippoMB/Variational-Graph-Auto-encoders-Tensorflow-2-Spektral-)) | Graph data | Spektral library |
| PyTorch | PyTorch Tutorials | [https://pytorch.org/tutorials/](https://pytorch.org/tutorials/) | Various | Includes relevant examples |
| PyTorch | VAE in PyTorch | [https://www.datacamp.com/tutorial/variational-autoencoders](https://www.datacamp.com/tutorial/variational-autoencoders) | MNIST | Step-by-step implementation |
| PyTorch | VAE Tutorial | [https://github.com/Jackson-Kang/Pytorch-VAE-tutorial](https://github.com/Jackson-Kang/Pytorch-VAE-tutorial) | MNIST, CIFAR-10 | Simple tutorial with VAE and VQ-VAE |
| PyTorch | VAE with PyTorch | [https://pyimagesearch.com/2023/10/02/a-deep-dive-into-variational-autoencoders-with-pytorch/](https://pyimagesearch.com/2023/10/02/a-deep-dive-into-variational-autoencoders-with-pytorch/) | Fashion MNIST | Detailed explanation and implementation |
| PyTorch | Generating Faces with VAEs | [https://pyimagesearch.com/2023/10/23/generating-faces-using-variational-autoencoders-with-pytorch/](https://pyimagesearch.com/2023/10/23/generating-faces-using-variational-autoencoders-with-pytorch/) | CelebA | Focuses on face generation |
| PyTorch | PyTorch-VAE | (https://github.com/AntixK/PyTorch-VAE) | CelebA | Collection of VAEs |
| PyTorch | VariationalAutoEncoder | (https://github.com/Robotmurlock/VariationalAutoEncoder) | Unspecified | Simple implementation |
| PyTorch | pytorch-vae | [https://github.com/ethanluoyc/pytorch-vae](https://github.com/ethanluoyc/pytorch-vae) | Unspecified | Includes a blog post link |
| PyTorch | s-vae-pytorch | [https://github.com/nicola-decao/s-vae-pytorch](https://github.com/nicola-decao/s-vae-pytorch) | Unspecified | Hyperspherical VAEs |
| PyTorch | Pytorch-VAE | (https://github.com/SashaMalysheva/Pytorch-VAE) | Cifar10 | Implementation for Cifar10 |
| PyTorch | Variational-autoencoder | [https://github.com/bvezilic/Variational-autoencoder](https://github.com/bvezilic/Variational-autoencoder) | MNIST | Another implementation on MNIST |
| PyTorch | ladder-vae-pytorch | [https://github.com/addtt/ladder-vae-pytorch](https://github.com/addtt/ladder-vae-pytorch) | SVHN, CIFAR10, CelebA, multi-dSprites | Ladder VAE |
| PyTorch | variational\_autoencoder\_pytorch | [https://github.com/geyang/variational\_autoencoder\_pytorch](https://github.com/geyang/variational_autoencoder_pytorch) | MNIST | Includes theory blog post |
| PyTorch | Variational-Autoencoder-PyTorch | ([https://github.com/bhpfelix/Variational-Autoencoder-PyTorch](https://github.com/bhpfelix/Variational-Autoencoder-PyTorch)) | CelebA | Trained on CelebA |
| PyTorch | cVAE | [https://github.com/unnir/cVAE](https://github.com/unnir/cVAE) | MNIST | Simple and clean Conditional VAE |

## **Module 3: Generative Adversarial Networks (GANs)**

### **3.1 Delving into the Theory of GANs and the Minimax Game**

Generative Adversarial Networks (GANs) represent a powerful framework for training generative models through an adversarial process involving two neural networks: a generator and a discriminator.13 The generator network's role is to create synthetic data that is as realistic as possible, aiming to mimic the distribution of the real training data.13 Conversely, the discriminator network acts as a binary classifier, tasked with distinguishing between real data samples from the training set and fake data samples produced by the generator.13

The training of GANs is based on the principles of minimax game theory.2 The generator and the discriminator are engaged in a competitive game where the generator tries to "fool" the discriminator into believing that its generated data is real, while the discriminator strives to correctly identify real and fake samples.2 This adversarial process drives both networks to improve their capabilities over time. The generator learns to produce increasingly realistic data, and the discriminator becomes better at detecting fakes.76 The training process aims to reach a state of Nash equilibrium, where neither the generator nor the discriminator can improve its performance further without affecting the other.7

The original formulation of the GAN loss function reflects this minimax game. The discriminator aims to maximize its ability to correctly classify both real data as real and fake data as fake. The generator, on the other hand, aims to minimize the probability that the discriminator will classify its generated data as fake.77 This can be represented mathematically as a minimax optimization problem where one network tries to minimize a value while the other tries to maximize it, with the value being related to the discriminator's ability to distinguish between real and generated data.77

For a comprehensive understanding of GAN theory, the original paper "Generative Adversarial Networks" by Ian Goodfellow and his colleagues 13 is an essential resource. Tutorials on platforms like GeeksforGeeks 76 and Machine Learning Mastery 13 provide accessible explanations of GAN concepts. Additionally, blog posts on OpenSource.com 1 and Analytics Vidhya 84 offer introductory guides and overviews of GANs and their underlying principles.

### **3.2 Exploring Different GAN Architectures (Vanilla GAN, DCGAN, StyleGAN)**

Over the years, various architectures have been developed based on the fundamental principles of Generative Adversarial Networks, each with its own strengths and applications. Three notable architectures include Vanilla GAN, Deep Convolutional GAN (DCGAN), and StyleGAN.

**Vanilla GAN** is the most basic form of a GAN, where both the generator and the discriminator are typically built using multilayer perceptrons (MLPs).76 The generator takes a random noise vector as input and attempts to transform it into a realistic data sample, while the discriminator evaluates whether the input data is real or generated. Vanilla GANs serve as a foundational model but can sometimes suffer from training instability and mode collapse, where the generator produces a limited variety of outputs.76

**Deep Convolutional GAN (DCGAN)** represents a significant advancement for image generation tasks by incorporating convolutional neural networks (CNNs) into both the generator and discriminator architectures.76 DCGANs introduce specific architectural guidelines, such as replacing pooling layers with strided convolutions and using batch normalization, to help stabilize the training process and improve the quality of generated images.85 The generator in a DCGAN typically takes a low-dimensional noise vector and upsamples it through a series of transposed convolutional layers to produce an image, while the discriminator uses convolutional layers to learn features that distinguish between real and generated images.85

**StyleGAN** is a more recent architecture that focuses on generating high-resolution images with an unprecedented level of control over image styles and features.76 Developed by NVIDIA, StyleGAN introduces a style-based generator that learns to separate high-level attributes (like pose and identity) from stochastic variations (like hair and freckles). This is achieved through a mapping network that transforms the input latent code into an intermediate style vector, which is then used to control the image generation process at different scales within the generator.84 StyleGAN has shown remarkable results in generating photorealistic images, particularly of human faces, and allows for intuitive manipulation of generated content.84

For further exploration of these GAN architectures, the GeeksforGeeks tutorial on GAN types 76 provides a good overview. PyTorch offers a detailed tutorial on implementing DCGANs 91 (URL: 91), while TensorFlow provides its own DCGAN tutorial 92 (URL: 92). The original StyleGAN papers 88 (URL: 99) and their open-source implementations 88 (URL: 88) on GitHub are valuable resources for understanding this advanced architecture. Kaggle notebooks also offer practical examples of DCGAN 101 (URL: 101) and StyleGAN 102 (URL: 102) implementations.

### **3.3 Open-Source GAN Implementations and Tutorials (TensorFlow and PyTorch)**

The open-source community has provided a wealth of resources for learning and implementing Generative Adversarial Networks in both TensorFlow and PyTorch. These implementations and tutorials cover various GAN architectures, from basic Vanilla GANs to more advanced models like DCGAN and StyleGAN.

**TensorFlow:**

* TensorFlow offers its own GAN library, TF-GAN 103 (also known as Tensorflow Graphics), which provides a lightweight and efficient framework for building and training GANs. It includes well-tested loss functions and evaluation metrics, simplifying the implementation process.103  
* For Vanilla GAN implementations in TensorFlow, GitHub repositories like "vanilla\_GAN" by togheppi 104 (URL: 104) and the implementation discussed in the TensorFlow GAN tutorial 95 (URL: 95) can be useful.  
* DCGAN implementations in TensorFlow are widely available on GitHub, including "DCGAN-tensorflow" by carpedm20 105 (URL: 105), "dcgan" by kpandey008 106 (URL: 106), and "DCGAN-tensorflow" by cankocagil 107 (URL: 107). The official TensorFlow tutorial on DCGANs 92 (URL: 92) also provides a step-by-step guide.  
* StyleGAN implementations in TensorFlow can be found in the official NVIDIA repository 88 (URL: 88) and other open-source projects like "StyleGAN-Tensorflow-2.0" by manicman1999 (mentioned in 108).

**PyTorch:**

* PyTorch also has its own GAN library, Torch-GAN 103 (URL: 103), which aims to make GAN development easier with a modular design and customizable components.  
* Vanilla GAN implementations in PyTorch are available in repositories such as "vanilla\_GAN" by togheppi 104 (URL: 104), "pytorch-GANs" by gordicaleksa 109 (URL: 109), "pytorch-vanilla-gan" by rafat97 62 (URL: 62), and the simple Vanilla GAN built with PyTorch 110 (URL: 110).  
* DCGAN implementations in PyTorch include "DCGAN" by cankocagil 107 (URL: 107), "dcgan" by kpandey008 106 (URL: 106), and the PyTorch DCGAN tutorial 91 (URL: 91).  
* StyleGAN implementations in PyTorch can be found in repositories like "StyleGAN.pytorch" by huangzh13 100 (URL: 100) and the PyTorch implementation of the StyleGAN Generator 102 (URL: 102) used in a Kaggle notebook.

Beyond these specific architectures, the PyTorch-GAN repository 111 (URL: 111) on GitHub serves as a valuable collection of PyTorch implementations for a wide variety of GANs presented in research papers. Additionally, GAN toolkits like the IBM GAN Toolkit 103 (URL: 103) provide a no-code way to implement state-of-the-art computer vision technology and offer multi-library support (PyTorch, Keras, TensorFlow).

The availability of these open-source resources, including dedicated libraries, tutorials, and a diverse range of implementations for different GAN types and frameworks 22, provides an excellent foundation for learners to explore and experiment with Generative Adversarial Networks.

**Table 4: Open-Source GAN Implementations**

| GAN Type | Framework | Repository/Tutorial Name | URL | Dataset Used (if specified) | Key Features/Notes |
| :---- | :---- | :---- | :---- | :---- | :---- |
| Vanilla GAN | TensorFlow | vanilla\_GAN | [https://github.com/togheppi/vanilla\_GAN](https://github.com/togheppi/vanilla_GAN) | Unspecified | Simple implementation |
| Vanilla GAN | TensorFlow | Implementing GANs in TensorFlow | [https://www.digitalocean.com/community/tutorials/implementing-gans-in-tensorflow](https://www.digitalocean.com/community/tutorials/implementing-gans-in-tensorflow) | Quadratic distribution | Basic implementation |
| Vanilla GAN | PyTorch | vanilla\_GAN | [https://github.com/togheppi/vanilla\_GAN](https://github.com/togheppi/vanilla_GAN) | Unspecified | Simple implementation |
| Vanilla GAN | PyTorch | pytorch-GANs | [https://github.com/gordicaleksa/pytorch-GANs](https://github.com/gordicaleksa/pytorch-GANs) | MNIST | Includes interpolation |
| Vanilla GAN | PyTorch | pytorch-vanilla-gan | [https://www.kaggle.com/code/rafat97/pytorch-vanilla-gan](https://www.kaggle.com/code/rafat97/pytorch-vanilla-gan) | MNIST | Basic tutorial |
| Vanilla GAN | PyTorch | Building a simple vanilla GAN with PyTorch | [https://machinecurve.com/index.php/2021/07/17/building-a-simple-vanilla-gan-with-pytorch](https://machinecurve.com/index.php/2021/07/17/building-a-simple-vanilla-gan-with-pytorch) | MNIST | Step-by-step guide |
| DCGAN | TensorFlow | DCGAN-tensorflow | (https://github.com/carpedm20/DCGAN-tensorflow) | MNIST, CelebA | Well-known implementation |
| DCGAN | TensorFlow | dcgan | [https://github.com/kpandey008/dcgan](https://github.com/kpandey008/dcgan) | MNIST | Pytorch and Tensorflow |
| DCGAN | TensorFlow | DCGAN-tensorflow | ([https://github.com/cankocagil/DCGAN](https://github.com/cankocagil/DCGAN)) | CelebA | Based on PyTorch official repo |
| DCGAN | TensorFlow | TensorFlow DCGAN tutorial | [https://www.tensorflow.org/tutorials/generative/dcgan](https://www.tensorflow.org/tutorials/generative/dcgan) | MNIST | Official tutorial |
| DCGAN | PyTorch | DCGAN | (https://github.com/cankocagil/DCGAN) | CelebA | Based on PyTorch official repo |
| DCGAN | PyTorch | dcgan | [https://github.com/kpandey008/dcgan](https://github.com/kpandey008/dcgan) | MNIST | Pytorch and Tensorflow |
| DCGAN | PyTorch | Implementing Deep Convolutional GAN (DCGAN) with PyTorch | [https://debuggercafe.com/dcgan-pytorch/](https://debuggercafe.com/dcgan-pytorch/) | CIFAR10 | Detailed tutorial |
| DCGAN | PyTorch | PyTorch DCGAN tutorial | [https://pytorch.org/tutorials/beginner/dcgan\_faces\_tutorial.html](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html) | CelebA | Official tutorial |
| StyleGAN | TensorFlow | StyleGAN | [https://github.com/NVlabs/stylegan](https://github.com/NVlabs/stylegan) | CelebA-HQ, FFHQ | Official implementation |
| StyleGAN | TensorFlow | StyleGAN-Tensorflow-2.0 | Mentioned in 108 | EarthPorn | Reimplementation in TF 2.0 |
| StyleGAN | PyTorch | StyleGAN.pytorch | (https://github.com/huangzh13/StyleGAN.pytorch) | ChineseGirl, FFHQ, WebCaricature | Unofficial implementation with full features |
| StyleGAN | PyTorch | Image Generation using Stylegan pre-trained model | [https://www.kaggle.com/code/songseungwon/image-generation-using-stylegan-pre-trained-model/notebook](https://www.kaggle.com/code/songseungwon/image-generation-using-stylegan-pre-trained-model/notebook) | FFHQ | Using pre-trained model |
| GAN Collection | PyTorch | PyTorch-GAN | ([https://github.com/eriklindernoren/PyTorch-GAN](https://github.com/eriklindernoren/PyTorch-GAN)) | Various | Collection of GAN implementations |
| Toolkit | Multi-library | IBM GAN Toolkit | [https://www.analyticsvidhya.com/blog/2020/08/top-5-gan-libraries-you-must-know/](https://www.analyticsvidhya.com/blog/2020/08/top-5-gan-libraries-you-must-know/) | Various | Supports PyTorch, Keras, TensorFlow |

## **Module 4: Transformer-Based Generative Models**

### **4.1 Understanding the Transformer Network Architecture**

The Transformer network represents a groundbreaking architecture in deep learning, primarily known for its success in natural language processing but increasingly applied to other domains such as computer vision.114 Its core innovation lies in the self-attention mechanism, which allows the model to weigh the importance of different parts of an input sequence when processing it.114 The original Transformer architecture follows an encoder-decoder structure.115 The encoder processes the input sequence and transforms it into a context vector or a sequence of context vectors, while the decoder uses this representation to generate the output sequence.115

Transformers offer several advantages over earlier recurrent neural network (RNN) architectures. Notably, they can process the entire input sequence in parallel, leading to significantly faster training times, especially when utilizing GPUs.114 Furthermore, the self-attention mechanism enables Transformers to effectively capture long-range dependencies within sequences, a challenge that RNNs often struggle with.114

The architecture of a Transformer network comprises several key components working in concert. **Self-attention** allows each element in the input sequence to attend to all other elements, computing a weighted sum of their representations to produce a contextualized representation for itself.115 **Multi-head attention** extends this by using multiple attention mechanisms in parallel, allowing the model to attend to different aspects of the input sequence simultaneously.114 **Positional encoding** is crucial as the self-attention mechanism itself is order-agnostic. Positional encodings add information about the position of each token in the sequence to the input embeddings.115 Each encoder and decoder layer also includes a **feed-forward network**, which applies further transformations to the representations.115 Finally, **residual connections** and **layer normalization** are used throughout the network to facilitate training and improve performance.115

To delve deeper into the intricacies of the Transformer architecture, the seminal paper "Attention Is All You Need" 114 provides a comprehensive technical description. Accessible explanations can also be found in blog posts on IBM Think 116 and Google Research.143 For a more hands-on approach, tutorials on platforms like DataCamp 118 and LearnOpenCV 127 offer practical guidance on building and understanding Transformer networks.

### **4.2 The Self-Attention Mechanism and Positional Encoding**

At the heart of the Transformer architecture lies the **self-attention mechanism**, a process that allows the model to understand the relationships between different words (or tokens) within an input sequence.116 This mechanism involves three key components for each token: the **query**, which represents what the token is looking for; the **key**, which represents what the token offers; and the **value**, which is the actual information the token holds.116 The attention mechanism calculates an **attention score** for each pair of tokens by comparing their queries and keys (typically using a dot product). These scores are then normalized (often using a softmax function) to obtain weights, which indicate the importance of each token in relation to others. Finally, a weighted sum of the value vectors is computed to produce the output for each token, effectively creating a context-aware representation.116

To enhance the capabilities of self-attention, Transformers employ **multi-head attention**.114 This technique involves running the self-attention mechanism multiple times in parallel, with each "head" using different sets of query, key, and value weight matrices. The outputs from these multiple attention heads are then concatenated and linearly transformed to produce the final output. Multi-head attention allows the model to attend to different aspects of the input sequence simultaneously, capturing a richer understanding of the relationships between tokens.114

Since the self-attention mechanism processes all tokens in parallel, it inherently lacks information about the order of tokens in the sequence. To address this, Transformers use **positional encoding**.115 Positional encodings are vectors that provide information about the position of each token in the sequence. These vectors are added to the input embeddings before they are fed into the Transformer layers. A common approach is to use sine and cosine functions of different frequencies to create these positional encoding vectors, ensuring that each position has a unique encoding.118 This allows the model to distinguish between tokens based on their position in the sequence, which is crucial for understanding the meaning of language.115

For further exploration of these core mechanisms, blog posts on H2O.ai 147 and Sebastian Raschka's blog 128 offer detailed explanations of self-attention. Tutorials on LearnOpenCV 127 and Machine Learning Mastery 137 provide practical insights into positional encoding. Additionally, the DeepLearning.AI blog 122 offers a good overview of the Transformer architecture, including self-attention.

### **4.3 Encoder-Decoder Architectures in Transformers**

The original Transformer architecture is built upon an **encoder-decoder structure**, where both the encoder and the decoder consist of stacks of identical layers.118 The **encoder**'s primary role is to process the input sequence and transform it into a rich, contextualized representation, often referred to as a context vector or a sequence of context vectors.123 This encoded representation aims to capture all the relevant information from the input sequence in a format that the decoder can then use to generate the desired output.123 Each encoder layer typically contains a multi-head self-attention mechanism followed by a position-wise feed-forward network, with residual connections and layer normalization applied around each sub-layer.120

The **decoder**'s function is to generate the output sequence based on the encoded representation from the encoder and its own previously generated outputs.123 This process of generating the output token by token, conditioned on the previously generated tokens, is known as autoregressive generation.123 Each decoder layer includes a masked multi-head self-attention mechanism, a multi-head attention mechanism that attends to the output of the encoder, and a position-wise feed-forward network, again with residual connections and layer normalization.120 The **masked self-attention** in the decoder is crucial for maintaining the autoregressive property by preventing the decoder from attending to subsequent positions in the output sequence that have not yet been generated.120

For a more detailed understanding of the encoder-decoder architecture in Transformers, blog posts on platforms like Hugging Face 125 and IBM Think 123 offer valuable explanations. Tutorials available on the d2l.ai website 124 provide mathematical and conceptual clarity. Additionally, Jupyter notebooks on GitHub, such as the one by patrickvonplaten 148, offer practical insights into the implementation and workings of encoder-decoder models based on the Transformer architecture.

### **4.4 Generative Pre-trained Transformers (GPT)**

Generative Pre-trained Transformers (GPT) represent a significant evolution in Transformer architectures, primarily utilizing a decoder-only structure for language generation tasks.126 Unlike the original Transformer which has both an encoder and a decoder, GPT models consist of a stack of decoder layers. The key idea behind GPT is **pre-training** on massive datasets of unlabeled text.114 During pre-training, the model learns to predict the next word in a sequence, effectively capturing a vast amount of knowledge about language structure and patterns.114

After this pre-training phase, the GPT model can be **fine-tuned** on smaller, task-specific datasets to perform a wide range of downstream tasks, such as text classification, question answering, and more.114 This pre-train and fine-tune paradigm has proven highly effective in leveraging the vast amounts of available text data to create powerful language models.

Prominent examples of GPT models include the GPT-3 series, which have demonstrated remarkable capabilities in generating coherent and contextually relevant text across various domains.120 These models have a very large number of parameters, allowing them to capture intricate details of language.

For those interested in learning more about GPT models, the Wikipedia page on Generative Pre-trained Transformer 134 provides a comprehensive overview. Blog posts on platforms like LLM Models 119, BuiltIn 117, and Turing.com 120 offer more accessible explanations of their architecture, training, and capabilities.

### **4.5 Open-Source Transformer Resources**

The open-source community has been instrumental in making Transformer technology accessible through various libraries, models, and tutorials. One of the most significant resources is the **Hugging Face Transformers library** 119 (URL: 150). This library provides thousands of pre-trained Transformer models, including various GPT variants, along with tools and functionalities for building, training, and deploying custom Transformer models. It supports both PyTorch and TensorFlow backends, making it a versatile choice for researchers and practitioners alike.119

Beyond the Hugging Face library, several open-source Transformer models are available. For instance, **GPT-Neo** and **Llama** 126 are examples of large language models with architectures based on the Transformer, offering alternatives to proprietary models.

Numerous tutorials and implementations of Transformer networks are also available. For PyTorch users, the repository "transformers-gen-ai" by AlexIoannides 150 (URL: 150) offers a starting point for understanding implementation details. PyTorch also provides its own tutorials 61 (URL: 61) that cover Transformer basics and advanced topics. GitHub repositories like "transformer" by hyunwoongko 151 (URL: 151) and the notebooks in the "uvadlc\_notebooks" repository 152 (URL: 152) offer further implementation examples and explanations. For TensorFlow users, the official TensorFlow Text tutorial on Transformers 153 (URL: 153) provides a comprehensive guide.

A particularly valuable resource for understanding the implementation of the original Transformer architecture is "The Annotated Transformer" 150 (URL: 150), which provides a detailed, line-by-line explanation of the "Attention Is All You Need" paper with corresponding PyTorch code snippets.

**Table 5: Open-Source Transformer Resources**

| Resource Type | Name | URL | Framework | Key Topics/Notes |
| :---- | :---- | :---- | :---- | :---- |
| Library | Hugging Face Transformers | [https://huggingface.co/transformers/](https://huggingface.co/transformers/) | PyTorch/TensorFlow | Pre-trained models, tools for building and training |
| Model | GPT-Neo | [https://www.opensourceforu.com/2025/05/the-power-of-open-source-generative-ai-and-large-language-models/](https://www.opensourceforu.com/2025/05/the-power-of-open-source-generative-ai-and-large-language-models/) | None | Open-source alternative to GPT-3 |
| Model | Llama | [https://www.opensourceforu.com/2025/05/the-power-of-open-source-generative-ai-and-large-language-models/](https://www.opensourceforu.com/2025/05/the-power-of-open-source-generative-ai-and-large-language-models/) | None | Open-source large language model by Meta AI |
| Tutorial/Implementation | transformers-gen-ai | [https://github.com/AlexIoannides/transformers-gen-ai](https://github.com/AlexIoannides/transformers-gen-ai) | PyTorch | Entry-point to transformer-based language modeling |
| Tutorial | PyTorch Tutorials | [https://pytorch.org/tutorials/](https://pytorch.org/tutorials/) | PyTorch | Includes Transformer-related tutorials |
| Implementation | transformer | [https://github.com/hyunwoongko/transformer](https://github.com/hyunwoongko/transformer) | PyTorch | Implementation of Transformer components |
| Tutorial/Implementation | uvadlc\_notebooks | (https://github.com/phlippe/uvadlc\_notebooks/blob/master/docs/tutorial\_notebooks/tutorial6/Transformers\_and\_MHAttention.ipynb) | PyTorch | Implementation of Transformer and Multi-Head Attention |
| Tutorial | TensorFlow Text Tutorials | [https://www.tensorflow.org/text/tutorials/transformer](https://www.tensorflow.org/text/tutorials/transformer) | TensorFlow | Sequence-to-sequence Transformer |
| Explanation/Implementation | The Annotated Transformer | [https://nlp.seas.harvard.edu/2018/04/03/attention.html](https://nlp.seas.harvard.edu/2018/04/03/attention.html) | PyTorch | Detailed explanation of the original paper with code |

## **Module 5: Diffusion Models**

### **5.1 Introduction to the Concepts Behind Diffusion Models**

Diffusion models have emerged as a powerful class of generative models, particularly noted for their ability to produce high-quality data across various modalities, including images, video, and audio.154 These models operate on the principle of reversing a gradual diffusion process. The core idea involves two main phases: a forward diffusion process, where noise is progressively added to the training data over a series of steps, and a reverse diffusion process, where the model learns to denoise the data, effectively reversing the noise addition to generate new samples.154

In the forward diffusion process, the data gradually loses its distinct features as small amounts of noise are added at each step, eventually transforming the data into a purely noisy signal, often resembling random Gaussian noise.154 The reverse diffusion process is where the generative power of the model lies. By learning to predict and remove the noise at each step of the reverse process, starting from random noise, the model can iteratively refine the signal until it converges to a realistic data sample that resembles the distribution of the original training data.154

Compared to other generative models like Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs), diffusion models are often praised for their training stability and the diversity of the samples they can generate.157 While GANs can sometimes suffer from unstable training and mode collapse (generating limited types of samples), and VAEs might rely on surrogate loss functions, diffusion models are learned with a more stable, fixed procedure.157 However, diffusion models typically require a large number of steps during the reverse process to generate a single sample, which can lead to longer inference times compared to GANs.157

Within the realm of diffusion models, several frameworks exist, including Denoising Diffusion Probabilistic Models (DDPMs), which use latent variables to estimate the probability distribution; Noise Conditioned Score Networks (NCSNs), which train a network to estimate the score function of the perturbed data distribution at different noise levels; and approaches based on Stochastic Differential Equations (SDEs), which model diffusion as a continuous process using forward and reverse SDEs.157

For those interested in understanding diffusion models further, blog posts on Lilian Weng's website 159 (lilianweng.github.io/posts/2021-07-11-diffusion-models/) and AssemblyAI 158 ([www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/](https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/)) provide insightful overviews. The Hugging Face Diffusion Models Course 160 (huggingface.co/learn/computer-vision-course/unit5/generative-models/diffusion-models/introduction) offers tutorials and practical guidance. Additionally, GitHub repositories like "intro-to-diffusion" by Jean-BaptisteBouvier 155 ([github.com/Jean-BaptisteBouvier/intro-to-diffusion](https://github.com/Jean-BaptisteBouvier/intro-to-diffusion)) provide simple code examples. The Wikipedia page on Diffusion Model 156 (en.wikipedia.org/wiki/Diffusion\_model) offers a comprehensive theoretical background.

### **5.2 Exploring Open-Source Resources for Learning Diffusion Models**

The open-source ecosystem provides several valuable resources for individuals looking to learn about and work with diffusion models. One of the most prominent is the **Hugging Face Diffusers library** 160 (URL: 160). This library offers a wide range of pre-trained diffusion models and tools for creating, training, and deploying custom diffusion models. It supports various diffusion techniques, including DDPMs and latent diffusion models, making it a central hub for both learning and practical applications.

Several open-source diffusion models have also gained significant attention, most notably **Stable Diffusion**.156 Stable Diffusion is a powerful text-to-image diffusion model that has demonstrated remarkable capabilities in generating high-quality and realistic images from textual prompts. Its open-source nature has fostered a large community of users and developers, leading to numerous resources and applications built around it.156

For those seeking hands-on experience, GitHub repositories like "intro-to-diffusion" by Jean-BaptisteBouvier 155 (URL: 155) offer simple implementations of diffusion models using PyTorch, providing a practical way to understand the core concepts. The Hugging Face Diffusion Models Course 160 (URL: 160) also includes notebooks that allow users to put theory into practice and train their own diffusion models. For a more in-depth understanding of Denoising Diffusion Probabilistic Models (DDPMs), "The Annotated Diffusion Model" (referenced in 160) provides a detailed walkthrough of the theory and code behind this specific type of diffusion model.

**Table 6: Open-Source Diffusion Model Resources**

| Resource Type | Name | URL | Key Topics/Notes |
| :---- | :---- | :---- | :---- |
| Library | Hugging Face Diffusers | [https://huggingface.co/docs/diffusers/index](https://huggingface.co/docs/diffusers/index) | Pre-trained models, tools for creating and training diffusion models |
| Model | Stable Diffusion | [https://stablediffusion.com/](https://stablediffusion.com/) | Text-to-image generation |
| Tutorial/Implementation | intro-to-diffusion | ([https://github.com/Jean-BaptisteBouvier/intro-to-diffusion](https://github.com/Jean-BaptisteBouvier/intro-to-diffusion)) | Simple diffusion model implementation in PyTorch |
| Tutorial | Hugging Face Diffusion Models Course | [https://huggingface.co/learn/computer-vision-course/unit5/generative-models/diffusion-models/introduction](https://huggingface.co/learn/computer-vision-course/unit5/generative-models/diffusion-models/introduction) | Covers the basics of diffusion models and how to use the Diffusers library |
| Explanation | The Annotated Diffusion Model | Referenced in 160 | In-depth walk-through of DDPM theory and code |

## **Module 6: Advanced Topics and Further Learning**

### **6.1 Evaluation Metrics for Generative Models**

Evaluating the performance of generative models poses unique challenges. For Variational Autoencoders, common metrics include reconstruction error, which measures the difference between the input and the reconstructed output, and the KL divergence, which quantifies the difference between the learned latent distribution and the prior. For Generative Adversarial Networks, evaluation is more complex and often involves metrics like the Inception Score (IS) and the Fréchet Inception Distance (FID) 6, which assess the quality and diversity of the generated samples. However, GANs are also known to suffer from issues like mode collapse, where the generator produces a limited variety of outputs, making evaluation even more nuanced.76

### **6.2 Ethical Considerations in Generative AI**

As Generative AI models become more powerful, ethical considerations become increasingly important. These models can inadvertently learn and amplify biases present in the training data, leading to unfair or discriminatory outputs. Furthermore, the ability of these models to generate realistic synthetic content raises concerns about potential misuse, such as the creation of fake news, deepfakes, and other forms of misinformation. Ongoing research in the field focuses on addressing these ethical challenges, including developing methods to audit and mitigate biases in data and models, and establishing best practices for responsible AI development.17

### **6.3 Further Learning Resources**

The field of Generative AI is constantly evolving. To stay at the forefront of this domain, it is highly recommended to explore research papers published on arXiv 164, a repository of pre-prints across various scientific disciplines. Additionally, following the proceedings of major conferences such as NeurIPS 166, ICML 168, and ACL 170 can provide insights into the latest advancements and research directions. For those looking to delve into more advanced topics, areas like normalizing flows, energy-based models, and the application of reinforcement learning for generative tasks offer promising avenues for further study.

## **Conclusion: A Structured Path to Mastering Generative AI**

This detailed study plan provides a structured roadmap for learning Generative AI, starting from foundational machine learning and deep learning concepts and progressing through the intricacies of Variational Autoencoders, Generative Adversarial Networks, Transformer networks, and Diffusion models. By leveraging the wealth of open-source resources available, including courses, tutorials, libraries, and implementations in TensorFlow and PyTorch, individuals can gain both theoretical knowledge and practical skills in this exciting field. Continuous engagement with advanced topics, research papers, and ethical considerations will be crucial for mastering Generative AI and contributing to its responsible and innovative development.

#### **Works cited**

1. Introduction to generative adversarial network \- Opensource.com, accessed May 9, 2025, [https://opensource.com/article/19/4/introduction-generative-adversarial-networks](https://opensource.com/article/19/4/introduction-generative-adversarial-networks)  
2. Is there any “organized and complete” source to study Generative Adversarial Networks (GANs) or just Generative Models? \- Quora, accessed May 9, 2025, [https://www.quora.com/Is-there-any-%E2%80%9Corganized-and-complete%E2%80%9D-source-to-study-Generative-Adversarial-Networks-GANs-or-just-Generative-Models](https://www.quora.com/Is-there-any-%E2%80%9Corganized-and-complete%E2%80%9D-source-to-study-Generative-Adversarial-Networks-GANs-or-just-Generative-Models)  
3. CS50's Introduction to Artificial Intelligence with Python | Harvard University, accessed May 9, 2025, [https://pll.harvard.edu/course/cs50s-introduction-artificial-intelligence-python](https://pll.harvard.edu/course/cs50s-introduction-artificial-intelligence-python)  
4. Variational Autoencoders Vaes \- Lark, accessed May 9, 2025, [https://www.larksuite.com/en\_us/topics/ai-glossary/variational-autoencoders-vaes](https://www.larksuite.com/en_us/topics/ai-glossary/variational-autoencoders-vaes)  
5. Simple Gan Examples For Simple Open-Source Ai Projects \- Restack, accessed May 9, 2025, [https://www.restack.io/p/simple-open-source-ai-projects-answer-gan-examples-cat-ai](https://www.restack.io/p/simple-open-source-ai-projects-answer-gan-examples-cat-ai)  
6. Intro to Generative Adversarial Networks (GANs) \- PyImageSearch, accessed May 9, 2025, [https://pyimagesearch.com/2021/09/13/intro-to-generative-adversarial-networks-gans/](https://pyimagesearch.com/2021/09/13/intro-to-generative-adversarial-networks-gans/)  
7. Guide to Generative Adversarial Networks (GANs) in 2024 \- viso.ai, accessed May 9, 2025, [https://viso.ai/deep-learning/generative-adversarial-networks-gan/](https://viso.ai/deep-learning/generative-adversarial-networks-gan/)  
8. A Complete Guide to GANs: Types, Techniques, and Real-World Applications, accessed May 9, 2025, [https://insights.daffodilsw.com/blog/a-complete-guide-to-gans](https://insights.daffodilsw.com/blog/a-complete-guide-to-gans)  
9. Open Source Tools for Generative AI: An Introduction, accessed May 9, 2025, [https://www.opensourceforu.com/2024/05/open-source-tools-for-generative-ai-an-introduction/](https://www.opensourceforu.com/2024/05/open-source-tools-for-generative-ai-an-introduction/)  
10. Crash Course in Open Source Generative AI \- YouTube, accessed May 9, 2025, [https://www.youtube.com/watch?v=XcOoDjOK4Gw](https://www.youtube.com/watch?v=XcOoDjOK4Gw)  
11. MACHINE LEARNING \[R17A0534\] LECTURE NOTES MALLA REDDY COLLEGE OF ENGINEERING & TECHNOLOGY, accessed May 9, 2025, [https://mrcet.com/downloads/digital\_notes/CSE/IV%20Year/MACHINE%20LEARNING(R17A0534).pdf](https://mrcet.com/downloads/digital_notes/CSE/IV%20Year/MACHINE%20LEARNING\(R17A0534\).pdf)  
12. Machine Learning Tutorial \- GeeksforGeeks, accessed May 9, 2025, [https://www.geeksforgeeks.org/machine-learning/](https://www.geeksforgeeks.org/machine-learning/)  
13. A Gentle Introduction to Generative Adversarial Networks (GANs) \- MachineLearningMastery.com, accessed May 9, 2025, [https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/](https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/)  
14. Introduction to Machine Learning \- MIT Open Learning Library, accessed May 9, 2025, [https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/about](https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/about)  
15. Introduction to Machine Learning | Electrical Engineering and Computer Science | MIT OpenCourseWare, accessed May 9, 2025, [https://ocw.mit.edu/courses/6-036-introduction-to-machine-learning-fall-2020/](https://ocw.mit.edu/courses/6-036-introduction-to-machine-learning-fall-2020/)  
16. Introduction to Machine Learning | Coursera, accessed May 9, 2025, [https://www.coursera.org/learn/machine-learning-duke](https://www.coursera.org/learn/machine-learning-duke)  
17. Machine Learning Crash Course \- Google for Developers, accessed May 9, 2025, [https://developers.google.com/machine-learning/crash-course](https://developers.google.com/machine-learning/crash-course)  
18. Intro to Machine Learning \- Kaggle, accessed May 9, 2025, [https://www.kaggle.com/learn/intro-to-machine-learning](https://www.kaggle.com/learn/intro-to-machine-learning)  
19. CS229: Machine Learning, accessed May 9, 2025, [https://cs229.stanford.edu/](https://cs229.stanford.edu/)  
20. Deep Learning Tutorial | GeeksforGeeks, accessed May 9, 2025, [https://www.geeksforgeeks.org/deep-learning-tutorial/](https://www.geeksforgeeks.org/deep-learning-tutorial/)  
21. Intro to Deep Learning \- Kaggle, accessed May 9, 2025, [https://www.kaggle.com/learn/intro-to-deep-learning](https://www.kaggle.com/learn/intro-to-deep-learning)  
22. Intro to Deep Learning with PyTorch \- Udacity, accessed May 9, 2025, [https://www.udacity.com/course/deep-learning-pytorch--ud188](https://www.udacity.com/course/deep-learning-pytorch--ud188)  
23. Neural Networks and Deep Learning \- Coursera, accessed May 9, 2025, [https://www.coursera.org/learn/neural-networks-deep-learning](https://www.coursera.org/learn/neural-networks-deep-learning)  
24. Introduction to Deep Learning | Electrical Engineering and Computer Science, accessed May 9, 2025, [https://ocw.mit.edu/courses/6-s191-introduction-to-deep-learning-january-iap-2020/](https://ocw.mit.edu/courses/6-s191-introduction-to-deep-learning-january-iap-2020/)  
25. Introduction to Deep Learning (I2DL), accessed May 9, 2025, [https://slds-lmu.github.io/i2dl/](https://slds-lmu.github.io/i2dl/)  
26. Start Here with Machine Learning, accessed May 9, 2025, [https://machinelearningmastery.com/start-here/](https://machinelearningmastery.com/start-here/)  
27. Understanding Deep Learning, accessed May 9, 2025, [https://udlbook.github.io/udlbook/](https://udlbook.github.io/udlbook/)  
28. What are some of the great resources to learn Machine learning from beginner to advanced? \- Reddit, accessed May 9, 2025, [https://www.reddit.com/r/learnmachinelearning/comments/vgtrsa/what\_are\_some\_of\_the\_great\_resources\_to\_learn/](https://www.reddit.com/r/learnmachinelearning/comments/vgtrsa/what_are_some_of_the_great_resources_to_learn/)  
29. mdozmorov/MachineLearning\_notes: Machine learning and deep learning resources \- GitHub, accessed May 9, 2025, [https://github.com/mdozmorov/MachineLearning\_notes](https://github.com/mdozmorov/MachineLearning_notes)  
30. Variational AutoEncoders | GeeksforGeeks, accessed May 9, 2025, [https://www.geeksforgeeks.org/variational-autoencoders/](https://www.geeksforgeeks.org/variational-autoencoders/)  
31. An introduction to Variational Autoencoders (VAE) \- AI Tech Blog, accessed May 9, 2025, [https://www.doptsw.com/posts/post\_2024-09-18\_d4b2bf](https://www.doptsw.com/posts/post_2024-09-18_d4b2bf)  
32. What is a Variational Autoencoder? \- IBM, accessed May 9, 2025, [https://www.ibm.com/think/topics/variational-autoencoder](https://www.ibm.com/think/topics/variational-autoencoder)  
33. Understanding Variational Autoencoders (VAEs) | Deep Learning \- YouTube, accessed May 9, 2025, [https://www.youtube.com/watch?v=HBYQvKlaE0A\&pp=0gcJCdgAo7VqN5tD](https://www.youtube.com/watch?v=HBYQvKlaE0A&pp=0gcJCdgAo7VqN5tD)  
34. Variational autoencoders \- Matthew N. Bernstein, accessed May 9, 2025, [https://mbernste.github.io/posts/vae/](https://mbernste.github.io/posts/vae/)  
35. Variational autoencoders. \- Jeremy Jordan, accessed May 9, 2025, [https://www.jeremyjordan.me/variational-autoencoders/](https://www.jeremyjordan.me/variational-autoencoders/)  
36. 178 \- An introduction to variational autoencoders (VAE) \- YouTube, accessed May 9, 2025, [https://www.youtube.com/watch?v=YV9D3TWY5Zo\&pp=0gcJCdgAo7VqN5tD](https://www.youtube.com/watch?v=YV9D3TWY5Zo&pp=0gcJCdgAo7VqN5tD)  
37. arxiv.org, accessed May 9, 2025, [https://arxiv.org/abs/1606.05908](https://arxiv.org/abs/1606.05908)  
38. \[1906.02691\] An Introduction to Variational Autoencoders \- arXiv, accessed May 9, 2025, [https://arxiv.org/abs/1906.02691](https://arxiv.org/abs/1906.02691)  
39. Tutorial \- What is a variational autoencoder? \- Jaan Lı 李, accessed May 9, 2025, [https://jaan.io/what-is-variational-autoencoder-vae-tutorial/](https://jaan.io/what-is-variational-autoencoder-vae-tutorial/)  
40. Variational autoencoder \- Wikipedia, accessed May 9, 2025, [https://en.wikipedia.org/wiki/Variational\_autoencoder](https://en.wikipedia.org/wiki/Variational_autoencoder)  
41. Lecture notes on variational auto-encoders (VAEs) \- Yingzhen Li, accessed May 9, 2025, [http://yingzhenli.net/home/pdf/imperial\_dlcourse2022\_vae\_notes.pdf](http://yingzhenli.net/home/pdf/imperial_dlcourse2022_vae_notes.pdf)  
42. Variational Auto Encoders, accessed May 9, 2025, [https://www.cs.cmu.edu/\~bhiksha/courses/deeplearning/Spring.2018/www/slides/lec16.vae.pdf](https://www.cs.cmu.edu/~bhiksha/courses/deeplearning/Spring.2018/www/slides/lec16.vae.pdf)  
43. Lecture 22: Variational Autoencoder Reference: Kingma & Welling (2013), accessed May 9, 2025, [https://courses.grainger.illinois.edu/ece417/fa2020/slides/lec22.pdf](https://courses.grainger.illinois.edu/ece417/fa2020/slides/lec22.pdf)  
44. Variational Autoencoders: How They Work and Why They Matter \- DataCamp, accessed May 9, 2025, [https://www.datacamp.com/tutorial/variational-autoencoders](https://www.datacamp.com/tutorial/variational-autoencoders)  
45. Robotmurlock/VariationalAutoEncoder: Implementation of the Auto-Encoding Variational Bayes paper in Pytorch with detailed explanation. \- GitHub, accessed May 9, 2025, [https://github.com/Robotmurlock/VariationalAutoEncoder](https://github.com/Robotmurlock/VariationalAutoEncoder)  
46. Variational Autoencoders \- Deep Generative Models, accessed May 9, 2025, [https://deepgenerativemodels.github.io/notes/vae/](https://deepgenerativemodels.github.io/notes/vae/)  
47. Variational Autoencoders and Probabilistic Graphical Models \- Cross Validated, accessed May 9, 2025, [https://stats.stackexchange.com/questions/541763/variational-autoencoders-and-probabilistic-graphical-models](https://stats.stackexchange.com/questions/541763/variational-autoencoders-and-probabilistic-graphical-models)  
48. What about variational autoencoders is "variational" : r/deeplearning \- Reddit, accessed May 9, 2025, [https://www.reddit.com/r/deeplearning/comments/we8piq/what\_about\_variational\_autoencoders\_is\_variational/](https://www.reddit.com/r/deeplearning/comments/we8piq/what_about_variational_autoencoders_is_variational/)  
49. Convolutional Variational Autoencoder | TensorFlow Core, accessed May 9, 2025, [https://www.tensorflow.org/tutorials/generative/cvae](https://www.tensorflow.org/tutorials/generative/cvae)  
50. Intro to Autoencoders | TensorFlow Core, accessed May 9, 2025, [https://www.tensorflow.org/tutorials/generative/autoencoder](https://www.tensorflow.org/tutorials/generative/autoencoder)  
51. Learn by example variational autoencoder \- Kaggle, accessed May 9, 2025, [https://www.kaggle.com/code/charel/learn-by-example-variational-autoencoder](https://www.kaggle.com/code/charel/learn-by-example-variational-autoencoder)  
52. Variational Autoencoder in TensorFlow (Python Code) \- LearnOpenCV, accessed May 9, 2025, [https://learnopencv.com/variational-autoencoder-in-tensorflow/](https://learnopencv.com/variational-autoencoder-in-tensorflow/)  
53. How to Build a Variational Autoencoder in Keras | Paperspace Blog, accessed May 9, 2025, [https://blog.paperspace.com/how-to-build-variational-autoencoder-keras/](https://blog.paperspace.com/how-to-build-variational-autoencoder-keras/)  
54. blackhat-coder/Tensorflow-VAE-: This repository contains an experimental implementation of a Variational Autoencoder (VAE) using TensorFlow. The project was developed for learning purposes, with a focus on exploring generative models through unsupervised learning. \- GitHub, accessed May 9, 2025, [https://github.com/blackhat-coder/Tensorflow-VAE-](https://github.com/blackhat-coder/Tensorflow-VAE-)  
55. ChengBinJin/VAE-Tensorflow: Variational Autoencoder Tensorflow Implementation \- GitHub, accessed May 9, 2025, [https://github.com/ChengBinJin/VAE-Tensorflow](https://github.com/ChengBinJin/VAE-Tensorflow)  
56. mingukkang/CVAE: Tensorflow Code for Conditional Variational AutoEncoder \- GitHub, accessed May 9, 2025, [https://github.com/mingukkang/CVAE](https://github.com/mingukkang/CVAE)  
57. shaohua0116/VAE-Tensorflow: A Tensorflow implementation of a Variational Autoencoder for the deep learning course at the University of Southern California (USC). \- GitHub, accessed May 9, 2025, [https://github.com/shaohua0116/VAE-Tensorflow](https://github.com/shaohua0116/VAE-Tensorflow)  
58. Tensorflow implementation of Variational Autoencoder for MNIST \- GitHub, accessed May 9, 2025, [https://github.com/conormdurkan/variational-autoencoder](https://github.com/conormdurkan/variational-autoencoder)  
59. ondrejbiza/vae: Variational autoencoders implemented in Tensorflow. \- GitHub, accessed May 9, 2025, [https://github.com/ondrejbiza/vae](https://github.com/ondrejbiza/vae)  
60. FilippoMB/Variational-Graph-Auto-encoders-Tensorflow-2-Spektral \- GitHub, accessed May 9, 2025, [https://github.com/FilippoMB/Variational-Graph-Auto-encoders-Tensorflow-2-Spektral-](https://github.com/FilippoMB/Variational-Graph-Auto-encoders-Tensorflow-2-Spektral-)  
61. Welcome to PyTorch Tutorials, accessed May 9, 2025, [https://pytorch.org/tutorials/](https://pytorch.org/tutorials/)  
62. PyTorch \- Vanilla GAN \- Kaggle, accessed May 9, 2025, [https://www.kaggle.com/code/rafat97/pytorch-vanilla-gan](https://www.kaggle.com/code/rafat97/pytorch-vanilla-gan)  
63. A Deep Dive into Variational Autoencoders with PyTorch \- PyImageSearch, accessed May 9, 2025, [https://pyimagesearch.com/2023/10/02/a-deep-dive-into-variational-autoencoders-with-pytorch/](https://pyimagesearch.com/2023/10/02/a-deep-dive-into-variational-autoencoders-with-pytorch/)  
64. Generating Faces Using Variational Autoencoders with PyTorch \- PyImageSearch, accessed May 9, 2025, [https://pyimagesearch.com/2023/10/23/generating-faces-using-variational-autoencoders-with-pytorch/](https://pyimagesearch.com/2023/10/23/generating-faces-using-variational-autoencoders-with-pytorch/)  
65. AntixK/PyTorch-VAE: A Collection of Variational Autoencoders (VAE) in PyTorch. \- GitHub, accessed May 9, 2025, [https://github.com/AntixK/PyTorch-VAE](https://github.com/AntixK/PyTorch-VAE)  
66. Jackson-Kang/Pytorch-VAE-tutorial: A simple tutorial of Variational AutoEncoders with Pytorch \- GitHub, accessed May 9, 2025, [https://github.com/Jackson-Kang/Pytorch-VAE-tutorial](https://github.com/Jackson-Kang/Pytorch-VAE-tutorial)  
67. Pytorch-VAE-tutorial/01\_Variational\_AutoEncoder.ipynb at master \- GitHub, accessed May 9, 2025, [https://github.com/Jackson-Kang/Pytorch-VAE-tutorial/blob/master/01\_Variational\_AutoEncoder.ipynb](https://github.com/Jackson-Kang/Pytorch-VAE-tutorial/blob/master/01_Variational_AutoEncoder.ipynb)  
68. A Variational Autoencoder (VAE) implemented in PyTorch \- GitHub, accessed May 9, 2025, [https://github.com/ethanluoyc/pytorch-vae](https://github.com/ethanluoyc/pytorch-vae)  
69. Pytorch implementation of Hyperspherical Variational Auto-Encoders \- GitHub, accessed May 9, 2025, [https://github.com/nicola-decao/s-vae-pytorch](https://github.com/nicola-decao/s-vae-pytorch)  
70. SashaMalysheva/Pytorch-VAE: This is an implementation of the VAE (Variational Autoencoder) for Cifar10 \- GitHub, accessed May 9, 2025, [https://github.com/SashaMalysheva/Pytorch-VAE](https://github.com/SashaMalysheva/Pytorch-VAE)  
71. PyTorch implementation of Variational Autoencoder (VAE) on MNIST dataset. \- GitHub, accessed May 9, 2025, [https://github.com/bvezilic/Variational-autoencoder](https://github.com/bvezilic/Variational-autoencoder)  
72. addtt/ladder-vae-pytorch: Ladder Variational Autoencoders (LVAE) in PyTorch \- GitHub, accessed May 9, 2025, [https://github.com/addtt/ladder-vae-pytorch](https://github.com/addtt/ladder-vae-pytorch)  
73. geyang/variational\_autoencoder\_pytorch: pyTorch variational autoencoder, with explainations \- GitHub, accessed May 9, 2025, [https://github.com/geyang/variational\_autoencoder\_pytorch](https://github.com/geyang/variational_autoencoder_pytorch)  
74. Variational Autoencoder implemented with PyTorch, Trained over CelebA Dataset \- GitHub, accessed May 9, 2025, [https://github.com/bhpfelix/Variational-Autoencoder-PyTorch](https://github.com/bhpfelix/Variational-Autoencoder-PyTorch)  
75. Simple and clean implementation of Conditional Variational AutoEncoder (cVAE) using PyTorch \- GitHub, accessed May 9, 2025, [https://github.com/unnir/cVAE](https://github.com/unnir/cVAE)  
76. Generative Adversarial Network (GAN) \- GeeksforGeeks, accessed May 9, 2025, [https://www.geeksforgeeks.org/generative-adversarial-network-gan/](https://www.geeksforgeeks.org/generative-adversarial-network-gan/)  
77. Generative adversarial network \- Wikipedia, accessed May 9, 2025, [https://en.wikipedia.org/wiki/Generative\_adversarial\_network](https://en.wikipedia.org/wiki/Generative_adversarial_network)  
78. Overview of GAN Structure | Machine Learning \- Google for Developers, accessed May 9, 2025, [https://developers.google.com/machine-learning/gan/gan\_structure](https://developers.google.com/machine-learning/gan/gan_structure)  
79. Generative Adversarial Networks \- Communications of the ACM, accessed May 9, 2025, [https://cacm.acm.org/research/generative-adversarial-networks/](https://cacm.acm.org/research/generative-adversarial-networks/)  
80. dsc-4-48-05-introduction-to-generative-adversarial-networks/README.md at master, accessed May 9, 2025, [https://github.com/learn-co-curriculum/dsc-4-48-05-introduction-to-generative-adversarial-networks/blob/master/README.md](https://github.com/learn-co-curriculum/dsc-4-48-05-introduction-to-generative-adversarial-networks/blob/master/README.md)  
81. Minimax Game for Training Generative Adversarial Networks \- Lei Mao's Log Book, accessed May 9, 2025, [https://leimao.github.io/blog/Generative-Adversarial-Networks-Minmax-Game/](https://leimao.github.io/blog/Generative-Adversarial-Networks-Minmax-Game/)  
82. Games of GANs: game-theoretical models for generative adversarial networks \- Wireless Communications and Networking Laboratory, accessed May 9, 2025, [https://wireless.ece.arizona.edu/sites/default/files/2023-09/GamesofGAN\_Springer.pdf](https://wireless.ece.arizona.edu/sites/default/files/2023-09/GamesofGAN_Springer.pdf)  
83. Generative Adversarial Network (GAN) \- GeeksforGeeks, accessed May 9, 2025, [https://www.geeksforgeeks.org/generative-adversarial-network-gan](https://www.geeksforgeeks.org/generative-adversarial-network-gan)  
84. StyleGAN Explained in Less Than Five Minutes \- Analytics Vidhya, accessed May 9, 2025, [https://www.analyticsvidhya.com/blog/2021/05/stylegan-explained-in-less-than-five-minutes/](https://www.analyticsvidhya.com/blog/2021/05/stylegan-explained-in-less-than-five-minutes/)  
85. Deep Convolutional GAN with Keras \- GeeksforGeeks, accessed May 9, 2025, [https://www.geeksforgeeks.org/deep-convolutional-gan-with-keras/](https://www.geeksforgeeks.org/deep-convolutional-gan-with-keras/)  
86. Implementing Deep Convolutional GAN (DCGAN) with PyTorch \- DebuggerCafe, accessed May 9, 2025, [https://debuggercafe.com/dcgan-pytorch/](https://debuggercafe.com/dcgan-pytorch/)  
87. Open Source Generative AI Models: A Comprehensive Guide to Getting Started \- Promact, accessed May 9, 2025, [https://promactinfo.com/blogs/open-source-generative-ai-models-a-comprehensive-guide-to-getting-started](https://promactinfo.com/blogs/open-source-generative-ai-models-a-comprehensive-guide-to-getting-started)  
88. NVlabs/stylegan \- Official TensorFlow Implementation \- GitHub, accessed May 9, 2025, [https://github.com/NVlabs/stylegan](https://github.com/NVlabs/stylegan)  
89. StyleGAN: Use machine learning to generate and customize realistic images \- Comet.ml, accessed May 9, 2025, [https://www.comet.com/site/blog/stylegan-use-machine-learning-to-generate-and-customize-realistic-images/](https://www.comet.com/site/blog/stylegan-use-machine-learning-to-generate-and-customize-realistic-images/)  
90. StyleGAN Variants \- Hugging Face Community Computer Vision Course, accessed May 9, 2025, [https://huggingface.co/learn/computer-vision-course/unit5/generative-models/gans-vaes/stylegan](https://huggingface.co/learn/computer-vision-course/unit5/generative-models/gans-vaes/stylegan)  
91. DCGAN Tutorial \- Generative Adversarial Networks \- PyTorch, accessed May 9, 2025, [https://pytorch.org/tutorials/beginner/dcgan\_faces\_tutorial.html](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)  
92. Deep Convolutional Generative Adversarial Network | TensorFlow Core, accessed May 9, 2025, [https://www.tensorflow.org/tutorials/generative/dcgan](https://www.tensorflow.org/tutorials/generative/dcgan)  
93. GAN Tutorial. First DCGAN using TensorFlow. \- Kaggle, accessed May 9, 2025, [https://www.kaggle.com/code/peremartramanonellas/gan-tutorial-first-dcgan-using-tensorflow](https://www.kaggle.com/code/peremartramanonellas/gan-tutorial-first-dcgan-using-tensorflow)  
94. Build a Generative Adversarial Neural Network with Tensorflow and Python | Deep Learning Projects \- YouTube, accessed May 9, 2025, [https://www.youtube.com/watch?v=AALBGpLbj6Q](https://www.youtube.com/watch?v=AALBGpLbj6Q)  
95. Building a simple Generative Adversarial Network (GAN) using TensorFlow \- DigitalOcean, accessed May 9, 2025, [https://www.digitalocean.com/community/tutorials/implementing-gans-in-tensorflow](https://www.digitalocean.com/community/tutorials/implementing-gans-in-tensorflow)  
96. GANs with Keras and TensorFlow \- PyImageSearch, accessed May 9, 2025, [https://pyimagesearch.com/2020/11/16/gans-with-keras-and-tensorflow/](https://pyimagesearch.com/2020/11/16/gans-with-keras-and-tensorflow/)  
97. Introduction to GANs with TensorFlow \- Python Lessons, accessed May 9, 2025, [https://pylessons.com/gan-introduction](https://pylessons.com/gan-introduction)  
98. pix2pix: Image-to-image translation with a conditional GAN | TensorFlow Core, accessed May 9, 2025, [https://www.tensorflow.org/tutorials/generative/pix2pix](https://www.tensorflow.org/tutorials/generative/pix2pix)  
99. A Style-Based Generator Architecture for Generative Adversarial Networks \- CVF Open Access, accessed May 9, 2025, [https://openaccess.thecvf.com/content\_CVPR\_2019/papers/Karras\_A\_Style-Based\_Generator\_Architecture\_for\_Generative\_Adversarial\_Networks\_CVPR\_2019\_paper.pdf](https://openaccess.thecvf.com/content_CVPR_2019/papers/Karras_A_Style-Based_Generator_Architecture_for_Generative_Adversarial_Networks_CVPR_2019_paper.pdf)  
100. A PyTorch implementation for StyleGAN with full features. \- GitHub, accessed May 9, 2025, [https://github.com/huangzh13/StyleGAN.pytorch](https://github.com/huangzh13/StyleGAN.pytorch)  
101. DCGAN | MNIST | PyTorch \- Kaggle, accessed May 9, 2025, [https://www.kaggle.com/code/utkarshsaxenadn/dcgan-mnist-pytorch](https://www.kaggle.com/code/utkarshsaxenadn/dcgan-mnist-pytorch)  
102. Image Generation using Stylegan pre-trained model \- Kaggle, accessed May 9, 2025, [https://www.kaggle.com/code/songseungwon/image-generation-using-stylegan-pre-trained-model/notebook](https://www.kaggle.com/code/songseungwon/image-generation-using-stylegan-pre-trained-model/notebook)  
103. 4 Impressive GAN Libraries Every Data Scientist Should Know\! \- Analytics Vidhya, accessed May 9, 2025, [https://www.analyticsvidhya.com/blog/2020/08/top-5-gan-libraries-you-must-know/](https://www.analyticsvidhya.com/blog/2020/08/top-5-gan-libraries-you-must-know/)  
104. togheppi/vanilla\_GAN: PyTorch implementation of Vanilla GAN \- GitHub, accessed May 9, 2025, [https://github.com/togheppi/vanilla\_GAN](https://github.com/togheppi/vanilla_GAN)  
105. carpedm20/DCGAN-tensorflow: A tensorflow implementation of "Deep Convolutional Generative Adversarial Networks" \- GitHub, accessed May 9, 2025, [https://github.com/carpedm20/DCGAN-tensorflow](https://github.com/carpedm20/DCGAN-tensorflow)  
106. kpandey008/dcgan: Implementation of Deep Convolutional Generative Adversarial Networks in Pytorch and Tensorflow \- GitHub, accessed May 9, 2025, [https://github.com/kpandey008/dcgan](https://github.com/kpandey008/dcgan)  
107. DCGAN paper implementation using PyTorch to generate faces \- GitHub, accessed May 9, 2025, [https://github.com/cankocagil/DCGAN](https://github.com/cankocagil/DCGAN)  
108. \[P\] I Reimplemented StyleGAN using TensorFlow 2.0 \- Including a Web Demo\! \- Reddit, accessed May 9, 2025, [https://www.reddit.com/r/MachineLearning/comments/e202r7/p\_i\_reimplemented\_stylegan\_using\_tensorflow\_20/](https://www.reddit.com/r/MachineLearning/comments/e202r7/p_i_reimplemented_stylegan_using_tensorflow_20/)  
109. gordicaleksa/pytorch-GANs: My implementation of various GAN (generative adversarial networks) architectures like vanilla GAN (Goodfellow et al.), cGAN (Mirza et al.), DCGAN (Radford et al.), etc. \- GitHub, accessed May 9, 2025, [https://github.com/gordicaleksa/pytorch-GANs](https://github.com/gordicaleksa/pytorch-GANs)  
110. Building a simple vanilla GAN with PyTorch \- MachineCurve.com, accessed May 9, 2025, [https://machinecurve.com/index.php/2021/07/17/building-a-simple-vanilla-gan-with-pytorch](https://machinecurve.com/index.php/2021/07/17/building-a-simple-vanilla-gan-with-pytorch)  
111. eriklindernoren/PyTorch-GAN: PyTorch implementations of Generative Adversarial Networks. \- GitHub, accessed May 9, 2025, [https://github.com/eriklindernoren/PyTorch-GAN](https://github.com/eriklindernoren/PyTorch-GAN)  
112. Tutorials | TensorFlow Core, accessed May 9, 2025, [https://www.tensorflow.org/tutorials](https://www.tensorflow.org/tutorials)  
113. Running a pre-trained tensorflow StyleGan model in PyTorch \- vision, accessed May 9, 2025, [https://discuss.pytorch.org/t/running-a-pre-trained-tensorflow-stylegan-model-in-pytorch/42001](https://discuss.pytorch.org/t/running-a-pre-trained-tensorflow-stylegan-model-in-pytorch/42001)  
114. Transformer (deep learning architecture) \- Wikipedia, accessed May 9, 2025, [https://en.wikipedia.org/wiki/Transformer\_(deep\_learning\_architecture)](https://en.wikipedia.org/wiki/Transformer_\(deep_learning_architecture\))  
115. An introduction to transformer models in neural networks and machine learning \- Algolia, accessed May 9, 2025, [https://www.algolia.com/blog/ai/an-introduction-to-transformer-models-in-neural-networks-and-machine-learning](https://www.algolia.com/blog/ai/an-introduction-to-transformer-models-in-neural-networks-and-machine-learning)  
116. What is a Transformer Model? \- IBM, accessed May 9, 2025, [https://www.ibm.com/think/topics/transformer-model](https://www.ibm.com/think/topics/transformer-model)  
117. Transformer Neural Networks: A Step-by-Step Breakdown | Built In, accessed May 9, 2025, [https://builtin.com/artificial-intelligence/transformer-neural-network](https://builtin.com/artificial-intelligence/transformer-neural-network)  
118. How Transformers Work: A Detailed Exploration of Transformer Architecture \- DataCamp, accessed May 9, 2025, [https://www.datacamp.com/tutorial/how-transformers-work](https://www.datacamp.com/tutorial/how-transformers-work)  
119. Exploring Open Source AI Models: LLMs and Transformer Architectures \- LLM Directory, accessed May 9, 2025, [https://llmmodels.org/blog/exploring-open-source-ai-models-llms-and-transformer-architectures/](https://llmmodels.org/blog/exploring-open-source-ai-models-llms-and-transformer-architectures/)  
120. Understanding Transformer Neural Network Model in Deep Learning and NLP \- Turing, accessed May 9, 2025, [https://www.turing.com/kb/brief-introduction-to-transformers-and-their-power](https://www.turing.com/kb/brief-introduction-to-transformers-and-their-power)  
121. The Transformer Blueprint: A Holistic Guide to the Transformer Neural Network Architecture \- AI Research Blog, accessed May 9, 2025, [https://deeprevision.github.io/posts/001-transformer/](https://deeprevision.github.io/posts/001-transformer/)  
122. Transformer and Generative AI Concepts \- devmio, accessed May 9, 2025, [https://devm.io/machine-learning/generative-ai-transformer-architecture](https://devm.io/machine-learning/generative-ai-transformer-architecture)  
123. What is an encoder-decoder model? \- IBM, accessed May 9, 2025, [https://www.ibm.com/think/topics/encoder-decoder-model](https://www.ibm.com/think/topics/encoder-decoder-model)  
124. 11.7. The Transformer Architecture — Dive into Deep Learning 1.0.3 documentation, accessed May 9, 2025, [https://d2l.ai/chapter\_attention-mechanisms-and-transformers/transformer.html](https://d2l.ai/chapter_attention-mechanisms-and-transformers/transformer.html)  
125. Transformer-based Encoder-Decoder Models \- Hugging Face, accessed May 9, 2025, [https://huggingface.co/blog/encoder-decoder](https://huggingface.co/blog/encoder-decoder)  
126. The Power of Open Source Generative AI and Large Language Models, accessed May 9, 2025, [https://www.opensourceforu.com/2025/05/the-power-of-open-source-generative-ai-and-large-language-models/](https://www.opensourceforu.com/2025/05/the-power-of-open-source-generative-ai-and-large-language-models/)  
127. Understanding Attention Mechanism in Transformer Neural Networks \- LearnOpenCV, accessed May 9, 2025, [https://learnopencv.com/attention-mechanism-in-transformer-neural-networks/](https://learnopencv.com/attention-mechanism-in-transformer-neural-networks/)  
128. Understanding and Coding the Self-Attention Mechanism of Large Language Models From Scratch \- Sebastian Raschka, accessed May 9, 2025, [https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html](https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html)  
129. Multi-Head Attention and Transformer Architecture \- Pathway, accessed May 9, 2025, [https://pathway.com/bootcamps/rag-and-llms/coursework/module-2-word-vectors-simplified/bonus-overview-of-the-transformer-architecture/multi-head-attention-and-transformer-architecture/](https://pathway.com/bootcamps/rag-and-llms/coursework/module-2-word-vectors-simplified/bonus-overview-of-the-transformer-architecture/multi-head-attention-and-transformer-architecture/)  
130. Multi-Head Attention Explained | Papers With Code, accessed May 9, 2025, [https://paperswithcode.com/method/multi-head-attention](https://paperswithcode.com/method/multi-head-attention)  
131. Multi-head in transformers : r/learnmachinelearning \- Reddit, accessed May 9, 2025, [https://www.reddit.com/r/learnmachinelearning/comments/1apy9uf/multihead\_in\_transformers/](https://www.reddit.com/r/learnmachinelearning/comments/1apy9uf/multihead_in_transformers/)  
132. Tutorial 6: Transformers and Multi-Head Attention — UvA DL Notebooks v1.2 documentation, accessed May 9, 2025, [https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial\_notebooks/tutorial6/Transformers\_and\_MHAttention.html](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial6/Transformers_and_MHAttention.html)  
133. 11.5. Multi-Head Attention — Dive into Deep Learning 1.0.3 documentation, accessed May 9, 2025, [https://d2l.ai/chapter\_attention-mechanisms-and-transformers/multihead-attention.html](https://d2l.ai/chapter_attention-mechanisms-and-transformers/multihead-attention.html)  
134. Generative pre-trained transformer \- Wikipedia, accessed May 9, 2025, [https://en.wikipedia.org/wiki/Generative\_pre-trained\_transformer](https://en.wikipedia.org/wiki/Generative_pre-trained_transformer)  
135. Positional Encoding in Transformers | GeeksforGeeks, accessed May 9, 2025, [https://www.geeksforgeeks.org/positional-encoding-in-transformers/](https://www.geeksforgeeks.org/positional-encoding-in-transformers/)  
136. Effect of positional encoding on graph transformer models \- Capital One, accessed May 9, 2025, [https://www.capitalone.com/tech/ai/positional-encoding-in-graph-transformers/](https://www.capitalone.com/tech/ai/positional-encoding-in-graph-transformers/)  
137. A Gentle Introduction to Positional Encoding in Transformer Models, Part 1 \- MachineLearningMastery.com, accessed May 9, 2025, [https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/](https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/)  
138. Position Embeddings for Vision Transformers, Explained \- Towards Data Science, accessed May 9, 2025, [https://towardsdatascience.com/position-embeddings-for-vision-transformers-explained-a6f9add341d5/](https://towardsdatascience.com/position-embeddings-for-vision-transformers-explained-a6f9add341d5/)  
139. Transformer Architecture: The Positional Encoding \- Amirhossein Kazemnejad's Blog, accessed May 9, 2025, [https://kazemnejad.com/blog/transformer\_architecture\_positional\_encoding/](https://kazemnejad.com/blog/transformer_architecture_positional_encoding/)  
140. 11.6. Self-Attention and Positional Encoding \- Dive into Deep Learning, accessed May 9, 2025, [https://d2l.ai/chapter\_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.html](https://d2l.ai/chapter_attention-mechanisms-and-transformers/self-attention-and-positional-encoding.html)  
141. How exactly does adding a positional encoding to a transformer's input embeddings model time-dependency? : r/LanguageTechnology \- Reddit, accessed May 9, 2025, [https://www.reddit.com/r/LanguageTechnology/comments/dxoyi6/how\_exactly\_does\_adding\_a\_positional\_encoding\_to/](https://www.reddit.com/r/LanguageTechnology/comments/dxoyi6/how_exactly_does_adding_a_positional_encoding_to/)  
142. Why can't positions in transformers be simply appended to the input to preserve the positional information instead of using positional encodings?, accessed May 9, 2025, [https://datascience.stackexchange.com/questions/110180/why-cant-positions-in-transformers-be-simply-appended-to-the-input-to-preserve](https://datascience.stackexchange.com/questions/110180/why-cant-positions-in-transformers-be-simply-appended-to-the-input-to-preserve)  
143. Transformer: A Novel Neural Network Architecture for Language Understanding, accessed May 9, 2025, [https://research.google/blog/transformer-a-novel-neural-network-architecture-for-language-understanding/](https://research.google/blog/transformer-a-novel-neural-network-architecture-for-language-understanding/)  
144. \[D\] Resources for deepening knowledge of Transformers : r/MachineLearning \- Reddit, accessed May 9, 2025, [https://www.reddit.com/r/MachineLearning/comments/12yk3ea/d\_resources\_for\_deepening\_knowledge\_of/](https://www.reddit.com/r/MachineLearning/comments/12yk3ea/d_resources_for_deepening_knowledge_of/)  
145. Attention is All you Need \- NIPS papers, accessed May 9, 2025, [https://papers.neurips.cc/paper/7181-attention-is-all-you-need.pdf](https://papers.neurips.cc/paper/7181-attention-is-all-you-need.pdf)  
146. Complete Guide to Building a Transformer Model with PyTorch \- DataCamp, accessed May 9, 2025, [https://www.datacamp.com/tutorial/building-a-transformer-with-py-torch](https://www.datacamp.com/tutorial/building-a-transformer-with-py-torch)  
147. What is Self-attention? \- H2O.ai, accessed May 9, 2025, [https://h2o.ai/wiki/self-attention/](https://h2o.ai/wiki/self-attention/)  
148. Transformer-based Encoder-Decoder Models \- GitHub, accessed May 9, 2025, [https://github.com/patrickvonplaten/notebooks/blob/master/Encoder\_Decoder\_Model.ipynb](https://github.com/patrickvonplaten/notebooks/blob/master/Encoder_Decoder_Model.ipynb)  
149. Encoder-decoder architecture: Overview \- YouTube, accessed May 9, 2025, [https://www.youtube.com/watch?v=zbdong\_h-x4](https://www.youtube.com/watch?v=zbdong_h-x4)  
150. AlexIoannides/transformers-gen-ai: Developing generative language models using transformers. \- GitHub, accessed May 9, 2025, [https://github.com/AlexIoannides/transformers-gen-ai](https://github.com/AlexIoannides/transformers-gen-ai)  
151. Transformer: PyTorch Implementation of "Attention Is All You Need" \- GitHub, accessed May 9, 2025, [https://github.com/hyunwoongko/transformer](https://github.com/hyunwoongko/transformer)  
152. Tutorial 6: Transformers and Multi-Head Attention \- GitHub, accessed May 9, 2025, [https://github.com/phlippe/uvadlc\_notebooks/blob/master/docs/tutorial\_notebooks/tutorial6/Transformers\_and\_MHAttention.ipynb](https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial6/Transformers_and_MHAttention.ipynb)  
153. Neural machine translation with a Transformer and Keras | Text \- TensorFlow, accessed May 9, 2025, [https://www.tensorflow.org/text/tutorials/transformer](https://www.tensorflow.org/text/tutorials/transformer)  
154. Introduction to Diffusion Models for Machine Learning | SuperAnnotate, accessed May 9, 2025, [https://www.superannotate.com/blog/diffusion-models](https://www.superannotate.com/blog/diffusion-models)  
155. Jean-BaptisteBouvier/intro-to-diffusion: Introduction to coding Diffusion models \- GitHub, accessed May 9, 2025, [https://github.com/Jean-BaptisteBouvier/intro-to-diffusion](https://github.com/Jean-BaptisteBouvier/intro-to-diffusion)  
156. Diffusion model \- Wikipedia, accessed May 9, 2025, [https://en.wikipedia.org/wiki/Diffusion\_model](https://en.wikipedia.org/wiki/Diffusion_model)  
157. Introduction to Diffusion Models \- Hugging Face Community Computer Vision Course, accessed May 9, 2025, [https://huggingface.co/learn/computer-vision-course/unit5/generative-models/diffusion-models/introduction](https://huggingface.co/learn/computer-vision-course/unit5/generative-models/diffusion-models/introduction)  
158. Introduction to Diffusion Models for Machine Learning \- AssemblyAI, accessed May 9, 2025, [https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction](https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction)  
159. What are Diffusion Models? | Lil'Log, accessed May 9, 2025, [https://lilianweng.github.io/posts/2021-07-11-diffusion-models/](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)  
160. tglcourse \- An Introduction to Diffusion Models, accessed May 9, 2025, [https://johnowhitaker.github.io/tglcourse/dm1.html](https://johnowhitaker.github.io/tglcourse/dm1.html)  
161. Stable Diffusion Models: a beginner's guide, accessed May 9, 2025, [https://stable-diffusion-art.com/models/](https://stable-diffusion-art.com/models/)  
162. A Gauss-Newton Approach for Min-Max Optimization in Generative Adversarial Networks \- arXiv, accessed May 9, 2025, [https://arxiv.org/pdf/2404.07172?](https://arxiv.org/pdf/2404.07172)  
163. Improving the Fairness of the Min-Max Game in GANs Training \- CVF Open Access, accessed May 9, 2025, [https://openaccess.thecvf.com/content/WACV2024/papers/Zhang\_Improving\_the\_Fairness\_of\_the\_Min-Max\_Game\_in\_GANs\_Training\_WACV\_2024\_paper.pdf](https://openaccess.thecvf.com/content/WACV2024/papers/Zhang_Improving_the_Fairness_of_the_Min-Max_Game_in_GANs_Training_WACV_2024_paper.pdf)  
164. \[2412.18288\] Towards understanding how attention mechanism works in deep learning \- arXiv, accessed May 9, 2025, [https://arxiv.org/abs/2412.18288](https://arxiv.org/abs/2412.18288)  
165. \[2310.10837\] Approximating Two-Layer Feedforward Networks for Efficient Transformers \- arXiv, accessed May 9, 2025, [https://arxiv.org/abs/2310.10837](https://arxiv.org/abs/2310.10837)  
166. Graph Transformer Networks \- NIPS papers, accessed May 9, 2025, [https://proceedings.neurips.cc/paper/9367-graph-transformer-networks.pdf](https://proceedings.neurips.cc/paper/9367-graph-transformer-networks.pdf)  
167. Physics-Informed Transformer Networks \- NeurIPS 2025, accessed May 9, 2025, [https://neurips.cc/virtual/2023/75460](https://neurips.cc/virtual/2023/75460)  
168. Interpretable Additive Tabular Transformer Networks \- OpenReview, accessed May 9, 2025, [https://openreview.net/forum?id=TdJ7lpzAkD](https://openreview.net/forum?id=TdJ7lpzAkD)  
169. Efficient Sparsely Activated Transformers \- ICML 2025, accessed May 9, 2025, [https://icml.cc/virtual/2022/19299](https://icml.cc/virtual/2022/19299)  
170. Anterior Cruciate Ligament (ACL) Tear Detection using Hybrid CNN Transformer, accessed May 9, 2025, [https://www.researchgate.net/publication/389759443\_Anterior\_Cruciate\_Ligament\_ACL\_Tear\_Detection\_using\_Hybrid\_CNN\_Transformer](https://www.researchgate.net/publication/389759443_Anterior_Cruciate_Ligament_ACL_Tear_Detection_using_Hybrid_CNN_Transformer)  
171. Hierarchical Transformer Networks for Long-sequence and Multiple Clinical Documents Classification | OpenReview, accessed May 9, 2025, [https://openreview.net/forum?id=jMKxETwI9fK](https://openreview.net/forum?id=jMKxETwI9fK)