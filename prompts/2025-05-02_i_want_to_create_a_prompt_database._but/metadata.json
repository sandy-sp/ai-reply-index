{
  "prompt": "i want to create a prompt database. but the prompt system is not standardized, every one have their own system. i want to come up with a universal system to classify different types of prompts and its sub classification. rather than a SQL i think this kind of database requires NOSQL, i dont know? but i want ask such key questions and self reflect to come up with a system to create a prompt database. start the thought process from here - What is a prompt database and how to create one where a normal human can use it easily?",
  "model": "ChatGPT",
  "response": "# Designing a Universal Prompt Database and Sharing Platform\n\n## What is a Prompt Database?\n\nA **prompt database** is essentially a repository of AI model prompts that\nhave been collected, organized, and made accessible for reuse. In prompt\nengineering, crafting a good prompt often takes iteration and skill, so a\nprompt database serves to **save users from \u201creinventing the wheel\u201d** each\ntime they need a prompt[virtualcaio.com](https://virtualcaio.com/prompt-\ndatabase#:~:text=A%20prompt%20database%20is%20a,you%20use%20it%20a%20lot).\nInstead of starting from scratch, users can pull from a library of tried-and-\ntested prompts that are known to produce effective results. Such a database\ncan span prompts for various purposes \u2013 from creative writing and coding to\nimage generation \u2013 acting as a knowledge base of best practices in interacting\nwith AI models[promptpanda.io](https://www.promptpanda.io/blog/ai-prompt-\ndatabase/#:~:text=The%20AI%20Prompt%20Database%20is,solving%20across%20different%20fields).\n\nPrompt databases drive efficiency and creativity. By browsing a well-curated\nprompt library, an AI developer or prompt engineer can quickly find\ninspiration or a starting template for their task. General end-users also\nbenefit by discovering prompts that yield useful outputs without needing deep\nprompt-crafting expertise. In summary, a prompt database bridges the gap\nbetween human intent and machine understanding by providing ready-made\ninstructions (prompts) that elicit high-quality responses from\nAI[promptpanda.io](https://www.promptpanda.io/blog/ai-prompt-\ndatabase/#:~:text=The%20AI%20Prompt%20Database%20is,solving%20across%20different%20fields).\nThis communal sharing of prompts fosters a community of practice around AI,\nmuch like code repositories do for programmers.\n\n## Prompt Schema and Data Model Design\n\nDesigning a flexible and extensible **prompt schema** is a core consideration\nfor a universal prompt platform. The goal is to accommodate diverse prompt\ntypes (text-to-text, text-to-image, code generation, chatbot conversations,\ntext-to-audio, etc.) under a **standardized structure**. At a high level, each\nprompt entry should capture basic metadata as well as any modality-specific\ndetails. Key fields and metadata might\ninclude[virtualcaio.com](https://virtualcaio.com/prompt-\ndatabase#:~:text=You%20might%20consider%20the%20following,fields%20in%20a%20prompt%20database)[virtualcaio.com](https://virtualcaio.com/prompt-\ndatabase#:~:text=,2%20or%20an%20internal%20database):\n\n  * **Prompt Content:** The text of the prompt itself (e.g. the instruction or query given to the AI). This is the central content that will be sent to an AI model.\n\n  * **Title/Description:** A short title or description summarizing the prompt\u2019s intent. This helps users quickly identify what the prompt does.\n\n  * **Type and Sub-Type:** The category of the prompt by modality and a sub-category. For example, type could be \"Text-to-Image\" vs \"Text Generation\", and sub-type could refine this (e.g. an image prompt\u2019s sub-type might be \u201cphotorealistic portrait\u201d vs \u201cabstract art\u201d, while a text prompt\u2019s sub-type might be \u201cchatbot persona\u201d vs \u201ccoding assistant\u201d). This classification allows filtering and specialized handling per prompt type.\n\n  * **LLM/Model Compatibility:** Which AI models or model families the prompt is designed to work with. This could be a list of models (e.g. \u201cOpenAI GPT-4, Midjourney v5, Stable Diffusion 1.5\u201d) or tags like \u201cStable Diffusion\u201d or \u201cChatGPT\u201d indicating compatibility. Storing this as a list of model identifiers or tags enables users to search prompts that are known to work on a given model[virtualcaio.com](https://virtualcaio.com/prompt-database#:~:text=,2%20or%20an%20internal%20database).\n\n  * **Tags/Keywords:** A set of tags describing the prompt\u2019s content or domain (e.g. `finance`, `creative-writing`, `Python`, `landscape`, etc.). Tags help in searching and grouping prompts by topic or style. For instance, a prompt might be tagged with `image, fantasy, landscape` or `text, marketing, email` to denote its usage.\n\n  * **Author/Creator:** Which user contributed the prompt. This ties into user profiles and attribution. It\u2019s useful for reputation (seeing prompts by a particular expert) and for allowing editing or removal by the owner.\n\n  * **Likes/Favorites Count:** A numeric count of how many users liked or saved the prompt. This serves as a quality signal \u2013 prompts with more likes are presumably effective or popular.\n\n  * **Fork/Source Reference:** If the prompt is a \u201cfork\u201d (editable copy) of another prompt, the schema should record a reference to the original prompt entry (e.g. an `original_prompt_id`). This creates a version lineage so users can see popular derivatives and the evolution of prompts. A fork count could also be derived to show how many times a prompt has been copied/modified by others.\n\n  * **Creation & Update Timestamps:** Dates for when the prompt was first created and last updated. This is standard metadata, useful for sorting (e.g. newest prompts) and for maintainers to know if a prompt is stale or has been improved over time.\n\n  * **Optional Example Output:** Especially for non-text modalities, it\u2019s useful to store an example result of the prompt. For a text-to-image prompt, this could be a thumbnail of an image generated using that prompt; for a code-generation prompt, perhaps a snippet of the code output or a description of the result. While not mandatory, example outputs can help users understand what to expect. (This field might be a URL to an image or a text blob, depending on type.)\n\n**Diverse Prompt Types \u2013 unified structure:** Each prompt type may require\nadditional fields beyond the core metadata above. For instance, a **text-to-\nimage** prompt often comes with **generation parameters** : Stable Diffusion\nprompts commonly include a **\u201cnegative prompt\u201d** (describing what  _not_ to\ninclude), as well as settings like image size, seed value for randomness, or\nguidance scale. To illustrate, the Lexica prompt database (for Stable\nDiffusion images) stores not just the prompt text but also metadata like image\ndimensions, the random seed used, and the model name (`\"stable-diffusion\"` in\nthis\ncase)[lexica.art](https://lexica.art/docs#:~:text=%2F%2F%20The%20prompt%20used%20to,generate%20this%20image)[lexica.art](https://lexica.art/docs#:~:text=%2F%2F%20Seed).\nLikewise, a text-to-image prompt entry might look like:\n\n  * Prompt text:  _\u201cA medieval castle on a hill at sunset, cinematic lighting.\u201d_\n\n  * Negative prompt:  _\u201cugly, distorted, watermark\u201d_\n\n  * Model:  _Stable Diffusion 1.5_\n\n  * Other params:  _width=512, height=512, seed=123456, guidance_scale=7_[ lexica.art](https://lexica.art/docs#:~:text=%2F%2F%20Seed).\n\nFor a **text generation** prompt (e.g. ChatGPT prompt), the additional\nstructure could involve roles or context. If it\u2019s a single-turn prompt, it\nmight just be a plain instruction. If it\u2019s a chatbot prompt, it could include\na system message (\u201cYou are an expert assistant\u2026\u201d) and possibly example user-\nassistant exchanges. We might store these as an array of messages or a\nformatted block of text. A **code generation** prompt might have a field for\nthe programming language or an optional starter code snippet that the model\nshould build upon. A **text-to-audio** prompt (text-to-speech or music\ngeneration) might include settings like the voice style or emotion, or\nreferences to a base audio model. While each modality has unique attributes,\n_the schema should be designed such that these specific fields don\u2019t break the\noverall structure_. One approach is to use a flexible JSON field or separate\nlinked table for **prompt parameters** , where type-specific data can be\nstored in a structured way. This way, every prompt entry has the core fields\n(content, tags, etc.) and, if needed, an attached JSON blob or related record\nwith extra details relevant only to its type.\n\n**Standardization across modalities:** To ensure consistency, we define a\n**common prompt interface**. At minimum, every prompt has a text instruction\nand some descriptive metadata as outlined. Additional fields can be\nstandardized per modality through schemas. For example, we define a schema for\n\u201cimage prompts\u201d that includes `negative_prompt`, `model`, `resolution`, etc.,\nand a schema for \u201cchat prompts\u201d that might include a list of dialogue turns.\nInternally, these could correspond to separate database tables or a unified\ntable with optional columns/JSON. Using a **model-agnostic format** is crucial\n\u2013 in fact, some frameworks like  _AIConfig_ advocate storing prompts in a\nstandardized JSON format along with model settings, which can be extended to\nany generative AI model (text, image, or\naudio)[github.com](https://github.com/lastmile-\nai/aiconfig#:~:text=,including%20text%2C%20image%20and%20audio). By adopting\nsuch an approach, our platform can treat all prompts in a unified way (for\nlisting, tagging, sharing) while still preserving the nuances of each type. In\npractice, this means when a user views a prompt, the UI can display the core\ninfo (prompt text, author, likes) in a consistent layout, and if there are\nextra details (like an image prompt\u2019s parameters or a code prompt\u2019s language),\nthose can be shown in a details section.\n\n### Example Data Model\n\n _Figure: An example entity-relationship diagram for the prompt database._ The\nplatform\u2019s data model can be designed in a relational style, capturing users,\nprompts, and their relationships. In the diagram, each **Prompt** is linked to\na **User** (its creator/author). Prompts can have many **Tags** (many-to-many\nrelationship, managed by a join table like `PromptTag`), allowing flexible\ncategorization. A **Model** table (or just a list of model tags) can record\nwhich AI models a prompt is compatible with \u2013 implemented via a join table\n`PromptModel` so that each prompt can reference multiple models. Social\ninteractions like likes (and saves) are represented by linking users to\nprompts in a **Like** table (and similarly a save/bookmark table, not shown,\nwould be analogous). The self-referential arrow \u201cforks\u201d on the Prompt entity\nindicates that a prompt may optionally point to another prompt as its original\nsource (forking relationship). This could be a field `original_prompt_id` in\nthe Prompt table, enabling the platform to trace fork lineages.\n\nThis relational schema is **extensible** : if a new prompt modality comes\nalong (say, text-to-video), one can add new fields or a new parameters table\nfor that type. Many relational databases (like PostgreSQL) also support JSON\ncolumns, which means we could store a blob of type-specific settings in a JSON\nfield for flexibility while still using SQL queries on core fields. The data\nmodel aims to balance structure with flexibility: structured enough to query\n(e.g., \u201cfind all prompts tagged `finance` and compatible with GPT-4\u201d) and\nflexible enough to store the unique data each prompt might need.\n\n## Choosing SQL vs. NoSQL for Prompt Storage\n\nOne key engineering decision is whether to use a traditional **SQL relational\ndatabase** or a **NoSQL** database (document or graph store) for the prompt\ndata. Each has merits given our requirements, and the choice should be\njustified by how the data is structured and how the application will query it.\n\n**Structured relationships:** The platform has multiple interrelated entities\n(users, prompts, tags, likes, etc.), which naturally form a relational\nstructure. **SQL databases** (MySQL, PostgreSQL, etc.) excel at such\nstructured data with clear relationships. They enforce a predefined schema \u2013\ntables with columns and data types \u2013 which ensures data integrity (e.g., a\nlike must reference a valid user and a valid prompt). SQL\u2019s ability to do JOIN\noperations is useful for assembling data (e.g., joining prompts with their\ntags or with the author info). In a relational model, we can easily query\nthings like \u201chow many prompts did user X create\u201d or \u201clist the top prompts with\ntag Y\u201d using SQL joins and aggregations. The downside is that we must define\nthe schema upfront and migrating the schema for new fields requires altering\ntables, but this is usually manageable with good design.\n\n**Flexible prompt structure:** On the other hand, prompts \u2013 especially across\ndiverse modalities \u2013 can be seen as semi-structured or varying in shape. This\nis where a **NoSQL document database** (like MongoDB) could be appealing.\nNoSQL databases allow a more flexible, dynamic schema: each prompt could be\nstored as a JSON document, and prompts of different types could simply have\ndifferent fields in their JSON. For example, a text prompt document might just\nhave `{prompt_text, tags, type:\"text\"}`, whereas an image prompt document\ncould have `{prompt_text, tags, type:\"image\", negative_prompt, width, height,\nmodel:\"SD1.5\", seed}` \u2013 without the database requiring a strictly uniform\ncolumn set. This flexibility makes it easy to evolve the prompt schema (just\nstart including a new field in the JSON). NoSQL can also scale horizontally,\nhandling large volumes of data by sharding, which might become relevant if the\nplatform grows massively[integrate.io](https://www.integrate.io/blog/the-sql-\nvs-nosql-\ndifference/#:~:text=SQL%20databases%20use%20structured%20query,dynamic%20schemas%20for%20unstructured%20data).\n\n**Queries and constraints:** We should consider how we will query the\ndatabase. If we plan to frequently query by relationships (like \u201call prompts a\nuser liked\u201d or \u201cprompts with tag X\u201d), a relational model is very\nstraightforward. In a NoSQL model, these queries might require creating your\nown referencing conventions or duplicating data (since joins are not natively\nsupported in document stores). For example, with MongoDB, one might embed tags\ninside the prompt document or store likes as an array in user documents \u2013 but\neither approach has trade-offs in consistency and query simplicity. Also,\nmaintaining counts (like like counts or fork counts) might be easier in SQL\nusing transactions or triggers to keep counts in sync.\n\n**Hybrid approach:** It\u2019s possible to get the best of both worlds. A common\napproach is to use a relational database for core structured data and use\n**JSON columns** or a schema-less field for the prompt details. PostgreSQL\u2019s\nJSONB column, for instance, would let us store the \u201cparameters\u201d (like the\nnegative prompt, etc.) in a JSON field while still allowing indexing on some\nkeys if needed. This way we get ACID transactions and relational integrity for\nthings like user accounts and likes (where SQL shines with\nconsistency[pro5.ai](https://www.pro5.ai/blog/choosing-the-right-database-for-\nyour-backend-sql-vs-\nnosql#:~:text=2)[pro5.ai](https://www.pro5.ai/blog/choosing-the-right-\ndatabase-for-your-backend-sql-vs-nosql#:~:text=3)), and flexibility for the\nparts of the prompt that vary by type.\n\nIn summary, if we anticipate a highly variable prompt schema and extremely\nhigh scaling needs, a NoSQL solution could be justified. However, given that\nour data has a lot of relational aspects (users, social interactions, tags), a\n**SQL database is likely the more appropriate choice** initially. It provides\nstrong consistency and query capabilities for building the social features.\nThe open-source prompt guide  _virtual CAIO_ also suggests using relational\ndatabases for structured needs and NoSQL if you expect very varied data\nstructures[virtualcaio.com](https://virtualcaio.com/prompt-\ndatabase#:~:text=,Trello%20for%20less%20technical%20solutions). In our case,\nwe can structure the core and still allow variation using JSON or linking\ntables. Moreover, SQL systems can certainly scale (via replication, sharding,\netc.) for a community platform \u2013 many large social sites have scaled on\nrelational databases. Therefore, a reasonable design is to start with a\nrelational DB (e.g. PostgreSQL) with a well-defined schema, and use extensions\n(like JSON fields or separate tables) to handle the prompt-specific extras. If\ndown the line the data model evolves beyond what SQL can comfortably handle,\nwe can consider complementing it with a NoSQL component (for example, using\nElasticSearch for full-text prompt search or a graph DB for exploring prompt\nrelationships).\n\n## User Experience and Feature Set\n\nBuilding an engaging and searchable **user interface** (UI) is critical to\nattract AI developers, prompt engineers, and general users alike. The\nplatform\u2019s UX should make it easy to **browse** , **share** , and **discuss**\nprompts, taking inspiration from familiar social apps like Instagram/Orkut\n(for the social feed feel) while focusing on prompt content.\n\n### Community & Social Features\n\nAt its heart, the platform is a **social network for prompts**. Users will be\nable to create accounts with profiles, where they can showcase the prompts\nthey have shared (their \u201cprompt wall\u201d). Each prompt a user posts appears as a\n**\u201cflashcard-style\u201d post** on their wall \u2013 essentially a card containing the\nprompt (and perhaps a preview or description). Other users can view these\nprompt cards, click on them to see details, and perform social actions:\n\n  * **Like** \ud83d\udc4d \u2013 Users can \u201clike\u201d or upvote prompts they find useful or interesting. The number of likes is visible, providing a signal of quality or popularity (just as Instagram shows likes on a post). A high like count can elevate a prompt to trending lists.\n\n  * **Save** \ud83d\udccc \u2013 Similar to bookmarking, users can save prompts to their personal collection (without publicly signaling it like a like). This is useful for general users who want to remember prompts for later use. It\u2019s analogous to Instagram\u2019s save feature \u2013 a private list of favorites.\n\n  * **Fork** \ud83c\udf74 \u2013 Forking a prompt creates an **editable copy** of that prompt under the user\u2019s account. This feature is inspired by open-source code collaboration (forking a repository) and allows prompt engineers to take an existing prompt and modify or extend it to suit their needs, without altering the original. The forked prompt will reference the original, and ideally the UI will credit the original author and maybe link back (e.g. \u201cForked from User123\u2019s prompt\u201d). This encourages collaboration and iterative improvement of prompts.\n\n  * **Share** \ud83d\udd17 \u2013 Users should be able to share prompts both within the platform and externally. Within the platform, sharing could mean reposting to one\u2019s own wall or recommending to others. Externally, since prompts are text, a one-click copy to clipboard is very handy (to paste into an AI tool). We might also provide a direct link to the prompt\u2019s page so that users can send it to friends or colleagues.\n\nAdditionally, **comments or discussion threads** could be a feature (though\nnot explicitly requested, it\u2019s a common community feature). This would let\nusers discuss how to improve a prompt or describe their results using it. For\nlaunch, comments might be optional, but having a space for feedback under each\nprompt can drive engagement and learning (prompt engineers can get tips from\neach other).\n\nThe UX should make these interactions straightforward \u2013 e.g., icons for\nlike/save/fork on each prompt card. Users should have a personal dashboard:\nviewing all the prompts they\u2019ve liked or saved, and tracking if others fork\ntheir prompts (notifications like \u201cUserX forked your prompt\u201d can gamify\ncontribution).\n\n### Browsing and Discovery\n\nFor a rich library to be useful, the platform must support effective **search\nand discovery** mechanisms:\n\n  * A **Search Bar** with advanced filtering is essential. Users should be able to search by keyword (free-text search through prompt content and titles). This search can be augmented with filters for type, model, tags, or author. For example, one could search \u201cSQL database prompt\u201d and filter type = \u201ctext\u201d to find text prompts about databases, or search \u201clandscape\u201d with type = \u201cimage\u201d to find image generation prompts involving landscapes. Implementing full-text search might involve using the database\u2019s text search capabilities or an external search engine for better scoring of results.\n\n  * **Tag Browsing:** Each tag can be clickable, leading to a page or feed of prompts tagged with that keyword. If a user clicks on \u201cPython\u201d tag, they\u2019d see all prompts relevant to Python (maybe code generation prompts or text prompts about Python). Tag pages help users dive into areas of interest.\n\n  * **Categories:** We might define high-level categories (similar to what The Prompt Index or PromptPanda use, like domains or use-cases). For instance, categories like  _Art, Coding, Marketing, Writing, Gaming, Education_ etc., which group prompts by their purpose. This can be a dropdown or explore section. New users can browse categories to get a sense of what's available. (These might relate to the \u201csub-type\u201d field or just be special tags).\n\n  * **Sorting and Discovery Feeds:** The platform can offer multiple views: \u201cMost Recent\u201d prompts (to see new additions in real-time), \u201cMost Liked\u201d or trending (prompts with the highest likes in the last week, etc.), and perhaps \u201cFeatured\u201d (curated or algorithmically recommended prompts). A **trending feed** helps surface popular content, which motivates contributors to create quality prompts that get likes. Sorting options like by popularity or date help different user needs (finding proven prompts vs. finding the latest experiments).\n\n  * **Personalized Feed:** If users can follow other users or topics, a home feed could show prompts from people you follow or those similar to ones you liked. In the style of Instagram, following prompt creators would make sense \u2013 prompt engineers might gain followers who want to see all their new prompts. However, implementing following is an additional layer (with follow relations and a feed algorithm), which could be a later enhancement. Initially, a global feed or category feeds might suffice.\n\nThe UI itself being \u201cflashcard style\u201d suggests a simple, clean presentation:\nlikely a card with the prompt text (truncated if long), maybe an image or icon\nindicating its type (e.g., a small icon of a chat bubble for text prompts, a\npalette or photo icon for image prompts, a code icon for coding prompts,\netc.). If an image prompt has an example image, the card might even show a\nthumbnail of that image as the visual hook (similar to how Instagram shows the\nimage itself). For text prompts, perhaps a stylized preview of some output or\njust a distinctive background. Consistency in design will help make different\ntypes recognizable at a glance.\n\n**Prompt Detail View:** Clicking on a prompt card should bring up a detailed\nview. This could be a modal or a dedicated page showing the full prompt, all\nits metadata (the full text, any example output, parameters, author, model\ncompatibility, etc.), and the social section (likes, forks, comments). From\nhere, the user can copy the prompt text easily with a \u201cCopy Prompt\u201d button \u2013\nas seen in The Prompt Index (they provide a copy button next to each\nprompt)[thepromptindex.com](https://www.thepromptindex.com/prompt-\ndatabase.php?srsltid=AfmBOoq9V5VACcJQ1EIl0YORDBaCKIwkbwBWrxMlM_w2RnQE9tzPvI7o#:~:text=Prompt%3A%20First%2C%20think%20deeply%20for,then%20respond%20with%20your%20answer).\nThe detail page can also list any forked versions (\u201cForks of this prompt\u201d) and\nrelated prompts (perhaps by tag similarity).\n\n### Design for Multiple User Types\n\nThe platform should be approachable for **general users** while offering depth\nfor **power users (prompt engineers and AI developers)**. General users likely\njust want to find a prompt and use it in their AI tool (e.g., find a good\nprompt for an email draft, copy it, and paste into ChatGPT). So for them,\nquick discovery and one-click copy are key. They might not contribute many\nprompts, but they will consume and perhaps like prompts.\n\nFor the **prompt engineers and developers** , the platform is a playground to\nshowcase their prompt crafting skills and to find building blocks for complex\nprompt workflows. They will appreciate features like forking (so they can\ntweak prompts) and detailed fields (being able to specify model versions, see\nparameters, etc.). They might also appreciate if the platform allows sharing\nnot just single prompts but chains or recipes (for instance, a series of\nprompts or a prompt with expected format). An advanced feature could be\nversioning: allowing prompt authors to update their prompt and maybe keep a\nchange log (the schema field \u201cversion notes\u201d suggested by some\nguides[virtualcaio.com](https://virtualcaio.com/prompt-\ndatabase#:~:text=,2%20or%20an%20internal%20database) hints that tracking\nprompt versions can be useful especially if prompts evolve as models change).\n\n**Ease of contribution:** Posting a prompt should be as straightforward as\nmaking a social media post. The UI would present a form where the user enters\nthe prompt text, selects a type (which then might show additional fields\nrelevant to that type), adds some tags, selects which models it works on\n(perhaps from a multi-select dropdown of popular models), and hits submit. The\nplatform can encourage providing an example output or additional context, but\nthese might be optional to lower the barrier to sharing.\n\nIn summary, the feature set includes: user profiles, prompt posting, liking,\nsaving, forking, searching, tagging, sorting, and possibly commenting and\nfollowing. These features collectively make the platform **engaging (through\nsocial feedback), organized (through tags/categories), and useful (through\neasy search and copy)**. As FlowGPT\u2019s success shows, a large library plus\ncommunity interaction and a user-friendly interface are key features of a\nprompt-sharing\nplatform[guide.flowgpt.com](https://guide.flowgpt.com/about/1basicinfo/1what#:~:text=FlowGPT%20is%20a%20community,questions%20in%20an%20informative%20way)[guide.flowgpt.com](https://guide.flowgpt.com/about/1basicinfo/1what#:~:text=,friendly%20interface).\n\n## Tech Stack and Implementation Considerations\n\nTo build this web-based platform, we will choose tools and frameworks that\nallow rapid development, scalability, and an active open-source community\nsupport (since the project will be open-source on GitHub). Here\u2019s a breakdown\nof the potential technology stack:\n\n**Frontend (Client Side):** A modern, dynamic single-page application (SPA)\nframework is ideal for a smooth, interactive UX. The frontend will be\nresponsible for the interactive feed, prompt cards, forms for new prompts, and\nso on. Popular choices include:\n\n  * **React** : A very popular library for building UIs. React, possibly combined with a framework like **Next.js** , can help in creating a responsive and fast frontend. Next.js would also allow server-side rendering for better SEO (so public prompt pages can be indexed by search engines) and provide an easy way to build an API layer if needed. React\u2019s component-based architecture will let us create reusable components for prompt cards, lists, etc., and its large ecosystem means we can leverage ready-made components (for things like modals, tooltips, icons).\n\n  * **Vue.js** or **Angular** : These are alternatives to React. Vue is lightweight and could be easier for some contributors to grasp, Angular is more full-featured (with built-in state management). The choice largely depends on team familiarity. React has the edge in community size, which might attract more contributors, and many open-source projects use it.\n\n  * **UI Component Libraries** : To achieve a clean, Instagram-like design quickly, we can use libraries such as **Material-UI (MUI)** or **Ant Design** or **Tailwind CSS** for utility-first styling. These can speed up building a cohesive design. For example, Material-UI provides ready-made card components which we can style into \u201cprompt cards\u201d.\n\n  * **State Management** : For handling application state (like the logged-in user info, or a cache of liked prompts), solutions like Redux (for React) or Pinia/Vuex (for Vue) might be used. However, modern React with Context or simple hooks might suffice for a project of this scope.\n\n**Backend (Server Side):** The backend will expose APIs for the frontend to\nfetch data (prompts, user profiles, etc.) and perform actions (like, fork,\nsearch). We have a few good options:\n\n  * **Node.js with Express or NestJS** : Using Node would allow us to write the backend in JavaScript/TypeScript, which aligns with a React frontend (same language across the stack). Express is minimalist and flexible, while NestJS is a framework that provides a more structured, Angular-like architecture out of the box (with controllers, services, etc.). The backend can expose RESTful endpoints (e.g., `GET /api/prompts`, `POST /api/prompts` for new prompt, etc.). If we choose NestJS or a similar framework, we can define modules for prompts, users, etc., making it modular for contributors.\n\n  * **Python with Django or FastAPI** : Python is another solid choice, especially since many AI developers are familiar with Python. Django is a full-featured web framework that could manage the database and API together; it has an admin interface which could be handy for moderation (allowing admins to edit or remove prompts via a web UI). FastAPI is a modern Python framework known for high performance and a great developer experience (with automatic docs generation). It\u2019s lighter than Django and could serve well for just building APIs. Python\u2019s ecosystem also has ORMs like SQLAlchemy or Django\u2019s ORM to interact with the database.\n\n  * **Ruby on Rails** : Rails is a mature framework that excels in rapid development of MVPs. It could quickly scaffold models like Prompt, User, etc., and provide RESTful controllers. It also has a strong community. However, Rails is less commonly used in AI tool contexts these days, so contributors might be less familiar with Ruby compared to JS/Python.\n\nRegardless of language, the backend should implement authentication (user\nlogin, JWT or session cookies), and enforce permissions (e.g., only the author\nor an admin can delete a prompt, etc.). There are libraries for auth in all\nmajor frameworks (Passport.js for Node, Django Allauth for Django, etc.), and\nOAuth integration if we want users to sign in via Google/GitHub for\nconvenience.\n\n**Database:** As discussed, a SQL database is a strong candidate.\n**PostgreSQL** is a great choice for open-source projects \u2013 it\u2019s free,\npowerful, and supports JSONB if we need the flexibility. It will handle\nrelational data for users, prompts, likes, etc., with ACID compliance ensuring\nconsistency (important for things like like counts and fork relations). If\nusing Django, it works smoothly with Postgres. If using Node, ORMs like Prisma\nor TypeORM can manage the Postgres schema. We should design indexes on key\nfields: for instance, an index on `Prompt.type` or `Prompt.content` for text\nsearch (or use Postgres full-text search capabilities on the content), indexes\non the join tables for fast tag filtering, etc. If the search requirements are\nbeyond basic text match, we might integrate **Elasticsearch** or\n**MeiliSearch** for more advanced full-text and filtering \u2013 these can index\nprompt documents and allow more complex queries (like semantic search or typo-\ntolerant search).\n\nFor NoSQL considerations, if we decided to use a document store instead,\n**MongoDB** could be used similarly to store prompt documents, but we\u2019d then\nneed to handle relations in the application logic. Another approach is using\n**Firebase/Firestore** , which offers a ready-made cloud NoSQL with auth \u2013 but\nsince our goal is open-source and self-hostable, Firestore (a Google service)\nmight not align with the deployment goals.\n\n**Storage for media:** If we allow image uploads (say a user attaches an\nexample image for their image prompt) or plan to store user profile pictures,\nwe\u2019ll need a place to store those files. This could be as simple as saving on\nthe server\u2019s filesystem (for a small scale) or using an object storage service\n(like Amazon S3 or an open-source alternative like MinIO). This is an\nimplementation detail, but worth noting. For instance, example images\ngenerated from prompts could be stored and the URL saved in the database.\n\n**APIs and Sharing:** All functionality should be exposed via well-defined\nAPIs. We may provide a public API for external developers to retrieve prompts\n(this could spur integrations, like a browser extension that fetches a prompt\nfrom the database and inputs it into an AI). Ensuring our API is RESTful or\nGraphQL and well-documented will also encourage community contributions and\nuse. GraphQL could be beneficial for a complex querying interface (clients can\nask for exactly the data they need, e.g., prompt with tags and author in one\nrequest), whereas REST is simpler to implement initially.\n\n**Real-time and Notifications:** While not a core requirement, if we add real-\ntime features (like seeing live updates or getting notified when someone forks\nyour prompt), technologies like WebSockets or using libraries (Socket.io in\nNode, or Django Channels in Python) could be introduced. However, this might\nbe overkill initially. Alternatively, periodic refresh or simple notification\ncenter (polled) could suffice.\n\nIn terms of development tools, since the project is open-source on GitHub:\n\n  * Setting up continuous integration (CI) tests (using GitHub Actions or similar) will help ensure contributions don\u2019t break the build.\n\n  * Using Docker or docker-compose to allow anyone to run the stack locally with minimal effort (containers for the web server, database, etc.) can greatly lower the barrier for contributors testing their changes.\n\n  * We should also include good documentation: a README with setup instructions, and maybe use tools like Swagger/OpenAPI (if REST) to document the API.\n\nBy choosing popular frameworks (React, Express, Django, etc.), we tap into\nlarge communities, meaning many potential contributors will be already\nfamiliar with the stack. This aligns with our open-source community goals and\nwill make it easier to maintain in the long run.\n\n## Examples of Similar Platforms and Inspiration\n\nThough the concept of a unified multi-modal prompt sharing platform is\ncutting-edge, we can draw inspiration from several existing platforms that\ntackle prompt sharing in specific domains:\n\n  * **FlowGPT** \u2013 A community-driven platform focusing on sharing prompts for ChatGPT and similar text-based models. FlowGPT has a large library of text prompts and emphasizes ease of sharing and discovery[guide.flowgpt.com](https://guide.flowgpt.com/about/1basicinfo/1what#:~:text=FlowGPT%20is%20a%20community,questions%20in%20an%20informative%20way). Its feature set includes prompt categorization and a user-friendly interface, demonstrating the appetite for prompt-sharing among users of conversational AI[guide.flowgpt.com](https://guide.flowgpt.com/about/1basicinfo/1what#:~:text=,friendly%20interface). Our platform\u2019s text prompt features (like prompt descriptions, copy-to-clipboard, etc.) can be modeled after what FlowGPT and similar communities provide.\n\n  * **The Prompt Index / PromptHero / Krea** \u2013 These are websites that catalog prompts, especially for image generation. For instance, The Prompt Index offers hundreds of prompts organized by categories (SEO, coding, marketing, etc.) and allows users to upvote them[thepromptindex.com](https://www.thepromptindex.com/prompt-database.php?srsltid=AfmBOoq9V5VACcJQ1EIl0YORDBaCKIwkbwBWrxMlM_w2RnQE9tzPvI7o#:~:text=Prompt%20Database). PromptHero and Krea.ai specifically have focused on Stable Diffusion prompts; they host large databases of prompts with corresponding images. A Medium study noted that Krea.ai released a database of over 10 million Stable Diffusion prompts scraped from Discord[medium.com](https://medium.com/@soapsudtycoon/prompt-engineering-trending-on-artstation-and-other-myths-part-2-d61e25a90517#:~:text=Krea,it%20should%20be%20good%2C%20right) \u2013 highlighting the scale of prompt data out there and the interest in indexing it. From these, we learn the importance of good filters; e.g., PromptHero lets you filter by model or image style, and Krea offers curated prompt collections like \u201cphotography modifiers\u201d for image prompts[medium.com](https://medium.com/@soapsudtycoon/prompt-engineering-trending-on-artstation-and-other-myths-part-2-d61e25a90517#:~:text=Krea,volumetric%20lighting%2C%20and%20many%20others). Our platform can incorporate similar filtering for image prompts (like filter by model or style tags).\n\n  * **Lexica** \u2013 An online search engine for Stable Diffusion-generated images and their prompts. Lexica is less of a social platform and more of a search tool, but it provides a great example of how to present image prompts alongside outputs. Each result on Lexica shows the prompt text and allows users to copy it, with metadata like the model and seed visible[lexica.art](https://lexica.art/docs#:~:text=%2F%2F%20The%20prompt%20used%20to,generate%20this%20image)[lexica.art](https://lexica.art/docs#:~:text=%2F%2F%20Seed). For our image prompt entries, showing a small result image (if available) and the key generation parameters will be inspired by Lexica\u2019s approach. Lexica also demonstrates scaling \u2013 it serves millions of image results, suggesting that prompt search can be optimized (they likely use specialized indexing for prompt text).\n\n  * **PromptBase** \u2013 A marketplace where prompt engineers sell prompts. While our platform is about free sharing, PromptBase highlights an interesting point: prompts can be treated as assets. PromptBase\u2019s existence suggests we might later consider features like **import/export** of prompts (maybe users can download a set of prompts or share links) and also underscores the need for clear **licensing or usage terms** for prompts (especially since we are open-source, perhaps prompts shared could default to a certain open license to encourage reuse, though users should be aware if they share proprietary info).\n\n  * **Hugging Face** \u2013 The Hugging Face Hub isn\u2019t a prompt sharing site, but it is a model and dataset sharing platform that has community features. We mention it because Hugging Face hosts  _datasets of prompts_ (for example, collections of prompts used to fine-tune models). Also, some Hugging Face Spaces (demo apps) include \u201cprompt generators\u201d or \u201cprompt libraries\u201d for specific models. The community aspect (followers, discussions on model pages) can inspire similar engagement on our prompt pages.\n\nIn summary, while no single existing platform covers  _all_ modalities\ntogether, each provides lessons: **FlowGPT** for text prompt community\nbuilding, **Lexica/PromptHero** for image prompt search and presentation, and\n**PromptIndex/PromptBase** for organization and value of prompts. Our platform\naims to unify these modalities, so users who work with multiple AI systems can\nfind everything in one place. By studying these case studies, we ensure our\nfeature set is competitive and addresses user expectations. We will also be\none of the first to open-source such a platform, inviting the community to\nimprove it \u2013 much like these examples succeeded by engaging their user\ncommunities.\n\n## Scalability and Open-Source Community Considerations\n\n### Scaling the Platform\n\nAs the user base and prompt library grow, the system architecture should\nhandle increasing load gracefully. **Scalability** must be considered in terms\nof both **read-heavy traffic** (many users browsing and searching prompts) and\n**write operations** (users adding prompts, likes, etc.). Some strategies and\nconsiderations:\n\n  * **Horizontal Scaling** : Design stateless backend servers so that we can run multiple instances behind a load balancer. This way, if the traffic increases, we can deploy additional server instances. Using cloud infrastructure (AWS, Azure, etc.) with auto-scaling groups or container orchestration (Docker + Kubernetes) can automate scaling. The statelessness means session data is stored in client tokens or a shared store (like Redis for sessions), not in memory.\n\n  * **Database Scaling** : A single SQL DB can be scaled vertically (more CPU, RAM, using a managed service for performance). For read-intensive workloads, adding read replicas can help distribute the load of search queries. If using Postgres, one could set up replicas and direct heavy read queries (like list browsing) to replicas while writes go to the master. Partitioning the database by certain keys (for example, by prompt type or by date) could be an option if tables grow extremely large, but that\u2019s likely only needed at massive scale. In a scenario of explosive growth (millions of prompts), we might consider sharding (e.g. using a distributed SQL like CockroachDB or Yugabyte, or moving some data to NoSQL). However, until we reach that point, simpler optimizations suffice.\n\n  * **Caching** : Introduce caching layers to reduce database load. For example, popular prompts or lists (like the \u201ctop prompts of the day\u201d) can be cached in an in-memory store like Redis. Similarly, when a user visits the site, their personal feed or frequently accessed data (like their own profile prompts) could be cached after first load. This reduces repeated queries. At the application level, we can cache the results of expensive queries (with an invalidation strategy when underlying data changes).\n\n  * **Content Delivery Network (CDN)** : If the platform serves images (prompt example outputs or user avatars), using a CDN to deliver those static assets will offload work from our servers and speed up content delivery globally. Even the site\u2019s static frontend files (JS, CSS) should be on a CDN for faster load.\n\n  * **Search optimization** : Searching across prompt text might become slow as data grows. If we find DB text search insufficient, deploying a search engine like **Elasticsearch** or **Apache Solr** could index prompts (with fields like tags, content, and even vector embeddings for semantic search) and handle queries far more efficiently. This would be a separate service optimized for reads. We might also consider using a vector database to enable semantic search (so users can find prompts by meaning, not just exact keywords), especially useful if we have many prompts.\n\n  * **Monitoring and Performance Tuning** : As an open-source project, we should encourage deployment of monitoring (like using tools such as Grafana/Prometheus or even New Relic) to watch database query times, memory usage, etc. This helps identify bottlenecks (for example, a particular query for the homepage feed might become slow with 100k prompts \u2013 then we know to add an index or redesign that query).\n\nWe should also plan for **moderation and content management at scale**. A\nprompt sharing platform could be misused (people might post spam or malicious\nprompts). At the start, this might be manual \u2013 admins removing inappropriate\ncontent. As it scales, community flagging mechanisms might be needed. This\nisn\u2019t directly about scaling performance, but scaling community governance.\nOpen-sourcing the project means others might host their own instances with\ntheir moderation rules, but for the public deployment, having clear usage\npolicies and some automated moderation (like filtering certain profanity in\npublic tags, etc.) could be considered.\n\n### Open-Source Community and Contributions\n\nSince the platform will have its development files on GitHub and invites open-\nsource contributions, we should cultivate a welcoming project environment:\n\n  * **Clear Documentation and Roadmap** : Providing a comprehensive README, contribution guide, and perhaps a roadmap of features will help contributors understand where they can help. Detailing the setup process (how to run the dev environment, run tests, etc.) is crucial. New contributors should be able to get the app running locally in minutes.\n\n  * **Modular Architecture** : As described in the tech stack, keeping the code modular (separating concerns like frontend vs backend, or within backend separate modules for prompts, users, etc.) makes it easier for people to work on different parts without stepping on each other\u2019s toes. For example, someone might improve the search algorithm while someone else works on UI tweaks simultaneously.\n\n  * **Issue Tracker and Labels** : We should use GitHub Issues to track bugs and feature requests, and label them (e.g., \u201cgood first issue\u201d for newcomers, \u201cbackend\u201d, \u201cfrontend\u201d, etc.). This signals to the community how they can jump in. For instance, an issue like \u201cImplement comment feature\u201d can be taken up by an interested contributor.\n\n  * **Code Reviews and Quality** : Encouraging thorough code reviews for incoming pull requests will maintain quality and also help mentor less experienced contributors. We should set up some automated linting and testing (so the CI can flag basic issues). This ensures the project remains maintainable as it grows.\n\n  * **License and Contribution Agreement** : Choosing a permissive license (like MIT or Apache-2.0) will encourage usage and contributions, since companies or individuals can adopt the platform without heavy restrictions. We might include a contributor license agreement (CLA) if needed (common in open-source projects to clarify that contributions are made under the project\u2019s license).\n\n  * **Community Engagement** : Beyond the code, building a community of users who contribute prompts is important. We could integrate the platform with the GitHub project by, for example, using discussions or a Discord/Slack channel for the project. This way developers and users can communicate. Prompt engineers using the platform might suggest features (\u201cI wish I could do X on the site...\u201d), which can directly translate into GitHub issues for contributors to tackle.\n\n  * **Encouraging Prompt Contributions** : Since content (prompts) is king for this platform, an open-source mindset can extend to the data as well. We might allow bulk import/export of prompts, or integration with GitHub (for example, a repo that auto-syncs prompts in JSON format). This way, the prompt library itself could become a community-maintained resource. However, this needs careful thought on consistency and avoiding spam.\n\nBy addressing scaling early, we ensure the platform can grow with its\npopularity. By nurturing the open-source community, we ensure that growth is\nsustainable \u2013 with many eyes on the code and many contributors adding\nimprovements. Ultimately, the vision is a robust, community-driven prompt\ndatabase that thrives both in content and code quality. With a solid schema,\nuser-friendly features, and the right tech foundation, this universal prompt\nsharing platform could become a go-to hub for prompt engineers and AI\nenthusiasts worldwide \u2013 much like a \u201cGitHub for prompts,\u201d where sharing and\ncollaboration fuel the advancement of prompt engineering.\n\n**Sources:** Prompt database concepts and\nbenefits[virtualcaio.com](https://virtualcaio.com/prompt-\ndatabase#:~:text=A%20prompt%20database%20is%20a,you%20use%20it%20a%20lot)[promptpanda.io](https://www.promptpanda.io/blog/ai-\nprompt-\ndatabase/#:~:text=The%20AI%20Prompt%20Database%20is,solving%20across%20different%20fields);\nrecommended prompt metadata\nfields[virtualcaio.com](https://virtualcaio.com/prompt-\ndatabase#:~:text=You%20might%20consider%20the%20following,fields%20in%20a%20prompt%20database)[virtualcaio.com](https://virtualcaio.com/prompt-\ndatabase#:~:text=,2%20or%20an%20internal%20database); FlowGPT community\nfeatures[guide.flowgpt.com](https://guide.flowgpt.com/about/1basicinfo/1what#:~:text=FlowGPT%20is%20a%20community,questions%20in%20an%20informative%20way)[guide.flowgpt.com](https://guide.flowgpt.com/about/1basicinfo/1what#:~:text=,friendly%20interface);\nexample of image prompt metadata from\nLexica[lexica.art](https://lexica.art/docs#:~:text=%2F%2F%20The%20prompt%20used%20to,generate%20this%20image)[lexica.art](https://lexica.art/docs#:~:text=%2F%2F%20Seed);\nand discussions on using SQL vs. NoSQL for structured vs. flexible\ndata[virtualcaio.com](https://virtualcaio.com/prompt-\ndatabase#:~:text=,Trello%20for%20less%20technical%20solutions)[integrate.io](https://www.integrate.io/blog/the-\nsql-vs-nosql-\ndifference/#:~:text=SQL%20databases%20use%20structured%20query,dynamic%20schemas%20for%20unstructured%20data).\nThese informed the above design and recommendations.\n\nCitations\n\n[![Favicon](https://www.google.com/s2/favicons?domain=https://virtualcaio.com&sz=32)Prompt Database | virtual CAIOhttps://virtualcaio.com/prompt-database](https://virtualcaio.com/prompt-database#:~:text=A%20prompt%20database%20is%20a,you%20use%20it%20a%20lot)[![Favicon](https://www.google.com/s2/favicons?domain=https://www.promptpanda.io&sz=32)The Ultimate Content Assistant: How AI Prompt Databases Drive Success - promptpanda.iohttps://www.promptpanda.io/blog/ai-prompt-database/](https://www.promptpanda.io/blog/ai-prompt-database/#:~:text=The%20AI%20Prompt%20Database%20is,solving%20across%20different%20fields)[![Favicon](https://www.google.com/s2/favicons?domain=https://virtualcaio.com&sz=32)Prompt Database | virtual CAIOhttps://virtualcaio.com/prompt-database](https://virtualcaio.com/prompt-database#:~:text=You%20might%20consider%20the%20following,fields%20in%20a%20prompt%20database)[![Favicon](https://www.google.com/s2/favicons?domain=https://virtualcaio.com&sz=32)Prompt Database | virtual CAIOhttps://virtualcaio.com/prompt-database](https://virtualcaio.com/prompt-database#:~:text=,2%20or%20an%20internal%20database)[![Favicon](https://www.google.com/s2/favicons?domain=https://lexica.art&sz=32)Lexica Search APIhttps://lexica.art/docs](https://lexica.art/docs#:~:text=%2F%2F%20The%20prompt%20used%20to,generate%20this%20image)[![Favicon](https://www.google.com/s2/favicons?domain=https://lexica.art&sz=32)Lexica Search APIhttps://lexica.art/docs](https://lexica.art/docs#:~:text=%2F%2F%20Seed)[![Favicon](https://www.google.com/s2/favicons?domain=https://github.com&sz=32)GitHub - lastmile-ai/aiconfig: AIConfig is a config-based framework to build generative AI applications.https://github.com/lastmile-ai/aiconfig](https://github.com/lastmile-ai/aiconfig#:~:text=,including%20text%2C%20image%20and%20audio)[![Favicon](https://www.google.com/s2/favicons?domain=https://www.integrate.io&sz=32)SQL vs NoSQL: 5 Critical Differences - Integrate.iohttps://www.integrate.io/blog/the-sql-vs-nosql-difference/](https://www.integrate.io/blog/the-sql-vs-nosql-difference/#:~:text=SQL%20databases%20use%20structured%20query,dynamic%20schemas%20for%20unstructured%20data)[![Favicon](https://www.google.com/s2/favicons?domain=https://www.pro5.ai&sz=32)Choosing the Right Database for Your Backend: SQL vs. NoSQLhttps://www.pro5.ai/blog/choosing-the-right-database-for-your-backend-sql-vs-nosql](https://www.pro5.ai/blog/choosing-the-right-database-for-your-backend-sql-vs-nosql#:~:text=2)[![Favicon](https://www.google.com/s2/favicons?domain=https://www.pro5.ai&sz=32)Choosing the Right Database for Your Backend: SQL vs. NoSQLhttps://www.pro5.ai/blog/choosing-the-right-database-for-your-backend-sql-vs-nosql](https://www.pro5.ai/blog/choosing-the-right-database-for-your-backend-sql-vs-nosql#:~:text=3)[![Favicon](https://www.google.com/s2/favicons?domain=https://virtualcaio.com&sz=32)Prompt Database | virtual CAIOhttps://virtualcaio.com/prompt-database](https://virtualcaio.com/prompt-database#:~:text=,Trello%20for%20less%20technical%20solutions)[![Favicon](https://www.google.com/s2/favicons?domain=https://www.thepromptindex.com&sz=32)AI Prompts | ChatGPT Prompts | Prompt Databasehttps://www.thepromptindex.com/prompt-database.php?srsltid=AfmBOoq9V5VACcJQ1EIl0YORDBaCKIwkbwBWrxMlM_w2RnQE9tzPvI7o](https://www.thepromptindex.com/prompt-database.php?srsltid=AfmBOoq9V5VACcJQ1EIl0YORDBaCKIwkbwBWrxMlM_w2RnQE9tzPvI7o#:~:text=Prompt%3A%20First%2C%20think%20deeply%20for,then%20respond%20with%20your%20answer)[![Favicon](https://www.google.com/s2/favicons?domain=https://guide.flowgpt.com&sz=32)What is FlowGPT? \u2013 FlowGPThttps://guide.flowgpt.com/about/1basicinfo/1what](https://guide.flowgpt.com/about/1basicinfo/1what#:~:text=FlowGPT%20is%20a%20community,questions%20in%20an%20informative%20way)[![Favicon](https://www.google.com/s2/favicons?domain=https://guide.flowgpt.com&sz=32)What is FlowGPT? \u2013 FlowGPThttps://guide.flowgpt.com/about/1basicinfo/1what](https://guide.flowgpt.com/about/1basicinfo/1what#:~:text=,friendly%20interface)[![Favicon](https://www.google.com/s2/favicons?domain=https://www.thepromptindex.com&sz=32)AI Prompts | ChatGPT Prompts | Prompt Databasehttps://www.thepromptindex.com/prompt-database.php?srsltid=AfmBOoq9V5VACcJQ1EIl0YORDBaCKIwkbwBWrxMlM_w2RnQE9tzPvI7o](https://www.thepromptindex.com/prompt-database.php?srsltid=AfmBOoq9V5VACcJQ1EIl0YORDBaCKIwkbwBWrxMlM_w2RnQE9tzPvI7o#:~:text=Prompt%20Database)[![Favicon](https://www.google.com/s2/favicons?domain=https://medium.com&sz=32)Prompt engineering: Trending on artstation and other myths (part 2) | by Adi | Mediumhttps://medium.com/@soapsudtycoon/prompt-engineering-trending-on-artstation-and-other-myths-part-2-d61e25a90517](https://medium.com/@soapsudtycoon/prompt-engineering-trending-on-artstation-and-other-myths-part-2-d61e25a90517#:~:text=Krea,it%20should%20be%20good%2C%20right)[![Favicon](https://www.google.com/s2/favicons?domain=https://medium.com&sz=32)Prompt engineering: Trending on artstation and other myths (part 2) | by Adi | Mediumhttps://medium.com/@soapsudtycoon/prompt-engineering-trending-on-artstation-and-other-myths-part-2-d61e25a90517](https://medium.com/@soapsudtycoon/prompt-engineering-trending-on-artstation-and-other-myths-part-2-d61e25a90517#:~:text=Krea,volumetric%20lighting%2C%20and%20many%20others)",
  "tags": [
    "DeepResearch"
  ],
  "date": "2025-05-02"
}